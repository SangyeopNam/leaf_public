[{"content":"도입 작성 배경 : 이번 토이프로젝트에서 Spring Security를 다루고 있는데, 기본 개념을 제대로 이해하지 못해서 많은 어려움을 겪었습니다. 이렇게 정리해두지 않으면 분명 나중에 또 까먹기 때문에, 공식 문서를 보면서 이해한 부분을 정리해두고 나중에 찾아보기 위해 기본 구조와 함께 예제들을 정리해볼 계획입니다. 사실 제가 내부구조를 정확히 아는 것도 아니고, 제 지식의 수준이 매우 얕기 때문에 Spring Security 공식문서에 적혀 있지 않은 내용은 잘못된 정보를 재생산 할 수 있다고 생각했습니다. 따라서 본 포스팅은 거의 Spring Security 6.3.4 레퍼런스 문서를 한글로 의역? 해석? 하는 수준에서 가볍게 봐주시면 좋을 것 같습니다.\nFilter : 공식문서에서도 Spring Security WebMVC의 구조와 관련된 페이지를 가보면, 대부분 필터에 대한 내용입니다. 결국 필터가 어떻게 동작하는지 이해하면 WebMVC에서 Spring Security의 기본 구조와 동작순서를 이해할 수 있기 때문에, 제목은 구조이지만 필터에 대한 설명 위주로 작성했습니다. Spring Reactive에서는 Servlet(WebMVC)에서와 전혀 다르게 동작한다고 하는데, 이 부분은 차후에 다루도록 하겠습니다.\n필터 Java servlet container의 필터 처리과정\n필터는 WebMVC 형태의 WAS를 다뤄보신 분들이라면 다들 사용해 보셨을 것 같습니다.\n사용자의 요청이 Controller(Spring에서는 DispatcherServlet)로 이동하기 전, 해당 요청을 검증하기 위한 단계를 나타냅니다.\n일종의 AOP1라고 할 수 있겠네요.\n필터는 스프링에서만 제공하는게 아닌, 자바 표준으로서 WAS(Servlet Container)에서 사용하기 위한 표준 스펙입니다.\n실제로 자바 표준 스펙에서 기본 제공하는 Filter 인터페이스의 형태는 다음과 같습니다.\npublic interface Filter { default void init(FilterConfig filterConfig) throws ServletException {} void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws IOException, ServletException; default void destroy() {} } doFilter 메소드의 인자를 보시면, 필터 인터페이스를 통해 가능한 역할은 크게 3가지입니다.\nServletRequest : 사용자 요청 검증(URL, Header 등) ServletResponse: 서버 응답 조작(status code, message body 등) FilterChain : 다음 필터로 요청 전송할지, 현재 필터에서 필터링할지 여부 결정 즉, 필터는 사용자 요청을 검증하고, 사전에 응답이 필요하면 세팅한 후 다음 필터로 요청을 전송하거나 필터링하는 일련의 과정이 반복됩니다. 이를 Filter Chaining이라고 표현합니다.\nSpring Security 필터 Spring에서는 자바 표준 필터를 Spring Container2에 호환하기 위해 다양한 기법을 사용합니다.\n아래 DelegatingFilterProxy와 FilterChainProxy는 AOP와 객체지향의 프록시 패턴3을 이해하지 않고 있다면, 조금 이해가 어려울 수 있습니다.\nDelagatingFilterProxy Bean으로 등록된 Filter를 품고 있는 DelegatingFilterProxy\nSpring이 Servlet Container(Java 표준)에서 사용하는 Filter를 Bean으로 등록 및 동작시키기 위한 프록시 객체입니다.\n여기서 Filters 내부의 Filter0, Filter2는 Spring이 관리하는 필터가 아닌 Servlet Container의 필터입니다.\n내부에 Spring Bean으로 등록된 Filter를 가지고 있으며, 해당 Bean에게 요청을 위임하여 동작시킵니다.\nServlet Container에서 사용하는 필터 인터페이스의 동작 사이에 Spring의 Bean을 끼워넣을 수 있는 일종의 JoinPoint4를 만들었다고 생각하시면 좋을 것 같습니다.\nFilterChainProxy Spring에서는 위의 DelegatingFilterProxy에 위임된 Bean Filter를 여러개 묶어서 Chain으로 연결한 것처럼 동작시킵니다. 해당 체인이 Spring Security에서 가장 핵심 로직인 SecurityFilterChain입니다.\nFilterChainProxy은 DelegatingFilterProxy로부터 위임된 필터 작업을 다음에 나올 SecurityFilterChain에게 요청을 위임하기 위한 프록시 객체입니다. SecurityFilterChain Proxy를 통해 SecurityFilterChain에게 요청이 위임됩니다.\n공식문서에서 위의 Proxy들을 언급한 이유는 결국 SecurityFilterChain의 구조를 설명하기 위함입니다.\n위의 그림에서처럼 두 개의 proxy 객체 덕분에 SecurityFilterChain에게 필터링을 위임할 수 있습니다.\n또한, 이러한 요청은 Matcher 로직을 통해 URI Path 기반으로 특정 패턴의 필터에게 요청을 위임하며, 패턴 별로 다른 로직의 필터를 동작시킬 수 있습니다.5\n앞의 필터에서 처리되지 않은 요청들은 모두 마지막 필터(/**)가 처리하겠죠?\n이러한 필터가 적용되는 순서 또한 중요합니다.\n예를 들어, 인가 관련 로직을 처리하기 전에 반드시 인증을 통해 해당 사용자에게 어떤 권한이 있는지를 확인해야 합니다.\n다음 소스코드를 참고하면 각각의 필터들이 내부적으로 어떤 순서로 동작하는지 확인할 수 있습니다. Custom Filter 등록하기 Filter를 구현하는 방법은 다음과 같습니다.\n필터를 상속받는 Bean을 구현합니다.\n이 때, Spring Security에서 제공하는 추상 클래스인 OncePerRequestFilter를 상속받아 사용할 것을 권장하고 있습니다. 해당 추상 클래스의 추상 메서드인 doFilterInternal를 구현하면, 템플릿 메서드 패턴6으로 하나의 요청에서 한번만 실행되는 필터를 생성할 수 있습니다. 당연히 하나의 요청에 한번만 실행되는거 아닌가..?하는 생각이 들어 찾아보니 servlet들끼리 dispatch를 하는 과정에서 여러번 실행될 수 있어 이런 필터를 통해 이번 요청에 이미 필터링을 거쳤는지 확인한다고 합니다.\nSecurityConfig에 등록합니다.\n@Bean SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http // ... .addFilterBefore(new TenantFilter(), AuthorizationFilter.class); return http.build(); } 차후 포스팅에서 실제로 Custom Filter로 JWT 인증 필터를 구현해서 등록해볼 예정입니다.\n결론 스프링에서 사용하는 필터는 자바 표준스펙과 호환되며, 중간에 다양한 기능을 끼워넣기 위해 잘 설계되어 있어 Custom Filter를 쉽게 등록할 수 있다!\n예외처리, 캐싱 관련된 내용도 한번에 작성하려고 했는데, 분량이 너무 길어져서 다음 포스트로 넘기겠습니다.\nReferences Link 게시일자 방문일자 작성자 Spring Security Docs - 2024.11.05. Spring Java Servlet Filter Docs - 2024.11.05. Oracle Spring Security Filter Order Source Code - 2024.11.05. Spring Once Per Request Filter When to Use 2018.03.18. 2024.11.05. StackOverflow Aspect Orient Programming - 관점 지향 프로그래밍 : 특정 로직의 핵심 관점(종단 관심사)과 부가 관점(횡단 관심사)을 나눈 뒤 각각을 모듈화하는 기법을 말합니다. 필터는 핵심 비즈니스 로직 전단계의 전처리 과정을 모듈화하는 Aspect(횡단 관심사)의 일종입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nApplication Context, Bean Factory, Bean Container 혹은 IOC Container라고도 합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nProxy Pattern - 프록시 패턴 : 본인 내부에 다른 객체의 참조를 갖고 있다가, 특정 작업의 요청을 내부 객체에 위임하는 형태의 디자인 패턴입니다. 이를 통해 접근 제어를 하거나 특정 부가기능을 수행할 수 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAspectJ에서 사용하는 개념으로, 횡단 관심사를 처리할 로직을 끼워넣을 지점을 결정합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpring에서는 이러한 SecurityFilterChain을 DelegatingFilterChain이 아닌 FilterChainProxy로 등록하는데, 이는 DelegatingFilterChain을 그대로 사용하면 기존 필터와 동일한 구조로 동작해야 하기 때문이라고 합니다. FilterChainProxy로 등록함으로써 스프링의 다양한 성능 최적화나 메모리 누수 방지 등등의 다양한 동작을 적용할 수 있고, 무엇보다 URL을 보고 필터 동작여부를 결정하는 것이 아니라, RequestMatcher를 활용할 수 있는 것도 FilterChainProxy로서 등록되기 때문이라고 하네요! 기존 로직에 부가기능을 추가한 뒤 다른 객체에게 위임하여 동작시킨다는 측면에서 일종의 데코레이터 패턴이라고 볼 수 있겠네요.\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; Template Method Pattern - 템플릿 메소드 패턴 : 상위 객체의 알고리즘을 하위 객체에서 구현하도록 설계하여 전체 구조를 변경하지 않고 특정 단계의 로직만 변경할 수 있게 합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/spring_security/spring_security_webmvc_base_architecture/","summary":"도입 작성 배경 : 이번 토이프로젝트에서 Spring Security를 다루고 있는데, 기본 개념을 제대로 이해하지 못해서 많은 어려움을 겪었습니다. 이렇게 정리해두지 않으면 분명 나중에 또 까먹기 때문에, 공식 문서를 보면서 이해한 부분을 정리해두고 나중에 찾아보기 위해 기본 구조와 함께 예제들을 정리해볼 계획입니다. 사실 제가 내부구조를 정확히 아는 것도 아니고, 제 지식의 수준이 매우 얕기 때문에 Spring Security 공식문서에 적혀 있지 않은 내용은 잘못된 정보를 재생산 할 수 있다고 생각했습니다. 따라서 본 포스팅은 거의 Spring Security 6.","title":"[Java]Spring Security WebMVC 기본 구조"},{"content":"도입 초심을 잃고 나태해진 자신을 반성하며 블로그를 다시 써보려고 합니다..\n예전에 썼던 글들을 보면서, 그래도 열심히 정리하고 노력했던게 뿌듯하기도 했고, 무엇보다 그동안 계속 속썩이던 구글 검색엔진이 드디어 내 블로그를 크롤링해서 미약하나마 트래픽이 발생했고, 다시 블로깅을 할 의지가 조금 생겼습니다!\n그동안의 행보 싸피를 수료하고, 운좋게도 바로 취업이 되어 8월부터 입사를 하게 되었습니다.\n입사 후에는 그래도 첫 회사라고 나름 의욕도 있었고, 열심히 다니다보니 어느새 블로그 생각은 점점 머릿속에서 사라지고 있었습니다..\n회사까지 출퇴근 거리도 꽤나 멀었고(왕복 4시간\u0026hellip;) 회사에 적응하면서 나름 보탬이 되고자 열심히 배우다보니 조금 현실에 안주했던 것 같습니다.\n평화롭게 회사를 다니던 어느날, 어이없게도 갑작스럽게 회사에서 월급 디폴트 선언1을 하면서 일상이 흔들리기 시작했습니다.\n월급과 희망이 없는 나날들 사실 첫번째 월급날도 입금이 조금 지연되었지만, 일시적이겠거니 했었습니다. 하지만 갑자기 월급이 끊기고, 식권도 끊기고, 기타 수많은 복지들이 사라지는걸 보며 생각보다 보통 일이 아니라는 것을 알게 되었습니다.\n월급이 밀린다는 소식이 전사에 퍼지자, 수많은 개발자분들이 퇴사를 하셨고 대부분의 서비스는 개발이 잠정 중단되었습니다. 사내에서 쓰는 다양한 프레임워크들이 많았는데, 이러한 프레임워크를 유지보수하는 분들도 연락이 잘 안되는 경우도 많았습니다.\n상황이 이러하니 마음잡고 개발을 하는 사람들도 없었고, 이직은 해야겠는데 바깥 시장도 쉽지는 않으니 다들 혼란 속에서 이런저런 유언비어들이 계속 퍼져나갔습니다.\n당연히 신입으로서 뭔가를 배우거나 해볼 수 있는 것도 없었고, 빨리 정리하고 퇴사를 하는게 맞겠다는 생각에 한달 정도 버티던 회사를 결국 퇴사했습니다.\n다시 취준생으로 10월 25일, 이제 3개월도 안된, 중고신입이라고 부르기도 애매한 경력을 가지고 다시 취업시장에 뛰어들게 되었습니다.\n겨우 3개월만에 돌아온 취준 시장은 입사 전보다도 훨씬 무겁고 경직된 느낌이었습니다.\n취준생분들은 공감하시겠지만 이미 레드오션이 된 개발바닥에서 신입은 최소 백준 골드 이상의 문제를 30분 이내에 풀 수 있는 실력과, 현업에 가까운 환경에서 다양한 프로젝트를 하면서 대규모 트래픽까지 경험해야 하는 극한의 능력자들을 가리키는 말이 되었습니다.\n하지만 이런 능력치를 가진 신입이더라도 문제는 뽑는 회사가 없다는 것입니다. 여기저기 플랫폼에는 대부분 3년차 이상의 경력직들만을 모집하고 있었고, 신입을 뽑는 회사는 극히 드물었습니다.\n저도 조금만 일찍 준비했더라면 하반기 공채를 노려볼 수 있었겠지만, 그마저도 거의 끝나나고 있었습니다.\n무엇보다 가장 힘들었던 것은 코딩테스트였습니다. 전역하고부터 싸피 1학기때까지 열심히 풀었던 실력은 다 어디로 갔는지, 쉽게 풀었던 것 같은 문제들도 다시 풀려니 많은 부담이 되었습니다.\n그래서 10월 한달은 코딩테스트만 주구장창 풀었고2, 실력은 조금씩 좋아졌지만 문제는 채용하는 회사가 이미 거의 끝났다는 것입니다.\n앞으로의 계획 위에서는 현재 상황을 조금 비관적으로 얘기한 감이 있지만, 그래도 퇴사 이후 어느정도 안정된 마음이 생기자 다시금 개발이 하고 싶어졌습니다.\n다행히 사이드 프로젝트를 진행중인게 몇 개 있어서 개발의 끈을 놓지는 않고 있습니다. 지금 진행중인 채용 프로세스가 한군데 남았는데 어떻게 될지는 모르겠지만, 내년도에도 개발자로서 계속 도전해볼 생각입니다.\n앞으로의 블로그 계획 뭔가 블로그 계획을 쓰려고 시작한 포스팅이었는데, 신세 한탄만 한 것 같네요\u0026hellip;;\n시간적 여유가 생긴 만큼, 적어도 주 2회는 포스팅 할 수 있도록 블로그도 꾸준히 써 볼 생각입니다.\n일단 사이드 프로젝트를 하면서 접한 스프링 시큐리티 관련 기술들을 패키지로 하나의 포스팅을 해볼 생각입니다. 코딩테스트 문제들도 주 1회 정도씩 괜찮은 문제들을 선별해서 올려보겠습니다. 이후에는 이전 회사에서 프레임워크처럼 만들었던 짭 스프링(?)이 있었는데 해당 프레임워크를 다시 개발해보고, 실제 스프링의 구조와 비교해보면서 조금 깊이있는 주제도 다뤄보고 싶습니다. 그리고 바쁘다는 핑계로 못읽었던 개발 서적들을 요새 열심히 읽고 있는데, 읽으면서 독후감도 계속 써보겠습니다. 올해는 이정도 하면 거의 마무리되지 않을까 싶네요..\n결론 현실에 안주하지 말고 성실히 살자! 기업명은 밝히지 않겠으나, 나름 직원도 많고 신입 초봉도 높은 티어에 속하는 기업이었는데 많이 충격이었습니다\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n10월 초부터 회사 시스템이 거의 붕괴(?)가 되어 출근해서 딱히 업무가 없었고, 코딩테스트를 계속 풀 수 있었습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EA%B0%9C%EB%B0%9C_%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC_%EB%8B%A4%EC%8B%9C_%EC%8B%9C%EC%9E%91%ED%95%98%EB%A9%B0.../","summary":"도입 초심을 잃고 나태해진 자신을 반성하며 블로그를 다시 써보려고 합니다..\n예전에 썼던 글들을 보면서, 그래도 열심히 정리하고 노력했던게 뿌듯하기도 했고, 무엇보다 그동안 계속 속썩이던 구글 검색엔진이 드디어 내 블로그를 크롤링해서 미약하나마 트래픽이 발생했고, 다시 블로깅을 할 의지가 조금 생겼습니다!\n그동안의 행보 싸피를 수료하고, 운좋게도 바로 취업이 되어 8월부터 입사를 하게 되었습니다.\n입사 후에는 그래도 첫 회사라고 나름 의욕도 있었고, 열심히 다니다보니 어느새 블로그 생각은 점점 머릿속에서 사라지고 있었습니다..\n회사까지 출퇴근 거리도 꽤나 멀었고(왕복 4시간\u0026hellip;) 회사에 적응하면서 나름 보탬이 되고자 열심히 배우다보니 조금 현실에 안주했던 것 같습니다.","title":"개발 블로그를 다시 시작하며..."},{"content":"도입 우리가 일상에서 매일 접속하는 인터넷은 전세계의 수많은 사용자가 사용하는 만큼 항상 엄청난 트래픽이 발생합니다. 이러한 트래픽의 가장 중심에는 데이터베이스가 있습니다. 결국 사용자는 데이터베이스를 통해 다양한 정보를 획득합니다.\n이러한 데이터베이스의 성능을 늘리기 위해 개발자들은 다양한 시도를 합니다. 그중에서도 이번에는 데이터베이스 이중화와 CQRS 패턴에 대해 알아보고, 이를 실제로 가상서버 및 코드로 구현해보려 합니다.\nDB 이중화 기법 데이터베이스 이중화에는 다양한 장점이 있습니다. 대표적으로\n장애 대응(Failover) : DB가 1개라면, 해당 DB가 다양한 원인1에 의해 장애가 발생했을 시 서비스 운영이 불가능합니다. DB를 이중화한다면 이러한 장애에 신속히 대응할 수 있으며, 차후 손실된 데이터를 복구하는 것도 가능합니다. 부하 분산(Load Balancing) : 하나의 DB가 받던 부하를 여러 DB로 분산한다면, 병목현상으로 인한 장애를 예방할 수 있을 뿐 아니라, 요청에 대한 신속한 응답을 기대할 수 있습니다. 또한, DB 이중화 기법을 통해 시스템의 두가지 성질을 달성할 수 있습니다.\nHA(High Availability; 고가용성) 시스템을 최대한 중단 시간 없이 운영할 수 있는 특성을 말합니다. HA를 판단하는 기준은 Availability가 있으며, 가용성에 따른 서비스 제공시간2을 계산할 수 있습니다. Availability Downtime per year 90% 36.5일 99.99% 52.6분 99.999% 5분 26초 \u0026hellip; \u0026hellip; 99.9999999% 31.56 밀리초 DR(Disaster Recovery; 재해복구) 자연재해 혹은 인위적 사고로부터 핵심 시스템을 복구하는 절차 혹은 지속성을 말합니다. 이러한 DR의 목표와 실제는 RPO, RTO, RTA로 나뉘게 됩니다. RTO(Recovery Time Objective) : 비즈니스의 지속성을 위한 복구 목표시간입니다. RTA(Recovery Time Actual) : 실제 복구하는데 걸리는 시간입니다. RPO(Recovery Point Objective) : 사고가 발생하면서 실제로 손실이 발생하는 시간입니다. RTO, RPO에 대한 설명\n그럼 이러한 이중화 기법에는 어떠한 것이 있는지 알아보겠습니다.\n사실 인프라나 하드웨어적 측면에서 훨씬 다양한 기법들이 있고, 오늘은 단일 소프트웨어(취준생) 수준의 이중화 기법을 알아보겠습니다.\nReplication 쌍둥이를 만듭니다.\n동일한 데이터를 가지는 복제 데이터베이스를 생성합니다. 마스터(master)와 슬레이브(slave)로 구성되어 슬레이브가 마스터의 데이터를 복제하는 방식으로 동작합니다. Clustering 동일한 작업을 하는 서버를 클러스터로 분리해 가용성을 확보할 수 있습니다.\n동일한 작업을 여러 노드를 통해 수행하는 서비스 방식을 말하며, 동일한 업무를 처리해야 하기에 동일한 정보를 가지고 있어야 합니다. 작업을 분산하거나 동기화하는 과정에서 오버헤드가 발생할 수 있으며, 이러한 작업 스케줄링 및 동기화가 클러스터링에서 해결해야 할 과제입니다. Shading 샤딩은 pk를 분배하는 전략이 중요합니다.\n하나의 작업을 여러 노드에 분산해서 작업하는 서비스 방식을 말합니다. 데이터베이스에서는 데이터를 분산해서 저장하는 방식을 말하며, 이렇게 분산 저장된 데이터를 적절하게 인덱싱하는 것이 중요합니다. Clustering과 헷갈릴 수 있지만, Clustering은 동일한 DB를 여러개 만드는 반면, Shading은 하나의 DB를 쪼개는 방식입니다. Shading은 수평 분할로, 한 테이블의 행을 여러개의 DB로 분리한다고 생각하며 될 것 같습니다.\nCQRS 패턴 지금까지 DB 이중화의 목적과 종류에 대해 알아보았는데요, 그럼 CQRS패턴은 무엇일까요?\n정의 CQRS3패턴은 Command(Create, Update, Delete)와 Query(Read)의 책임을 분리하라는 원칙을 구현한 패턴입니다.\n목적 Command와 Query를 분리하는 이유는 다음과 같습니다.\n읽기와 쓰기의 빈도 차이 : 어플리케이션 로직을 생각해보면, 통상 쓰기보다 읽기가 훨씬 많이 발생합니다. Command와 Query를 분리한다면, Query를 수행하는 DB를 Command용 DB보다 많이 생성함으로써 이러한 비율을 맞춰 서비스를 최적화할 수 있습니다. 확장성 : 위에서 설명한 비율을 고민하며 독립적으로 DB를 확장할 수 있습니다. 트랜잭션 : Command는 데이터를 변경하기에 트랜잭션이 발생하며, Query는 통상 읽기 전용으로 이루어집니다. 트랜잭션을 처리하는 로직이 분리되면 데이터 변경을 위한 로직을 관리하기 쉬워집니다. 보안 : 쓰기 권한을 가진 요청을 통해서만 데이터가 변경되는지 확인하기가 용이해집니다. 구현 이러한 CQRS패턴은 어플리케이션 계층에서도 구현할 수 있지만, 데이터베이스를 분리하여 두 작업을 원천 분리할 수 있습니다.\n그 중 대표적인 방법이 위에서 설명했던 Replication을 응용한 방식입니다. Replication은 위에서 설명한 것처럼 Master DB에서 변경된 데이터를 Slave DB에서 그대로 복제하는 특징을 가지고 있습니다.\n따라서 Command는 Master DB에서 수행하고, Query는 Slave DB에서 수행하는 방식으로 Command와 Query를 분리할 수 있습니다.\n결론 다양한 이점을 가진 DB 이중화의 다양한 방식을 알아보았고, 이를 통해 CQRS 패턴을 구현할 수 있습니다. 다음 시간부터는 MySQL에서 제공하는 Replication기술을 활용해 SpringBoot Server에서 CQRS패턴을 활용하는 예제를 직접 구현해보겠습니다.\n이제야 좀 기술블로그 같은 주제를 다루는 것 같네요. 앞으로도 프로젝트나 다양한 이슈로부터 얻는 노하우와 기술들을 정리해 나가겠습니다.\nReferences URL 게시일자 방문일자 작성자 https://travislife.tistory.com/29 2020.08.03. 2024.03.12. 트레비스의 IT라이프 https://if.kakao.com/ 2022.12.09. 2024.03.12. if-kakao-2022 https://en.wikipedia.org/wiki/Disaster_recovery 2024.03.05. 2024.03.12. wikipedia https://techblog.woowahan.com/2687/ 2020.07.06. 2024.03.12. 송재욱, 전병두 https://learn.microsoft.com/ko-kr/azure/architecture/patterns/cqrs 미등록 2024.03.12. Azure Storage 개발자 혹은 DB관리자의 실수, 정전, 천재지변, 해커의 공격 등 정말 다양한 원인이 있으며 이러한 모든 원인을 회피하는 것은 불가능합니다. 실제로 2022년 10월 15일 발생한 카카오 데이터센터 화재로 1개월 이상 복구작업을 하기도 했습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n고가용성 시스템을 추구하는 Erlang 은 nine nines(99.9999999%)를 달성했다고 하네요.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCommand and Query Responsibility Segregation; 명령과 쿼리 분리의 원칙입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/mysql_springboot_cqrs_%ED%8C%A8%ED%84%B4_%EA%B5%AC%ED%98%84%EC%9D%84_%EC%9C%84%ED%95%9C_db_%EC%9D%B4%EC%A4%91%ED%99%94/db_%EC%9D%B4%EC%A4%91%ED%99%94_%EB%B0%8F_cqrs_%ED%8C%A8%ED%84%B4%EC%9D%98_%EC%A4%91%EC%9A%94%EC%84%B1/","summary":"도입 우리가 일상에서 매일 접속하는 인터넷은 전세계의 수많은 사용자가 사용하는 만큼 항상 엄청난 트래픽이 발생합니다. 이러한 트래픽의 가장 중심에는 데이터베이스가 있습니다. 결국 사용자는 데이터베이스를 통해 다양한 정보를 획득합니다.\n이러한 데이터베이스의 성능을 늘리기 위해 개발자들은 다양한 시도를 합니다. 그중에서도 이번에는 데이터베이스 이중화와 CQRS 패턴에 대해 알아보고, 이를 실제로 가상서버 및 코드로 구현해보려 합니다.\nDB 이중화 기법 데이터베이스 이중화에는 다양한 장점이 있습니다. 대표적으로\n장애 대응(Failover) : DB가 1개라면, 해당 DB가 다양한 원인1에 의해 장애가 발생했을 시 서비스 운영이 불가능합니다.","title":"DB 이중화 및 CQRS 패턴의 중요성"},{"content":"도입 이전 포스팅 참조 : DB 이중화 및 CQRS 패턴의 중요성\n실습환경\nDocker : v25.0.3 MySQL : v8.3.0 시작에 앞서 간단히 Replication의 원리를 확인해보겠습니다.\nSlave DB는 Master DB의 로그파일을 참조하여 변경사항을 업데이트 합니다.\nMaster DB는 데이터 변경사항을 Binary log 파일에 저장합니다. Slave DB는 Binary log 파일의 변경사항을 감시하다가, 변경이 발생하면 해당 로그를 확인합니다. 변경사항을 Relay log파일에 적용합니다. SQL Thread는 Relay log파일의 변경사항을 감시하다가, 변경이 발생하면 DB에 반영합니다. 그럼 이제 본격적으로 MySQL Master DB와 Slave DB를 Docker 이미지로 생성하고, Replication 설정을 통해 Master DB의 변경사항을 Slave DB로 복제하는 실습을 진행하겠습니다.\nMySQL Docker 생성 Docker1를 통해 가상 OS에 2개(Master, Slave)의 MySQL 서버를 생성해보겠습니다.\nMySQL Docker 이미지 다운로드 Docker 이미지 경로에서 다운로드 받거나, 아래 명령어를 shell에서 사용합니다. docker pull mysql:8.3.0 Master DB 생성 Master DB를 다운로드 받은 Docker Image를 통해 생성하겠습니다.\n포트는 3307 포트를 사용하겠습니다.\n환경변수2에 주의해서 명령어를 입력해주세요.\ndocker run -it --name mysql_master -p 3307:3307 -e MYSQL_ROOT_PASSWORD=1234 -e MYSQL_DATABASE=target_db -e MYSQL_USER=master_user -e MYSQL_PASSWORD=1234 -d mysql:8.3.0 --log-bin=master-bin --server-id=1 --port=3307 --default_authentication_plugin=mysql_native_password # 붙여넣기를 위해 줄바꿈을 하지 않았습니다. 환경변수와 설정에 대한 자세한 설명은 아래나 공식문서 참고해주세요. # -e MYSQL_ROOT_PASSWORD : 루트 계정의 비밀번호를 설정합니다. # -e MYSQL_DATABASE : 해당 이름의 데이터베이스를 생성합니다. # -e MYSQL_USER : 해당 유저를 생성합니다. # -e MYSQL_PASSWORD : 해당 유저의 비밀번호를 설정합니다. # --log-bin : 변경사항을 저장할 바이너리 로그파일의 이름을 설정합니다. # --server-id : 서버 식별자를 사용합니다. 통상 master id를 1, 나머지 id를 2 ~ 2^32-1로 설정하면 됩니다. # --port : MySQL을 실행할 컨테이너 내부 포트 주소를 변경합니다. # --default_authentication_plugin : 접속 시 암호화된 비밀번호를 사용할지 여부를 결정합니다. 위와 같이 설정하면 암호화를 사용하지 않습니다. # 공식문서 : https://hub.docker.com/_/mysql Slave DB 생성 Slave DB의 내부 데이터베이스는 Master DB를 복제하기 때문에 동일한 이름으로 지정해야 합니다.\n포트는 3308 포트를 사용하겠습니다.\ndocker run -it --name mysql_slave -p 3308:3308 -e MYSQL_ROOT_PASSWORD=1234 -e MYSQL_DATABASE=target_db -e MYSQL_USER=slave_user -e MYSQL_PASSWORD=1234 -d mysql:8.3.0 --log-bin=master-bin --server-id=2 --read-only=1 --port=3308 --default_authentication_plugin=mysql_native_password # --read-only=1 : 읽기전용 DB로 설정하여 Master DB와의 데이터 정합성이 깨지지 않도록 합니다. Master DB 설정 Slave DB가 Master DB의 정보를 받아오기 위해서는 Master 계정을 설정하고 로그파일을 확인해주어야 합니다.\n계정 생성 및 권한 설정 Slave DB를 연결하려면 Master DB에서 Master 계정을 생성한 후 외부 접근 권한을 가능하도록 변경해야 합니다.\nContainer 내부로 접근\ndocker exec -it mysql_master /bin/bash MySQL root 계정에 접속\nmysql -u root -p # 1234 입력 Master 계정 권한 변경\nGRANT REPLICATION SLAVE ON *.* TO \u0026#39;master_user\u0026#39;@\u0026#39;%\u0026#39;; 로그파일 확인 이제 Master DB에서 변경사항이 발생하면 자동으로 업데이트 되는 로그파일을 확인해보겠습니다.\nSlave DB에서 해당 파일을 모니터링하기 때문에, 해당 파일의 이름과 포지션 값을 연동해야 합니다.\nSHOW MASTER STATUS\\G; # +-------------------+----------+--------------+------------------+-------------------+ # | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | # +-------------------+----------+--------------+------------------+-------------------+ # | master-bin.000003 | 385 | | | | # +-------------------+----------+--------------+------------------+-------------------+ # 상태메시지 중 {File명}과 {Position} 확인 후 별도 저장 Docker IP주소 확인 Replication 설정 전에 Master DB의 Docker IP 주소를 확인해야 합니다.\nmysql, Container 종료\nexit #Bye exit #exit Docker inspect를 통해 컨테이너 IP주소 확인\ndocker inspect mysql_master #...(생략) # \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34;, # \u0026#34;GlobalIPv6Address\u0026#34;: \u0026#34;\u0026#34;, # \u0026#34;GlobalIPv6PrefixLen\u0026#34;: 0, # \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.2\u0026#34; #...(생략) Slave DB 설정 그럼 이제 Slave DB가 Master DB의 Log파일을 참조하도록 설정해보겠습니다.\nReplication 설정 Slave DB에 접속해서 Replication 설정을 합니다.\n(master에 접속한 터미널은 그대로 두고, 별도의 터미널을 실행하시는 것을 권장합니다.)\nContainer 내부로 접근\ndocker exec -it mysql_slave /bin/bash MySQL root 계정에 접속\nmysql -u root -p # 1234 입력 slave 설정은 root 권한이 필요합니다.\nReplication 설정을 합니다. 이 때, 쉼표와 자료형 문법에 주의해야 합니다.3\nmysql\u0026gt; CHANGE REPLICATION SOURCE TO # 위에서 확인한 Master DB docker 내부주소를 입력합니다. mysql\u0026gt; SOURCE_HOST=\u0026#39;{Master DB docker 내부주소}\u0026#39;, mysql\u0026gt; SOURCE_PORT=3307, mysql\u0026gt; SOURCE_USER=\u0026#39;master_user\u0026#39;, mysql\u0026gt; SOURCE_PASSWORD=\u0026#39;1234\u0026#39;, # 아까 확인한 바이너리 로그파일의 이름 및 포지션을 적어야 합니다. mysql\u0026gt; SOURCE_LOG_FILE=\u0026#39;{File명}\u0026#39;, mysql\u0026gt; SOURCE_LOG_POS={Position}; Replication 동작을 시작합니다.\nmysql\u0026gt; START SLAVE; # 만약 replication 설정을 변경하려면 \u0026#39;STOP SLAVE;\u0026#39;로 동작을 종료한 후 위 명령어를 통해 변경해야 합니다. 연결 완료여부 확인 이제 Slave 설정이 정상적으로 완료되었는지 확인해보겠습니다.\nSHOW SLAVE STATUS\\G; # +----------------------------------+-------------+-------------+-------------+---------------+-------------------+---------------------+-------------------------------+---------------+-----------------------+------------------+-------------------+-----------------+---------------------+--------------------+------------------------+-------------------------+-----------------------------+------------+------------+--------------+---------------------+-----------------+-----------------+----------------+---------------+--------------------+--------------------+--------------------+-----------------+-------------------+----------------+-----------------------+-------------------------------+---------------+---------------+----------------+----------------+-----------------------------+------------------+--------------------------------------+-------------------------+-----------+---------------------+----------------------------------------------------------+--------------------+-------------+-------------------------+--------------------------+----------------+--------------------+--------------------+-------------------+---------------+----------------------+--------------+--------------------+------------------------+-----------------------+-------------------+ #| Slave_IO_State | Master_Host | Master_User | Master_Port | Connect_Retry | Master_Log_File | Read_Master_Log_Pos | Relay_Log_File | Relay_Log_Pos | Relay_Master_Log_File | Slave_IO_Running | Slave_SQL_Running | Replicate_Do_DB | Replicate_Ignore_DB | Replicate_Do_Table | Replicate_Ignore_Table | Replicate_Wild_Do_Table | Replicate_Wild_Ignore_Table | Last_Errno | Last_Error | Skip_Counter | Exec_Master_Log_Pos | Relay_Log_Space | Until_Condition | Until_Log_File | Until_Log_Pos | Master_SSL_Allowed | Master_SSL_CA_File | Master_SSL_CA_Path | Master_SSL_Cert | Master_SSL_Cipher | Master_SSL_Key | Seconds_Behind_Master | Master_SSL_Verify_Server_Cert | Last_IO_Errno | Last_IO_Error | Last_SQL_Errno | Last_SQL_Error | Replicate_Ignore_Server_Ids | Master_Server_Id | Master_UUID | Master_Info_File | SQL_Delay | SQL_Remaining_Delay | Slave_SQL_Running_State | Master_Retry_Count | Master_Bind | Last_IO_Error_Timestamp | Last_SQL_Error_Timestamp | Master_SSL_Crl | Master_SSL_Crlpath | Retrieved_Gtid_Set | Executed_Gtid_Set | Auto_Position | Replicate_Rewrite_DB | Channel_Name | Master_TLS_Version | Master_public_key_path | Get_master_public_key | Network_Namespace | #+----------------------------------+-------------+-------------+-------------+---------------+-------------------+---------------------+-------------------------------+---------------+-----------------------+------------------+-------------------+-----------------+---------------------+--------------------+------------------------+-------------------------+-----------------------------+------------+------------+--------------+---------------------+-----------------+-----------------+----------------+---------------+--------------------+--------------------+--------------------+-----------------+-------------------+----------------+-----------------------+-------------------------------+---------------+---------------+----------------+----------------+-----------------------------+------------------+--------------------------------------+-------------------------+-----------+---------------------+----------------------------------------------------------+--------------------+-------------+-------------------------+--------------------------+----------------+--------------------+--------------------+-------------------+---------------+----------------------+--------------+--------------------+------------------------+-----------------------+-------------------+ #| Waiting for source to send event | 172.17.0.2 | master_user | 3307 | 60 | master-bin.000003 | 901 | a25cfc1154fc-relay-bin.000002 | 845 | master-bin.000003 | Yes | Yes | | | | | | | 0 | | 0 | 901 | 1063 | None | | 0 | No | | | | | | 0 | No | 0 | | 0 | | | 1 | fb49312a-e4e3-11ee-a432-0242ac110002 | mysql.slave_master_info | 0 | NULL | Replica has read all relay log; waiting for more updates | 10 | | | | | | | | 0 | | | | | 0 | | #+----------------------------------+-------------+-------------+-------------+---------------+-------------------+---------------------+-------------------------------+---------------+-----------------------+------------------+-------------------+-----------------+---------------------+--------------------+------------------------+-------------------------+-----------------------------+------------+------------+--------------+---------------------+-----------------+-----------------+----------------+---------------+--------------------+--------------------+--------------------+-----------------+-------------------+----------------+-----------------------+-------------------------------+---------------+---------------+----------------+----------------+-----------------------------+------------------+--------------------------------------+-------------------------+-----------+---------------------+----------------------------------------------------------+--------------------+-------------+-------------------------+--------------------------+----------------+--------------------+--------------------+-------------------+---------------+----------------------+--------------+--------------------+------------------------+-----------------------+-------------------+ Last_Error 메시지가 없고, Slave_SQL_Running_State에 \u0026lsquo;Replica has read all relay log; waiting for more updates\u0026rsquo; 라고 되어있으면 성공적으로 연결된 상태입니다.\nMaster DB에서 해당 DB에 Table을 생성하고, 컬럼을 추가해보겠습니다.\nContainer 내부로 접근\ndocker exec -it mysql_master /bin/bash MySQL master 계정에 접속\nmysql -u master_user -p # 1234 입력 테이블 및 컬럼 추가\n# master shell mysql\u0026gt; USE target_db; mysql\u0026gt; CREATE TABLE test(id int, name varchar(10)); mysql\u0026gt; INSERT INTO test(id, name) VALUES(1, \u0026#39;leaf\u0026#39;); Slave DB에서 해당 변경사항을 인식하는지 확인해보겠습니다.\nContainer 내부로 접근\ndocker exec -it mysql_slave /bin/bash MySQL slave 계정에 접속\nmysql -u slave_user -p # 1234 입력 컬럼 확인\n# slave shell mysql\u0026gt; USE target_db; mysql\u0026gt; SELECT * FROM test; # +------+------+ # | id | name | # +------+------+ # | 1 | leaf | # +------+------+ # 1 row in set (0.00 sec) # 위와 같이 테이블 및 컬럼이 정상 조회되면 성공입니다. 결론 지금까지 Mysql과 Docker로 Replication을 구현하여 DB를 이중화 해보았습니다.\n다음 시간에는 Master, Slave DB를 SpringBoot와 Datasource로 연동하여 Application 내부에서 CRUD를 수행해 보겠습니다.\nReferences URL 게시일자 방문일자 작성자 https://dev.mysql.com/doc/refman/8.0/en/replication.html - 2024.03.13. MySQL https://hub.docker.com/_/mysql - 2024.03.13. MySQL Docker는 가상화된 컨테이너를 생성 및 관리해주는 프로그램입니다. Docker가 설치되지 않았다면, Docker 홈페이지를 통해 Docker Desktop을 설치 후 진행해주세요.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n전체 환경변수는 Docker 문서에서 확인하실 수 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMySQL문법과 동일하게 값(컬럼) 사이에는 쉼표를 적고, 정수형(Integer)은 따옴표를 적지 않으며 문자형(varchar)은 따옴표를 명시해야 MySQL이 해당 구문을 인식합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/mysql_springboot_cqrs_%ED%8C%A8%ED%84%B4_%EA%B5%AC%ED%98%84%EC%9D%84_%EC%9C%84%ED%95%9C_db_%EC%9D%B4%EC%A4%91%ED%99%94/mysql_replication_database_%EA%B5%AC%ED%98%84/","summary":"도입 이전 포스팅 참조 : DB 이중화 및 CQRS 패턴의 중요성\n실습환경\nDocker : v25.0.3 MySQL : v8.3.0 시작에 앞서 간단히 Replication의 원리를 확인해보겠습니다.\nSlave DB는 Master DB의 로그파일을 참조하여 변경사항을 업데이트 합니다.\nMaster DB는 데이터 변경사항을 Binary log 파일에 저장합니다. Slave DB는 Binary log 파일의 변경사항을 감시하다가, 변경이 발생하면 해당 로그를 확인합니다. 변경사항을 Relay log파일에 적용합니다. SQL Thread는 Relay log파일의 변경사항을 감시하다가, 변경이 발생하면 DB에 반영합니다. 그럼 이제 본격적으로 MySQL Master DB와 Slave DB를 Docker 이미지로 생성하고, Replication 설정을 통해 Master DB의 변경사항을 Slave DB로 복제하는 실습을 진행하겠습니다.","title":"[MySQL]Replication Database 구현"},{"content":"도입 미루고 미루던 블로그를 이제야 만들었다. 사실 내가 블로그를 쓰게 될 것이라고는 전혀 생각지도 못했지만, 이왕 시작한거 열심히 써보려고 한다.\n첫 협업과 위키페이지 작성 블로그를 쓰게 된 가장 큰 계기는 첫 프로젝트에서 처음으로 협업을 하면서 느꼈던 생각들이었다.\n같은 팀원들끼리 공유해야 할 것도 많았고, 팀장으로서 소통의 창구가 필요한 것도 느끼고 있었기에 처음에는 짧은 지식으로나마 직접 위키페이지를 만들었다.\n(Vue.js로 로컬에서 라이브 서버를 띄워놓음\u0026hellip;)\n처음에는 나름 잘 만들었다고 뿌듯해 했지만,\n로컬에서만 작동하는 부분(같은 네트워크 대역을 쓸때만 접속이 가능) 수정사항이나 새로운 요구사항이 발생할 때마다 변경이 힘듦 팀원들도 사실 많이 이용하지는 않았는지 별로 피드백이 없었음 위의 이유(핑계)들로 프로젝트가 바빠지면서 점차 소홀히 관리하게 되었다.\n첫 실패와 다짐 EC2 서버에 별도로 포트를 잡아 해당 페이지를 올려버릴까도 생각했었지만, 변경내역 관리나 빌드 등에 공수가 너무 들 것 같아 포기했었다.\n하지만 프로젝트가 진행되면서 전역적인 설정이나 참고할만한 내용들을 올리는 창구는 통일되지 않았고, 비슷한 문제를 여러 번 설명하는 과정에서 확실히 시행착오들을 한군데에 정리해 둘 필요성이 있겠다는 생각이 들었다.\n또한, 나중에 어떤 기술을 잘 모르는 사람들에게 내가 쓴 블로그의 글과 함께 설명한다면, 훨씬 이해를 도울 수 있겠다는 것도 이유 중 하나였다.\n당시의 생각들과 실패를 반면교사 삼아, 이번에 마음먹고 며칠 고생해서 깃블로그를 만들었다. 아직 부족한 부분이 많지만 개선해나가는 과정에서 많이 배울 수 있을 것 같아 기대도 된다. 그리고 이렇게 내 지식을 정리하면서 느끼는 것은, 정리하거나 누군가에게 설명해보지 않고서는 내가 어떤 걸 알고 어떤 걸 정말 모르는지 판단하기 어렵다는 것이다.\n앞으로의 계획 기술 블로그 우선, 개발자로 진로를 굳힌 만큼 내 기술과 지식, 시행착오들을 잘 정리해두려고 한다. 나도 물론 참고하겠지만, 다른 사람들에게도 조금이나마 도움이 되기를 바라는 마음이다. 오픈소스의 첫 발걸음을 뗀 것 같아 설레는 마음도 있다.\nLanguages JAVA\n자바에 대해 기초를 배우기는 했지만, java8 이후부터 변경된 사항과 좀더 깊은 부분들은 아직 많이 부족하다는 것을 코드를 짜면서도 많이 느낀다. 가급적 많은 사람들에게 도움이 될 수 있도록 시행착오나, 정말 필요한 내용들에 대해서 정리해보려고 한다.\nOthers\n패러다임은 바뀌고 프로그래밍 언어는 계속 출시된다. 언젠가 자바와 스프링도 도태될 것이고, 더욱 멋지고 빠른 언어들이 계속 등장할 것이다. 다양한 언어가 있겠지만, 당장 알아보고 싶은건 Kotlin과 Elixir이다. 지금까지 배운 언어들도 정말 훌륭하고 멋진 기능들을 제공했지만, 똑똑한 개발자들이 만든 다른 언어들이 얼마나 대단한 기능을 제공할지 벌써 기대가 된다.\nSpring\n이 블로그 이름에서도 알 수 있듯이, 스프링은 나에게 많은 영감과 배움의 기회를 주었다. 스프링을 좀 더 깊이 알면 알수록, 객체지향에도 한발짝 다가가는 기분이 든다.\n스프링의 내부적인 동작들도 궁금하고, 특히 요즘은 스프링이 제공하는 어노테이션의 한계\n(ex. bean은 최대 얼마나 등록 가능한지, 이떄 어플리케이션에 부하가 어느정도 되는지)\n도 궁금해져서 언젠가 연구하고 정리해보고 싶다.\nDatabase\n아직 데이터베이스에 대한 지식은 정말 부족하다. JPA가 정말 너무 많이 도와주다보니 오히려 DB에 대해 너무 모르게 된 것이 아닌가 하는 생각도 든다.\n어차피 백엔드 개발자라면 결국 데이터와의 싸움을 하게 될 텐데, 나중에 후회하기 전에 미리 공부해두고 싶다.\nAlgorithm\n결국 컴퓨터와 대화를 잘하려면 그들의 생각을 배울 필요가 있다. 아직 부족하지만, 조금씩 알고리즘 문제도 풀면서 논리적인 사고를 하는 습관을 계속 익혀야겠다. 가능할지는 모르겠지만, 객체지향적으로 인터페이스를 설계하고 클래스를 구현하는 방식으로 알고리즘 문제를 푸는 시도도 해보고 싶다.\nDesign Pattern\n구조와 패턴을 잘 아는것은 그만큼 코드를 보는 눈을 넓혀주는 것 같다. 디자인 패턴에 대해 공부하고, 특히 실제로 어디에서 쓰이고 있는지 정리해보고 싶다.\nArchitecture\n코드를 짜면서 항상 잘 짜고 있는지 의구심이 들었다. 좋은 코드와 좋은 설계가 무엇인지 공부하고 실제로 코드에 적용하면서 배우는 시간을 가져볼 예정이다.\nCommunications\n군에 있을때부터 지독하게 얽혀있던 통신, 항상 어렵고 항상 모르겠지만 이제는 뭔가 익숙하다못해 친밀한 느낌마저도 든다. 나름 내 인생에 많은 부분을 차지했던 분야인만큼 잘 정리해두면 많은 사람들에게 도움이 될 수 있을 것 같다.\nInfrastructure\n인프라는 모든 서비스들이 제대로 동작하는 토대가 된다. 그만큼 중요한 분야이기 때문에 소홀히 할 수 없고, 트렌드도 자주 바뀌는만큼 계속 관심갖고 지켜볼 필요가 있을 것 같다.\nSecurity\n보안도 군에서부터 많이 따라다녔던 녀석이지만, 바쁘고 귀찮다는 핑계로 많이 소홀히 한적도 있었다. 배우면 배울수록 절대 소홀히 할 수 없는 부분이라고 생각해서 계속 공부해 나가려고 한다.\nEtc\n더 많은 분야들이 있겠지만, 우선 위의 분야들 위주로 정리해나가고자 한다. 하지만 스스로도 너무 여기저기 기웃거리는 타입임을 잘 아는지라 언제 새로운 태그가 생길런지는 모르겠다.\n취미 블로그 Diary or Plan\n매일 일기를 쓰는건 힘들겠지만, 주에 1번 혹은 달에 한번이라도 일기를 적어보려고 한다. 내 생각을 정리하는데 글쓰기 만큼 좋은것도 없는 것 같다. 그리고 앞으로의 계획이나 생각 등도 한곳에 정리해두고 싶다.\nCube\n요새 왜인지는 모르겠는데 어려서 했던 큐브가 재미있어서 조금씩 정리해보려고 한다. 너무 많은 시간을 뺏는 취미는 아니니까 시간날때 조금씩 하는 정도는 괜찮겠지..\n결론 프로젝트를 하면서 블로그의 필요성을 진득하게 느껴서 다양한 분야의 기술을 한곳에 정리하는 개발 블로그를 운영해보려 한다.\n🔥 시작은 미미하지만 많은 사람들이 믿고 찾아볼 수 있는 위키가 될 수 있도록 꾸준히 노력하자.\n","permalink":"https://1eaf.site/posts/%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC_%EC%93%B0%EA%B2%8C_%EB%90%9C_%EA%B3%84%EA%B8%B0%EC%99%80_%EC%95%9E%EC%9C%BC%EB%A1%9C%EC%9D%98_%EB%B0%A9%ED%96%A5%EC%84%B1_240228/","summary":"도입 미루고 미루던 블로그를 이제야 만들었다. 사실 내가 블로그를 쓰게 될 것이라고는 전혀 생각지도 못했지만, 이왕 시작한거 열심히 써보려고 한다.\n첫 협업과 위키페이지 작성 블로그를 쓰게 된 가장 큰 계기는 첫 프로젝트에서 처음으로 협업을 하면서 느꼈던 생각들이었다.\n같은 팀원들끼리 공유해야 할 것도 많았고, 팀장으로서 소통의 창구가 필요한 것도 느끼고 있었기에 처음에는 짧은 지식으로나마 직접 위키페이지를 만들었다.\n(Vue.js로 로컬에서 라이브 서버를 띄워놓음\u0026hellip;)\n처음에는 나름 잘 만들었다고 뿌듯해 했지만,\n로컬에서만 작동하는 부분(같은 네트워크 대역을 쓸때만 접속이 가능) 수정사항이나 새로운 요구사항이 발생할 때마다 변경이 힘듦 팀원들도 사실 많이 이용하지는 않았는지 별로 피드백이 없었음 위의 이유(핑계)들로 프로젝트가 바빠지면서 점차 소홀히 관리하게 되었다.","title":"블로그를 쓰게 된 계기와 앞으로의 방향성"},{"content":"도입 이전 포스팅 참조 : DB 이중화 및 CQRS 패턴의 중요성 \u0026gt; MySQL Replication Database 구현\n실습환경\nDocker : v25.0.3 MySQL : v8.3.0 Java : v17.0.9 Spring : v3.2.4 저번 시간에 생성한 Master / Slave DB에 SpringBoot를 직접 연동해서 CRUD를 하는 실습을 진행합니다.\n프로젝트 생성 Springboot 프로젝트를 생성합니다. 아래 사진과 같이 JPA, Lombok, MySQL Driver 의존성을 추가하겠습니다. 스프링부트 프로젝트를 위와 같이 의존성을 추가하여 생성합니다.\nbuild.gradle 실행 위에서 생성한 프로젝트의 jar파일을 풀고, build.gradle 파일을 intellij 혹은 eclipse로 실행합니다. gradle로 프로젝트를 실행하면 자동으로 소스파일 경로가 생성됩니다.\nJpaConfig 클래스 생성 원래 스프링부트에 JPA 의존성을 추가하면 기본으로 설정된 DataSource를 불러와 사용하지만, 저번 시간에 분리한 Command(쓰기)와 Query(읽기) DB를 DataSource로 사용하기 위해 다음과 같이 JpaConfig를 설정하겠습니다.\npackage com.replication.demo.config; // config 패키지 생성 import org.springframework.context.annotation.Configuration; @Configuration // Spring에 자동으로 Bean을 등록하기 위함 public class JpaConfig {} DataSource 구현 JpaConfig내부에 DataSource를 Bean으로 등록하면, 이후 Spring이 해당 Bean의 설정을 통해 DataSource를 생성하므로 편리하게 DB에 접근할 수 있습니다.\n두 개의 DataSource를 각각 구현하고, Transaction시점에 필요한 DataSource를 결정할 수 있도록 Spring에서는 AbstractRoutingDataSource라는 추상클래스를 제공합니다.\nCommand \u0026amp; Read DataSource Bean 생성 우선, 쓰기와 읽기 DataSource를 다음과 같이 JpaConfig 내부에서 Bean으로 등록합니다.\n@Configuration public class JpaConfig { @Bean(\u0026#34;commandDataSource\u0026#34;) // 원본 DB와 연결된 DataSource public DataSource commandDataSource() { HikariDataSource dataSource = DataSourceBuilder.create() .driverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;) .url(\u0026#34;jdbc:mysql://localhost:3307/target_db\u0026#34;) .username(\u0026#34;master_user\u0026#34;) .password(\u0026#34;1234\u0026#34;) .type(HikariDataSource.class) .build(); dataSource.setMaximumPoolSize(2); // Pool Size도 설정 가능합니다. return dataSource; } @Bean(\u0026#34;queryDataSource\u0026#34;) // Repl DB와 연결된 DataSource public DataSource queryDataSource() { HikariDataSource dataSource = DataSourceBuilder.create() .driverClassName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;) .url(\u0026#34;jdbc:mysql://localhost:3308/target_db\u0026#34;) .username(\u0026#34;slave_user\u0026#34;) .password(\u0026#34;1234\u0026#34;) .type(HikariDataSource.class) .build(); dataSource.setMaximumPoolSize(5); // 보통 읽기전용 작업이 더 많기 때문에 크게 설정하겠습니다. } } jdbc에서 사용하는 port 및 username과 password는 저번 시간에 생성한 DB 환경변수를 참고하시면 됩니다.\nRoutingDataSource 구현 읽기전용 트랜잭션인지 여부에 따라 동적으로 DataSource를 사용해야 하므로, 스프링에게 트랜잭션 시점에 해당 작업에 대해 알려주고, 필요한 DataSource를 동적으로 불러오도록 해야 합니다.\n이를 위해 다음과 같이 추상 클래스인 AbstractRoutingDataSource를 상속받는 사용자 정의 클래스를 생성합니다.\n@Slf4j // AbstractRoutingDataSource 구현 public static class ReplicationRoutingDataSource extends AbstractRoutingDataSource { @Override protected Object determineCurrentLookupKey() { boolean isReadOnly = TransactionSynchronizationManager.isCurrentTransactionReadOnly(); log.info(\u0026#34;Use ReadOnly Datasource : {}\u0026#34;, isReadOnly); return isReadOnly ? \u0026#34;replication\u0026#34; : \u0026#34;original\u0026#34;; } } 위 설정에서 determineCurrentLookupKey 메서드를 구현하면 동적으로 DataSource를 라우팅하는 것이 가능한데, 그 key를 TransactionSynchronizationManager1의 속성값(isCurrentTransactionReadOnly; 현재 트랜잭션이 읽기전용인지?)으로 사용해서 DataSource를 읽기 / 쓰기 시점에 결정합니다.\n다음으로 위 클래스를 활용해서 실제로 DataSource를 결정 후 해당 DataSource를 Bean으로 등록합니다.\nReplicationRoutingDataSource 클래스는 AbstractRoutingDataSource를 상속받고 있기 때문에 해당 추상클래스의 메서드를 사용가능하여 다음과 같이 ReadOnly 여부에 따른 데이터소스를 설정하는 것이 가능합니다.\nReadOnly여부는 @Transactional(readOnly = true)인지를 확인하여 결정됩니다. 이 때, org.springframework.transaction.annotation.Transactional을 사용해야 함을 주의합니다. (jakarta.transactional 아님!!)\n@Bean(\u0026#34;routingDataSource\u0026#34;) // DataSource 종류에 따른 DataSource 라우팅(변경) public DataSource routingDataSource(@Qualifier(\u0026#34;commandDataSource\u0026#34;) DataSource commandDataSource, @Qualifier(\u0026#34;queryDataSource\u0026#34;) DataSource queryDataSource) { ReplicationRoutingDataSource routingDataSource = new ReplicationRoutingDataSource(); // DataSource 라우팅 Map\u0026lt;Object, Object\u0026gt; dataSourceMap = new HashMap\u0026lt;\u0026gt;(); dataSourceMap.put(\u0026#34;command\u0026#34;, commandDataSource); dataSourceMap.put(\u0026#34;query\u0026#34;, queryDataSource); // 기본 DataSource 및 ReadOnly 여부에 따른 DataSource 설정 routingDataSource.setDefaultTargetDataSource(commandDataSource); // commandDataSource를 기본 사용 routingDataSource.setTargetDataSources(dataSourceMap); // ReadOnly여부에 따른 DataSource 변경 return routingDataSource; } 다음으로 위의 Bean을 LazyConnectionDataSourceProxy으로 감싸는데, 이는 트랜잭션 진입 시점이 아닌 실제 커넥션이 필요한 시점2에 DataSource를 결정하기 위함입니다.\n@Bean(\u0026#34;routingLazyDataSource\u0026#34;) // Connection 시점에 DataSource 결정하기 위한 Proxy public DataSource routingLazyDataSource(@Qualifier(\u0026#34;routingDataSource\u0026#34;) DataSource routingDataSource) { return new LazyConnectionDataSourceProxy(routingDataSource); } EntityManagerFactory 구현 Spring에서는 트랜잭션의 동시성 문제3를 해결하기 위해 EntityManager를 트랜잭션 시마다 생성하는 Factory Method 패턴을 구현하고 있습니다. 이를 위해 저희도 EntityManagerFactory에 위에서 설정한 DataSource를 직접 주입함으로써 동시성 문제를 해결할 수 있습니다.\n@Bean(\u0026#34;entityManagerFactory\u0026#34;) // Entity 를 관리하기 위한 JPA Manager 설정 LocalContainerEntityManagerFactoryBean entityManagerFactory( @Qualifier(\u0026#34;routingLazyDataSource\u0026#34;) DataSource dataSource) { LocalContainerEntityManagerFactoryBean emf = new LocalContainerEntityManagerFactoryBean(); // DataSource 설정 emf.setDataSource(dataSource); // EntityManager 가 관리할 Base Package 설정 emf.setPackagesToScan(\u0026#34;com.replication.demo.*\u0026#34;); // Hibernate Vendor Adaptor 설정 HibernateJpaVendorAdapter hibernateJpaVendorAdapter = new HibernateJpaVendorAdapter(); hibernateJpaVendorAdapter.setDatabasePlatform(\u0026#34;org.hibernate.dialect.MySQLDialect\u0026#34;); emf.setJpaVendorAdapter(hibernateJpaVendorAdapter); // JPA 및 Hibernate 설정 Properties properties = new Properties(); properties.setProperty(\u0026#34;spring.jpa.hibernate.ddl-auto\u0026#34;, \u0026#34;create-drop\u0026#34;); properties.setProperty(\u0026#34;hibernate.show_sql\u0026#34;,\u0026#34;true\u0026#34;); properties.setProperty(\u0026#34;hibernate.format_sql\u0026#34;,\u0026#34;true\u0026#34;); properties.setProperty(\u0026#34;hibernate.default_batch_fetch_size\u0026#34;, \u0026#34;100\u0026#34;); emf.setJpaProperties(properties); return emf; } Vendor Adaptor는 JPA 구현체를 선택하기 위함이며, 보통 Hibernate를 많이 사용합니다.4 기타 JPA 및 Hibernate 설정은 JPA 공식 문서와 Hibernate 공식 문서에서 더욱 자세한 옵션과 설명을 확인하실 수 있습니다.\nTransactionManager 구현 Spring에서 @Transactional를 통해 트랜잭션이 발생하면, Spring Container에서 TransactinManager를 불러와 트랜잭션을 수행합니다. 이 때, 위에서 구현한 DataSource와 EntityManager를 사용해서 트랜잭션을 수행하도록 하겠습니다.\n@Bean(\u0026#34;transactionManager\u0026#34;) // 트랜잭션 매니저 설정 public PlatformTransactionManager transactionManager( @Qualifier(\u0026#34;entityManagerFactory\u0026#34;) EntityManagerFactory entityManagerFactory) { JpaTransactionManager jpaTransactionManager = new JpaTransactionManager(); jpaTransactionManager.setEntityManagerFactory(entityManagerFactory); return jpaTransactionManager; } PlatformTransactionManager는 다양한 플랫폼의 트랜잭션을 지원하기 위한 클래스이며, 위에서는 JpaTransactionManager를 사용했지만 HibernateTransactionManager나 JdbcTransactionManager등의 플랫폼도 사용 가능합니다.\n테스트 이제 Config 설정이 완료되었으니, 직접 Test를 통해 원하는 기능이 제대로 실행되는지 확인해보겠습니다.\nEntity 생성 테스트코드를 작성하기 전, DB에 저장할 엔티티 클래스를 먼저 생성하겠습니다.\nUser Entity 생성\npackage com.replication.demo.entity; import jakarta.persistence.*; import lombok.*; import java.util.List; @Entity(name = \u0026#34;users\u0026#34;) @NoArgsConstructor @Getter @Setter public class User { @Id @GeneratedValue @Column(name = \u0026#34;user_id\u0026#34;) private Long id; private String name; private Integer age; @OneToMany(mappedBy = \u0026#34;owner\u0026#34;) private List\u0026lt;Computer\u0026gt; computers; } Computer Entity 생성\npackage com.replication.demo.entity; import jakarta.persistence.*; import lombok.Getter; import lombok.NoArgsConstructor; import lombok.Setter; @Entity(name = \u0026#34;computer\u0026#34;) @NoArgsConstructor @Getter @Setter public class Computer { @Id @GeneratedValue @Column(name = \u0026#34;computer_id\u0026#34;) private Long id; @Enumerated(EnumType.STRING) private ComputerType type; @Column(name = \u0026#34;os\u0026#34;) private String OS; @ManyToOne @JoinColumn(name = \u0026#34;owner_id\u0026#34;) private User owner; } Computer Type 생성\npackage com.replication.demo.entity; public enum ComputerType { MAC, WINDOW, LINUX } 테스트코드 작성 마지막으로, 테스트코드를 통해 Command(readOnly = false) 트랜잭션과 Query(readOnly = true) 트랜잭션을 분리하여 정상적으로 조회되는지 확인해보겠습니다.\npackage com.replication.demo; import com.replication.demo.entity.Computer; import com.replication.demo.entity.ComputerType; import com.replication.demo.entity.User; import jakarta.persistence.EntityManager; import jakarta.persistence.PersistenceContext; import org.junit.jupiter.api.*; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.annotation.Rollback; import org.springframework.transaction.annotation.Transactional; import java.util.ArrayList; import java.util.List; import static org.assertj.core.api.Assertions.assertThat; @SpringBootTest @TestMethodOrder(MethodOrderer.OrderAnnotation.class) class DemoApplicationTests { @PersistenceContext EntityManager em; @Test @Order(1) void contextLoads() { } @Test @Order(2) @DisplayName(\u0026#34;최초 데이터 입력\u0026#34;) @Transactional(readOnly = false) @Rollback(value = false) void init() { // 사용자 생성 User user = new User(); user.setAge(28); user.setName(\u0026#34;leaf\u0026#34;); // 컴퓨터 1 생성 및 저장 List\u0026lt;Computer\u0026gt; computers = new ArrayList\u0026lt;\u0026gt;(); Computer macCom = new Computer(); macCom.setOS(\u0026#34;Ventura\u0026#34;); macCom.setType(ComputerType.MAC); macCom.setOwner(user); computers.add(macCom); em.persist(macCom); // 컴퓨터 2 생성 및 저장 Computer windowCom = new Computer(); windowCom.setOS(\u0026#34;WINDOW 11\u0026#34;); windowCom.setType(ComputerType.WINDOW); windowCom.setOwner(user); computers.add(windowCom); em.persist(windowCom); // 컴퓨터 사용자에 추가 후 사용자 저장 user.setComputers(computers); em.persist(user); em.flush(); em.clear(); } @Test @Order(3) @DisplayName(\u0026#34;사용자 조회 시 컴퓨터 잘 불러오는지 테스트\u0026#34;) @Transactional(readOnly = true) void userQueryWithComputer() { // given List\u0026lt;User\u0026gt; users = em.createQuery( \u0026#34;select u \u0026#34; + \u0026#34;from users as u \u0026#34; + \u0026#34;join u.computers as c\u0026#34;, User.class) .getResultList(); // when User userInDB = users.get(0); // then // 사용자명, 나이 테스트 assertThat(userInDB.getName()).isEqualTo(\u0026#34;leaf\u0026#34;); assertThat(userInDB.getAge()).isEqualTo(28); assertThat(userInDB.getComputers()).hasSize(2); // 맥북 컴퓨터 가지고 있는지 테스트 assertThat(userInDB.getComputers()).anyMatch(c -\u0026gt; c.getOS().equals(\u0026#34;Ventura\u0026#34;)); assertThat(userInDB.getComputers()).anyMatch(c -\u0026gt; c.getType().equals(ComputerType.MAC)); // 윈도우 컴퓨터 가지고 있는지 테스트 assertThat(userInDB.getComputers()).anyMatch(c -\u0026gt; c.getOS().equals(\u0026#34;WINDOW 11\u0026#34;)); assertThat(userInDB.getComputers()).anyMatch(c -\u0026gt; c.getType().equals(ComputerType.WINDOW)); } } @RollBack(false)를 통해 롤백을 방지한 후 다음 테스트가 실행되도록 설계했습니다.5\n테스트 실행결과, 위와 같이 데이터소스 선택 및 실제 SQL이 잘 나가는 것을 확인할 수 있습니다.\n결론 지금까지 이중화된 DB의 데이터소스를 SpringBoot에서 동적으로 선택하여 실제 DB와 연동 후 테스트까지 수행했습니다. 해당 프로젝트의 소스코드는 깃허브에 올려두었으니, 필요 시 참고하시기 바랍니다.\nReferences URL 게시일자 방문일자 작성자 https://docs.spring.io/spring-data/relational/reference/jdbc/getting-started.html 미확인 2024.03.31. Spring https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#appendix.application-properties.data 미확인 2024.04.10. Spring https://stackoverflow.com/questions/24643863/is-entitymanager-really-thread-safe 2014.07.09. 2024.04.10. Ken Y-N 트랜잭션 동기화 기법을 사용하기 위한 클래스입니다. 보통 여러 트랜잭션을 한번에 커밋 및 롤백하여 정합성을 보장하기 위해 사용합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n특히 Hibernate의 영속성 컨텍스트와 같은 1차 캐시를 사용할 경우, DataSource 접근이 필요하지 않지만 @Transactional로 인해 불필요한 커넥션이 발생하게 됩니다. LazyConnectionDataSourceProxy으로 Proxy객체를 사용할 경우 실제로 Connection이 필요한 시점에 DataSource에 접근하기 때문에 성능상 이점이 많습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEntity Manager는 Thread-Safe하지 않기 때문에, Factory를 통해 필요 시점에 새로운 Entity Manager를 생성해서 활용해야 합니다. 해당 StackOverflow를 읽어보시면, 이 때 주입되는 Entity Manager는 Proxy형태로, 실제 트랜잭션 시점에 진짜 Entity Manager로 대체되기 때문에 Thread-Safe 할 수 있다고 합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n참고로 JPA의 EntityManagerFactory대신 Hibernate의 SessionFactory를 구현하는 방법도 있지만, 이는 JPA의 구현체에 의존하므로 좋지 않은 것 같습니다(DIP 위반). 하지만 Hibernate만의 특정 기술을 사용해야만 하는 상황에서는 SessionFactory를 구현 후 TransactionManager에 HibernateTransactionManager를 사용하시면 될 것 같습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n원래는 @BeforeEach 를 사용하여 DB를 초기화하면 되지만, 트랜잭션 범위 설정이 클래스 단위로 제한되어 @Transactional(readOnly = true)를 지정하면 init() 메서드에 @Transactional(readOnly = false)를 설정해도 DB에 값이 반영되지 않는 문제가 발생했습니다. 하는 수 없이 위와 같은 방식으로 설계했습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/mysql_springboot_cqrs_%ED%8C%A8%ED%84%B4_%EA%B5%AC%ED%98%84%EC%9D%84_%EC%9C%84%ED%95%9C_db_%EC%9D%B4%EC%A4%91%ED%99%94/springboot_datasource_%EC%9D%B4%EC%A4%91%ED%99%94cqrs-%ED%8C%A8%ED%84%B4_%EA%B5%AC%ED%98%84/","summary":"도입 이전 포스팅 참조 : DB 이중화 및 CQRS 패턴의 중요성 \u0026gt; MySQL Replication Database 구현\n실습환경\nDocker : v25.0.3 MySQL : v8.3.0 Java : v17.0.9 Spring : v3.2.4 저번 시간에 생성한 Master / Slave DB에 SpringBoot를 직접 연동해서 CRUD를 하는 실습을 진행합니다.\n프로젝트 생성 Springboot 프로젝트를 생성합니다. 아래 사진과 같이 JPA, Lombok, MySQL Driver 의존성을 추가하겠습니다. 스프링부트 프로젝트를 위와 같이 의존성을 추가하여 생성합니다.\nbuild.gradle 실행 위에서 생성한 프로젝트의 jar파일을 풀고, build.","title":"[Java]SpringBoot DataSource 이중화(CQRS 패턴) 구현"},{"content":"도입 처음 개발 블로그를 만들려고 했을때 찾아보니, 국내에서 많이 사용하는 개발 블로그에는 3가지 종류가 있었습니다.\nvelog tistory github 각각의 장단점을 살펴보고, 제가 깃허브 블로그를 선택한 이유에 대해서 설명하려고 합니다.\nvelog velopert(김민준) 님께서 개발하신 개발 블로그입니다. 플랫폼이 개발 블로그에 특화되어 있고, UI도 깔끔해서 블로깅을 할때 1순위로 고민되는 옵션입니다.\n장점 간편한 사용법과 블로깅\n사용법이 간편해서 블로깅에만 편하게 집중할 수 있습니다. 처음 블로깅을 시작하거나, 머리아픈 것을 싫어한다면 가장 추천되는 블로그인 이유입니다. 불필요한 옵션 및 세팅 최소화\n1번과도 연결되는 부분인데, 별다른 옵션이나 기능이 없어서 다른 고민을 할 필요가 없습니다. 처음 글을 작성하면 별다른 세팅 없이도 조회수나 댓글 등을 쉽게 확인 가능합니다. 다양한 개발자들의 생태계 구축\n훌륭한 개발자분들께서 이미 좋은 글들을 많이 남겨주고 계시고, 커뮤니티처럼 본인만의 의견이나 짤, 드립들도 심심치 않게 올라옵니다. 개발 커뮤니티답게 업계의 좋은 정보들도 많이 얻을 수 있고, 다른 분들의 글을 보며 좋은 자극을 받을 수 있습니다. 단점 적은 옵션과 선택폭, 획일화된 디자인\n사실 장점 1, 2번에서 필연적으로 발생하는 단점입니다. 세팅이 간편하고 접근성이 쉬운 만큼, 개발자 본인이 선택할 수 있는 옵션은 많지 않습니다. 본인만의 블로그로 커스터마이징 하고 싶다면 한계가 있는 부분은 사실입니다. 또한, UI가 기본적으로 예쁘기는 하지만 본인만의 스타일이나 방향성 등을 보여주기는 힘듭니다. 게시글 기능에만 초점이 맞춰져 있기도 하고, 세팅할 수 있는 요소가 거의 없어 velog의 스타일로 획일화되는 것 같습니다. 광고 불가능\n기본적으로 velopert님이 운영하시는 블로그이다 보니 광고를 통해 수익을 얻는 것이 불가능합니다. 광고수익을 기대하는 분들이 velog를 주저하는 이유 중 하나일 것 같습니다. 통계 기능\n본인이 작성한 게시물에 대한 조회수나 좋아요 등에 대한 개수정도만 확인 가능하여 구체적인 통계 시스템을 구축하는 것은 힘들어 보입니다. 개인 블로그에 대해 좀더 철저히 관리하고 싶으면 망설여지는 부분입니다. tistory kakao에서 운영하는 블로그입니다. 2006년이라는 오랜 세월동안 국내의 메이저 블로그로 자리잡았고, 다양한 분야의 블로그와 본인만의 커스터마이징이 장점입니다.\n장점 자유로운 스킨 편집\n개발자라면 기본적인 마크업 언어는 많이 접해보셨을 것입니다. 마크업 언어를 통한 스킨편집을 지원하기 때문에 본인만의 스타일로 블로그를 꾸밀 수 있습니다. 특히 블로깅을 잘 하시는 분들을 보면 티스토리 블로그인지 깃허브 블로그인지 헷갈릴 정도로 예쁘게 커스터마이징한 블로그를 심심치 않게 볼 수 있습니다. 소통 및 통계 기능\n기본적으로 댓글이나 구독 등 다른 사용자와의 소통을 위한 기능이 잘 되어 있습니다. 또한, 방문자에 대한 통계와 유입 경로 등을 상세히 분석할 수 있어 본인의 블로그를 확장하는데 많은 도움을 얻을 수 있습니다. 구글 애드센스 등 수익모델과의 연동\n구글 애드센스나 카카오 애드핏 등 광고 서비스와 쉽게 연동이 가능합니다. 광고를 통해 수익을 얻으시려는 분들은 많이 고민하게 되는 옵션 중 하나일 것 같습니다. 실제로 찾아보니 네이버 블로그보다 광고 연동이 잘 되어 티스토리를 사용한다는 분들도 많이 접할 수 있었습니다. 단점 지나친 광고노출\n공부를 하기 위해 다른 티스토리 블로그에 들어가보면, 점점 광고가 많아지는 것 같은 느낌을 받습니다. 특히 어떤 블로그는 다른 탭이나 어플리케이션으로 이동했다가 돌아오면 전체화면을 가려버리는 악성 모달창(?)이 뜨기도 합니다. 이러한 광고 기능으로 인해 순수하게 정보 공유 목적으로 블로그를 운영하거나 정보를 얻으려는 사람들은 불편함을 느낄 것 같습니다. 블로그 관리 의존성\n블로그 관리가 티스토리 고객센터에서 이루어지다 보니 결국 블로그의 생존성도 티스토리 고객센터에 의존하게 됩니다. 특정 게시글에 비정상적인 트래픽 용량이 발생하거나 신고를 많이 받은 블로그는 차단당한다는 글도 많이 보았습니다. 실제로 고객센터에서도 일일히 관리하기가 힘들다보니 일단 제재를 받기 시작하면 소명 등의 절차가 까다롭고 본인의 포스팅을 지키기가 어렵다고 합니다. 많은 사용자에 따른 보안 및 기타 이슈\n개인적인 파일이나 정보 등을 함부로 블로그에 올리면 안되겠지만, 본인의 개인정보가 많은 사람들이 사용하고 어떤 정책으로 관리될지 모를 티스토리 서버의 db로 전송된다는 부분은 찝찝합니다. (사실 깃허브나 여타 블로그도 서버에 파일이 올라가는건 똑같긴 하지만, 티스토리는 좀더 많은 사람이 사용하다 보니 불안한 감이 있습니다.) 그리고 국내에서 많은 트래픽이 발생하는 메이저 포털인 만큼, 여러 사람들에게 포스팅이 노출될 것이고 필연적으로 불필요한 충돌이나 문제(도배나 악성댓글 등)가 발생할 수도 있을 것 같습니다. github 장점 극강의 자유도, 확장의 용이성\n모든 기능을 커스터마이징 할 수 있습니다. 애초에 html을 만들어서 올려야 하기 때문에, html 형식을 벗어나지만 않는다면 모든 뷰를 수정할 수 있습니다. 특히 css를 잘 다룬다면, 본인만의 개성있는 포트폴리오 페이지를 제공하기에는 안성맞춤입니다. 또한, 기능을 확장하려면 본인이 해당 기능을 직접 구현하거나, 외부 라이브러리 의존을 통해 구현할 수 있습니다. 최초에는 기능이 없었지만, 다양한 기능을 직접 추가하거나 삭제할 수 있습니다. 레포지토리와의 연동\n정적 페이지 빌드를 위해 기본적으로 깃허브에 커밋을 해야 합니다. 커밋 기록 (잔디) 도 남길 수 있고, 무엇보다 깃허브가 제공하는 모든 버전관리, 이슈 트래킹 등을 그대로 사용할 수 있다는 점이 매력적입니다. 경험\n사실 개발자로서 본인만의 페이지를 운영하는 경험은 향후 많은 도움이 될 것입니다. 직접 페이지를 빌드하거나 수정하고, 다른 유저의 피드백을 받고, 어떻게 하면 나의 페이지를 노출할 수 있을지 고민하는 일련의 과정이 개발자의 현업과도 일맥상통하는 부분이 있습니다. 단점 초기 진입장벽\n모든 기능을 구현할 수 있다는 것은 반대로 말하면 모든 기능을 알아야 한다는 것입니다. 마크업 언어에 대한 이해는 기본이고, 각종 기능의 내부적인 기능을 알아야 구현이 가능하여 초기 세팅이나 공부하는 과정에서 많은 시간이 걸립니다. 오버헤드\n단지 블로그 글을 작성하고 싶을 뿐인데, 수행하는 과정이 정말 많습니다. 로컬에서 글을 작성하고, (템플릿 프레임워크를 쓴다면)로컬 서버에서 확인 후 빌드하고, 깃에 커밋까지 해야 등록이 됩니다. 또한, 깃이 이를 연동하는데 최소 1분정도는 소요되어 직접 결과를 확인하는데에도 많은 시간이 걸립니다. 초기 유입과 확장\n다른 플랫폼에 비해 새로운 도메인에서 시작하다보니, 초기에 다른 사람들과 소통하기가 쉽지 않습니다. 당장 이 글을 쓰는 저도 제 글을 얼마나 읽어주실지 잘 모르겠습니다. 어느 정도 트래픽이 발생하기 위해서는 꾸준한 관리와 노력이 필요할 것 같습니다. 개발 블로그 선택 저는 위의 장단점을 분석하면서 결국 깃허브 블로그를 운영하기로 마음먹었습니다.\n어차피 개발공부를 해야 했고, 나중에 현업이나 프로젝트에서 마주칠 문제라면 차라리 혼자 공부하면서 미리 부딪혀 보는게 낫겠다는 생각이었습니다.\n그리고 아직은 많은 사람들이 사용하는 블로그에 글을 작성하기에는 제 비루한 실력이 노출되는 부분도 걱정이 되었습니다.\n마지막으로, 백엔드 개발자로서 수정에는 닫혀있고 확장에는 열려있는 구조 1 를 선택하지 않을 수 없었습니다. (무엇보다 간지가 납니다.)\n결론 velog, tistory, github 블로그를 비교해본 결과, 저는 깃허브 블로그를 사용하기로 마음먹었습니다. 다음 포스팅에서는 여러 SSG(Static Site Generator) 도구 중 hugo를 도입하게 된 배경과 간략한 소개, 그리고 설치방법에 대해 알아보겠습니다.\nReferences OCP(Open Close Principal; 개방 폐쇄의 원칙)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EC%A2%8C%EC%B6%A9%EC%9A%B0%EB%8F%8C_%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EC%83%9D%EC%84%B1%EA%B8%B0/%EA%B0%9C%EB%B0%9C_%EB%B8%94%EB%A1%9C%EA%B7%B8%EC%9D%98_%EC%A2%85%EB%A5%98%EC%99%80_%EC%84%A0%ED%83%9D/","summary":"도입 처음 개발 블로그를 만들려고 했을때 찾아보니, 국내에서 많이 사용하는 개발 블로그에는 3가지 종류가 있었습니다.\nvelog tistory github 각각의 장단점을 살펴보고, 제가 깃허브 블로그를 선택한 이유에 대해서 설명하려고 합니다.\nvelog velopert(김민준) 님께서 개발하신 개발 블로그입니다. 플랫폼이 개발 블로그에 특화되어 있고, UI도 깔끔해서 블로깅을 할때 1순위로 고민되는 옵션입니다.\n장점 간편한 사용법과 블로깅\n사용법이 간편해서 블로깅에만 편하게 집중할 수 있습니다. 처음 블로깅을 시작하거나, 머리아픈 것을 싫어한다면 가장 추천되는 블로그인 이유입니다. 불필요한 옵션 및 세팅 최소화","title":"개발 블로그의 종류와 선택"},{"content":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여 \u0026gt; HUGO 기본 설치 및 사용법 \u0026gt; Git 연동과 정적 페이지 배포\n저번 포스팅까지 블로그를 만들어봤는데요, 댓글이 없으니 뭔가 허전한 느낌입니다. 원래 블로그는 다른 사람과의 소통을 위함이니까요.\n이번 시간에는 블로그 댓글을 생성하는 라이브러리들을 비교해보고, 그중 utterances를 직접 블로그에 적용해 보겠습니다.\n저도 처음에는 어떻게 댓글을 구현할까 하다가, 직접 기능을 만들어보려고도 생각했었습니다. 하지만, 그럼 로그인 기능이나 댓글을 저장하는 DB도 만들어야 하는데 블로그 만드는 것보다 더 많은 노력이 필요할 것 같았습니다. 여기저기 찾아보니 댓글을 구현해주는 다양한 라이브러리가 있어 다행히 쉽게 적용할 수 있었습니다.\n블로그 댓글 구현방법 비교 블로그 종류가 다양한 만큼, 블로그 댓글을 구현하는 방법도 다양합니다.\n그럼 댓글 구현방법에 대한 각각의 장단점을 알아보겠습니다.\nDisqus Disqus는 댓글을 쉽게 구현하도록 도와주는 프레임워크입니다. Disqus 내부에 서버가 있어 댓글을 작성하면 해당 서버에 댓글을 작성하고 불러오는 방식으로 구현됩니다.\n또한, Hugo에서 공식적으로 지원하는 댓글 기능이기도 합니다.1\nHugo 문서에 나와있는 것처럼 config에 Disqus 이름(shortname)을 작성하면 쉽게 연동이 가능합니다.\nservices: disqus: shortname: your-disqus-shortname 장점\nHugo에서 기본으로 지원하는 기능인 만큼 연동성이 좋습니다. 다른 사이트에 남긴 댓글들을 모아서 한번에 조회가 가능하며, 댓글 추이나 통계에 대한 분석도 제공합니다.2 사용자가 많고 특히 해외에서는 해당 서비스 사용자가 많은 것 같습니다. 단점\n댓글을 남기기 위해서는 사용자가 해당 서비스에 가입해야 합니다. 현재까지 유효한 정책인지는 모르겠지만, 과거에는 2년 이상 사용 시 과금을 했다고 합니다. 서비스 기업이다 보니 차후에 요금정책이 변경될 가능성도 있을 것 같습니다. 마찬가지로 해당 서비스가 종료되면 댓글도 사라질 위험이 있습니다. 저는 다른것보다 사용자가 새로운 회원가입을 해야 하는 부분에 불편함이 있을 것 같아 다른 옵션을 찾아보게 되었습니다.\nCommento Commento는 가벼움과 프라이버시에 초점을 맞춘 댓글 플랫폼입니다. Commento 또한 해외에서 많이 사용하는 옵션 중 하나입니다. Commento와 Disqus 사이에 고민하는 포스팅을 많이 볼 수 있었습니다.3\n장점\n프라이버시를 보장하기 위한 익명 댓글 기능이 있습니다. 클라우드 서버나 사용자 DB에 연결되어 댓글이 저장되기 때문에 유실 걱정이 없습니다. 제 기준에서는 UI나 디자인이 제일 깔끔한 것 같습니다. Comment Demo 페이지, 이미지를 누르면 해당 데모 페이지로 이동합니다.\n단점\n클라우드 서비스 사용시 요금 정책이 있습니다. 현재 날짜 기준 월 10$, 연 99$입니다. 클라우드 서비스나 DB에 등록하는 과정이 조금 복잡합니다. 도메인별로 클라우드 서버를 설정하기 때문에 댓글 공유는 되지 않습니다. 요금은 클라우드 서비스를 사용하기 위해 어쩔 수 없이 내야하는 부분인 것 같고, 직접 DB를 구현하면 무료라고 합니다. 저는 차후 블로그 유저가 많아지거나, utterances가 불편한 점이 생기면 commento를 도입해볼 생각도 있습니다.\nUtterances 제 블로그에 도입해서 사용하고 있는 Utterances 입니다.\n작동 원리는 깃허브 issue에 댓글을 남기고 트래킹하는 방식으로 구현이 되어있습니다.\n정말 똑똑한 사람들이 많습니다. 여담이지만 utteranc.es라는 url 정말 잘 만든 것 같습니다.\n코드 한 줄만 추가하면 바로 사용할 수 있어 가볍고 깃허브 아이디만 있으면 쉽게 댓글을 달 수 있습니다.\n장점\n방문자도 깃허브 계정만 있으면 댓글을 남기는 것이 가능합니다. script 기반으로 설치 및 구현이 쉽습니다. 깃허브 이슈와 연동되기 때문에 별도의 저장공간이 불필요합니다. 단점\n이슈번호와 연결이 잘못되면 다른 글에 남긴 댓글이 보이는 등 이상현상이 발생한다고 하네요.(아직 댓글이 없어서 직접 확인은 못했습니다.) 깃허브가 없는 일반 사용자는 댓글을 남길 수 없습니다. css를 설정하지 못하고 정해진 테마(9개) 중 선택해야 합니다.(css 테마가 필요하면 직접 구현해서 오픈소스에 기여해달라고 하네요..) 어차피 깃허브 블로그인 이상 제 블로그의 생명주기는 깃허브와 같아졌으므로, utterances가 가장 합리적인 선택으로 보였습니다. 사용해보고 문제가 있다면 다른 댓글 플랫폼도 사용해보고 싶네요.\nUtterances 설치방법 설치를 시작하기에 앞서 Utterances에서 댓글이 구현되는 원리를 간단히 알아보자면 다음과 같습니다.\nUtterances Bot이 깃허브 앱에 등록이 되고, 사용자가 작성한 스크립트로 페이지에 불러와집니다. 해당 스트립트에 표기된 깃허브 레포지토리에서 현재 페이지에 맞는 댓글을 불러옵니다. 댓글 작성버튼을 누르면 레포지토리에 현재 페이지의 정보와 함께 댓글을 저장합니다. 심플하면서도 깃허브 페이지에 아주 효과적인 전략인 것 같습니다. 그럼 이제 본격적으로 Utterances를 설치해보겠습니다.\nUtterances 기본설정 먼저 Utterances 홈페이지에 들어가서 설정을 해야 합니다. 해당 페이지에 들어가시면 configuration탭이 있는데, 딱 4가지 설정만 하시면 됩니다.\n레포지토리 입력(필수)\n먼저 해당 댓글을 사용할 레포지토리를 입력합니다. 본인의 블로그 레포지토리가 될 수도 있고, 별도의 댓글만 저장하기 위한 전용 레포지토리를 생성하셔도 좋습니다.\n저는 정적 페이지를 위한 레포지토리를 분리해두었기 때문에 해당 레포지토리를 그대로 사용했습니다.\n[1] 레포지토리를 입력합니다.\n이슈 매핑방법(필수)\nUtterances Bot이 깃허브 이슈에 댓글을 저장하고, 불러오기 위해서는 해당 이슈가 어떤 포스트에 해당하는지를 알아야 합니다.\n이를 위해 깃허브 이슈와 댓글을 어떻게 매핑할지 6가지 전략을 선택할 수 있습니다.\n실제로 Utterances로 댓글을 남기면 해당 전략에 따라 레포지토리 이슈에 저장이 되므로 본인이 관리하기 편한 방식을 선택하시는게 좋습니다.\npathname : 현재 페이지의 url 중 경로명을 기반으로 댓글을 저장 및 탐색합니다. 처음에 해당 방식을 사용했는데, 경로명에 한글이 포함되어있으면 utf-8로 인코딩 된 경로가 나오게 되어 나중에 알아보기가 힘들어 title로 변경했습니다.\nURL : url을 기반으로 댓글을 저장 및 탐색합니다. pathname과 다르게 전체 url경로를 모두 사용합니다.\ntitle : 포스팅 제목을 기반으로 댓글을 저장 및 탐색합니다.\nog:title : Open Graph4의 메타 필드를 참조해서 댓글을 저장 및 탐색합니다.\nissue number : 이슈번호를 특정할 수 있습니다. 이슈가 자동생성되지 않아 미리 이슈를 만들어 두고 직접 연결해야 합니다.\nspecific term : 이슈를 탐색할 때 설정한 특정 키워드를 포함하는지 확인합니다. 5번과 유사하지만 처음 댓글을 달면 해당 키워드를 포함하여 자동으로 이슈를 생성해줍니다.\n[2] 매핑전략을 선택합니다.\n이슈 라벨 설정(선택)\n필수는 아니지만 이슈 앞에 부착할 라벨을 설정할 수 있습니다. 만약 이슈와 댓글을 동시에 사용하는 페이지가 있다면 이를 구분할 때 편리할 듯 합니다.\n💬 와 같은 이모지도 넣을 수 있다고 하네요.\n[3] 이슈 라벨을 선택합니다.\n테마 설정(필수) 마지막으로 테마(댓글 템플릿)를 설정해야 합니다. utteranc.es 페이지에서 테마를 선택하면 자동으로 해당 테마에 맞게 페이지가 변경되니, 해당 페이지를 보고 본인의 블로그와 맞는 페이지를 선택하시면 될 것 같습니다.\n[4] 이슈 테마를 선택합니다.\n이제 Utterances 설정이 끝났습니다. 모든 설정을 마치면 다음과 같이 스크립트를 복사할 수 있습니다.\n스크립트 태그를 복사합니다.\nHugo 템플릿 설정 모든 설정이 끝났다면, 해당 설정정보를 블로그로 불러와야 합니다. 저는 Hugo를 사용하고 있기 때문에 Hugo에서 설정하는 방법을 설명드리겠습니다.\n다른 정적 페이지를 사용하신다면 해당 페이지의 html 중 댓글이 필요한 위치에 script를 불러오시면 됩니다.\nHugo에서 댓글을 적용하시려면 우선 Hugo가 어떻게 페이지를 렌더링하는지 이해해야 합니다.5 위 주석을 참고하시면 Hugo의 페이지 렌더링 순서는 다음과 같습니다.\n사용자가 설정한 특정 레이아웃 사용자가 설정한 기본 레이아웃 테마에 설정된 특정 레이아웃 테마에 설정된 기본 레이아웃 저는 PaperMod라는 테마를 사용하고 있습니다. 따라서 댓글을 화면에 표시하기 위해서는 제가 직접 레이아웃 폴더를 생성해서 PaperMod의 Comment 레이아웃(comments.html)을 Override6해주어야 합니다.\n따라서 다음과 같이 새로운 폴더와 comments.html 파일을 생성합니다.\n... ├── README.md ├── archetypes ├── config │ └── _default │ └── hugo.yaml ├── content ├── layouts # layouts 디렉터리를 생성합니다. │ └── partials # partials 디렉터리를 생성합니다. │ └── comments.html # comments.html을 생성하고, 내부에 아래 주석 내용을 붙여넣기합니다. ├── public ├── resources └── themes └── PaperMod # [붙여넣기] comments.html : PaperMod에서 제공하는 기본 템플릿입니다. {{- /* Comments area start */ -}} {{- /* to add comments read =\u0026gt; https://gohugo.io/content-management/comments/ */ -}} {{- /* Comments area end */ -}} 위에서 생성한 comments.html 파일 내부에 아까 생성했던 utterances script 태그를 복사하면 완료입니다.\n{{- /* Comments area start */ -}} # utterances script를 여기에 붙여넣습니다. {{- /* Comments area end */ -}} 다른 Hugo 테마를 사용하신다면, 테마 폴더 내부의 layouts를 찾아보시면 Comments가 구현되어 있으실텐데 해당 파일을 가져오시면 됩니다.\n테마에 Comments가 구현되어 있지 않다면 Hugo 사이트를 참고해서 직접 레이아웃을 구현하셔야 합니다.\nGithub App 등록 Utterances가 레포지토리의 이슈에 접근하려면 깃허브 앱으로 등록해야 합니다. Utterances App 페이지에서 설치가 가능합니다.\n참고로 아래 사진과 같이 댓글을 저장할 레포지토리만 등록하시면 잘 작동합니다.\n필요한 레포지토리만 등록하시면 됩니다.\nCanonical Path 설정 처음 Utterances를 적용하시면 아마 다음 페이지와 같이 로그인하라는 창이 나오실겁니다.\n로그인이 필요합니다.\n로그인 과정은 다음과 같습니다.\n로그인 버튼을 클릭하면 현재 페이지에서 Github의 OAuth 서비스 페이지로 이동합니다. 인증이 완료되면 Github에서 인증 토큰을 발급합니다. Utterances Bot이 해당 토큰을 통해 아까 설정한 레포지토리로 접근합니다. 레포지토리에 접근이 가능해지면 현재 페이지와 레포지토리를 연결한 후, 현재 페이지로 복귀합니다. 이 과정에서 Utterances Bot은 Canonical Path7를 통해 현재 페이지를 인식하게 됩니다.\n그러나 Canonical Path가 제대로 설정되어 있지 않다면, Utterance Bot이 해당 페이지를 인식하지 못합니다. 따라서 Canonical Path를 올바르게 설정해서 Utterance Bot이 다시 해당 페이지로 찾아올 수 있도록 합니다.\n이러한 Canonical Path는 head에 링크 태그로 생성됩니다.\nCanonical Path를 설정하는 방법은 테마마다 달라서 저는 PaperMod 테마 기준으로 설명드리겠습니다.\nPaperMod 테마의 layouts \u0026gt; partials \u0026gt; head.html 템플릿을 확인해보면 다음과 같이 canonical path가 생성됨을 알 수 있습니다.\n// CanonicalURL이 있으면 그걸로 생성, 아니면 Permalink로 생성 \u0026lt;link rel=\u0026#34;canonical\u0026#34; href=\u0026#34;{{ if .Params.canonicalURL -}} {{ trim .Params.canonicalURL \u0026#34; \u0026#34; }} {{- else -}} {{ .Permalink }} {{- end }}\u0026#34;\u0026gt; 따라서 hugo 설정파일 내부에 Params.canonicalURL 설정이 있다면 해당 설정을 통해 canonicalURL을 생성하고, 그렇지 않으면 Permalink8를 따라간다는 것을 알 수 있습니다.\nPermalink는 설정파일의 BaseURL에 현재 콘텐츠의 경로를 붙여서 생성됩니다.\n{{ with resources.Get \u0026#34;images/a.jpg\u0026#34; }} {{ .Permalink }} → https://example.org/images/a.jpg {{ end }} 콘텐츠 경로는 hugo가 빌드하는 과정에서 잘 세팅이 되기 때문에 BaseURL만 해당 블로그의 기본주소로 잘 설정하면 정확한 canonicalURL을 얻을 수 있습니다.\n따라서 기본 설정파일(hugo.yaml or hugo.toml or config.yaml)의 BaseURL을 현재 블로그 페이지의 기본주소로 잘 설정해주어야 합니다.\n# hugo.toml 혹은 hugo.yaml baseURL: \u0026#34;https://{github계정명}.github.io/\u0026#34; # yaml 형식일 경우 baseURL = \u0026#39;https://{github계정명}.github.io/\u0026#39; # toml 형식일 경우 여기까지 설정하셨으면 Github OAuth를 통해 로그인이 잘 되실겁니다.\n결론 오늘은 깃허브 블로그 댓글을 구현하는 다양한 방법에 대해 알아보고, 그 중 Utterances를 통해 직접 구현해보았습니다. 다들 본인만의 블로그를 만드시는데 조금이나마 도움이 되었으면 좋겠습니다.\n앞으로도 Hugo 블로그에 관련한 다양한 세팅에 대해 다뤄볼 예정이니 필요하거나 궁금한 부분이 있으시다면 알려주세요.\n블로그 글이 너무 길어져버렸네요. 앞으로는 배경 설명과 직접 구현하는 포스팅을 잘 분리해야 할 것 같습니다..\nReferences URL 게시일자 방문일자 작성자 https://gohugo.io/ 미등록 2024.03.07. Hugo Authors https://disqus.com/ 미등록 2024.03.07. 2024 Disqus https://docs.commento.io/ 미등록 2024.03.07. Commento https://utteranc.es/ 미등록 2024.03.07. Utterances https://stackshare.io/stackups/commento-vs-disqus 미등록 2024.03.07. Stackshare Hugo의 문서를 보면 공식적으로 Disqus를 지원하고 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDisqus의 다양한 장점은 해당 페이지에서 확인할 수 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCommento vs Disqus\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOpen Graph는 검색엔진이나 SNS 등에서 해당 페이지에 접속하기 전에 대략적인 페이지 구성 등을 확인할 수 있도록 해주는 프로토콜입니다. \u0026#160;\u0026#x21a9;\u0026#xfe0e;\n어떤 템플릿이 렌더링될까?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n자바를 사용해보신 분들은 잘 아시겠지만 덮어쓰기한다는 뜻입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n한 페이지를 이동할 수 있는 여러 개의 URL이 있을때, Bot들이 참고해서 올 수 있는 공식 경로를 뜻합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n자세한 설명은 Hugo 공식 홈페이지를 참조하시기 바랍니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EC%A2%8C%EC%B6%A9%EC%9A%B0%EB%8F%8C_%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EC%83%9D%EC%84%B1%EA%B8%B0/%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EB%8C%93%EA%B8%80_%EA%B5%AC%ED%98%84_utterances_%EB%8F%84%EC%9E%85%EA%B8%B0/","summary":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여 \u0026gt; HUGO 기본 설치 및 사용법 \u0026gt; Git 연동과 정적 페이지 배포\n저번 포스팅까지 블로그를 만들어봤는데요, 댓글이 없으니 뭔가 허전한 느낌입니다. 원래 블로그는 다른 사람과의 소통을 위함이니까요.\n이번 시간에는 블로그 댓글을 생성하는 라이브러리들을 비교해보고, 그중 utterances를 직접 블로그에 적용해 보겠습니다.\n저도 처음에는 어떻게 댓글을 구현할까 하다가, 직접 기능을 만들어보려고도 생각했었습니다. 하지만, 그럼 로그인 기능이나 댓글을 저장하는 DB도 만들어야 하는데 블로그 만드는 것보다 더 많은 노력이 필요할 것 같았습니다.","title":"깃허브 블로그 댓글 구현 : Utterances 도입기"},{"content":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여 \u0026gt; HUGO 기본 설치 및 사용법\n지난 시간에 Hugo설치 및 간단한 사용법을 알아보았습니다. 이번에는 깃과 연동하여 버전관리 및 깃허브 페이지에 블로그를 띄워보겠습니다.\n이 포스팅은 Git이 설치되어 있는 것을 전제로 합니다. 혹시 Git이 설치되지 않은 분들은 설치 후 진행해주세요.\n블로그 디렉터리와 Git 연결하기 먼저 지난 시간에 생성한 디렉터리를 Git에 등록해야 합니다. 대부분 Git에 익숙하시겠지만, 아직 어려우신 분들을 위해 자세히 설명드리겠습니다.\n블로그 레포지토리 생성 Git에 특정 디렉터리를 올려 버전관리를 하기 위해서는 레포지토리를 생성해야 합니다. 1.깃허브 메인 페이지에서 레포지토리 생성버튼을 클릭합니다.\n2.레포지토리 이름을 작성하고 public을 선택한 후, Create repository 버튼을 클릭합니다.\n이제 깃허브에 블로그 레포지토리가 생성되었습니다.\n블로그 레포지토리 연결 새로 생성한 레포지토리에 저번에 생성한 블로그 디렉터리를 연결합니다. 우선 git bash 혹은 zsh등의 쉘에서 \u0026lsquo;cd {디렉터리 경로}\u0026rsquo; 명령어를 통해 블로그의 최상위 디렉터리로 이동합니다. git bash 혹은 zsh등의 쉘에서 블로그의 최상위 디렉터리로 이동합니다.\n다음 명령어를 통해 블로그 원격 레포지토리에 커밋합니다. # 새로운 로컬 레포지토리 생성 $ git init # 원격 레포지토리 연결 : 원격 레포지토리 주소는 새로 생성된 레포지토리에 있습니다.(하단 이미지 참조) $ git remote add origin {원격 레포지토리 주소} # 로컬 브랜치 이름 변경(깃허브는 최초 브랜치가 main이고 깃은 master여서 이름을 main으로 변경해야 합니다.) $ git branch -m main # 로컬 레포지토리(블로그 디렉터리) → 원격 레포지토리로 커밋 $ git add . $ git commit -m \u0026#34;first commit\u0026#34; $ git push -u origin main 새로 생성된 레포지토리에서 위 버튼으로 원격 레포지토리 주소를 복사할 수 있습니다.\n이제 블로그 디렉터리와 레포지토리가 연결되어 변경사항을 커밋하면 깃허브에 저장할 수 있습니다.\n배포용 레포지토리 생성하기 블로그 레포지토리를 성공적으로 등록하였으니, 이제 배포용 레포지토리를 생성해야 합니다.\n이렇게 두 개의 레포지토리를 두는 이유는 다음과 같습니다.\nHugo로 빌드한 페이지를 별도의 레포지토리에서 관리하여 블로그 디렉터리와 소스코드 분리 깃허브 계정의 정적페이지 주소와 동일한 이름의 레포지토리를 사용하여 메인 페이지 경로 단일화1 그럼 배포용 레포지토리를 생성해서 연결해보겠습니다.\n배포용 레포지토리 생성 본인의 깃허브 페이지 주소와 동일한 레포지토리를 생성합니다. 위의 블로그 레포지토리 생성과 동일한 절차로 생성하되, 이름을 아래와 같이 설정하시면 됩니다. # 본인 깃허브 페이지 주소 : https://{본인 깃허브 계정명}.github.io {본인 깃허브 계정명}.github.io 제가 현재 Github Pages에 등록해 사용중인 Repository입니다.\n배포용 레포지토리가 생성되었습니다.\n블로그 레포지토리와 연결 새로 생성한 배포용 레포지토리는 블로그 레포지토리 내부의 public 경로에 submodule로 등록해야 합니다. 이렇게 등록 후 블로그 레포지토리에서 새로 페이지를 작성하면, 자동으로 배포용 레포지토리 내부 파일의 변경사항으로 잡히기 때문에 편하게 관리할 수 있습니다. submodule로 등록 및 확인하는 명령어는 다음과 같습니다. # git submodule add {서브모듈 레포지토리 주소} public $ git submodule add https://github.com/leaf-nam/leaf-nam.github.io.git public # 제대로 등록되었는지 확인해보려면, 아래 명령어를 실행합니다. $ git submodule # +72759664014b7a27ad069a24aa876836605e2d51 public (heads/main) 정상 등록 후 커밋 시 위와 같이 깃허브 경로 내부에 배포용 레포지토리가 submodule로 등록됩니다.\n이제 배포용 레포지토리가 서브모듈로 등록되어 배포할 준비를 마쳤습니다.\n정적 사이트 배포하기 생성된 배포용 레포지토리에 정적파일들을 업로드 후 Github Pages를 사용하여 배포하겠습니다.\n배포용 레포지토리에 정적파일 업로드 git bash를 실행하여 블로그 레포지토리에서 정적파일들을 빌드합니다. # 블로그 레포지토리 메인 경로로 이동합니다. $ cd {블로그 레포지토리 경로} # 정적파일을 빌드합니다. $ hugo #Start building sites … #hugo v0.123.4-21a41003c4633b142ac565c52da22924dc30637a+extended #darwin/arm64 BuildDate=2024-02-26T16:33:05Z VendorInfo=brew # | KO #-------------------+----- # Pages | 67 # Paginator pages | 0 # Non-page files | 26 # Static files | 0 # Processed images | 12 # Aliases | 25 # Cleaned | 0 배포용 레포지토리로 이동 후 해당파일들을 커밋합니다. # 배포용 레포지토리로 이동합니다. $ cd public # 해당 파일들을 커밋합니다. $ git add . $ git commit -m \u0026#34;blog 업로드\u0026#34; $ git push origin main 이제 깃허브에 있는 레포지토리에 저희가 생성한 블로그 정적파일들이 업로드되었습니다.\nGithub Pages 설정 배포용 레포지토리에 들어가서 다음 절차를 통해 Github Pages를 배포합니다. 1.레포지토리의 Settings로 이동합니다.\n2.사이드바의 Pages로 이동하면 현재 Branch의 배포 경로가 None으로 되어 있습니다.\n3.배포경로를 main-/(root)로 변경 후 Save합니다.\n4.상단바의 Actions로 들어가보면 배포가 진행되고 있습니다.\n5.배포가 완료된 후, 다시 Settings로 돌아오면 다음과 같이 배포중이라는 메시지가 보입니다.\n해당페이지로 들어가면 정상적으로 블로그가 배포됨을 확인할 수 있습니다.\n결론 지금까지 블로그 페이지를 깃허브와 연동하고 Git Pages를 사용하여 배포까지 완료했습니다. 깃 사용이 익숙하신 분들이라면 금방 적용하셨을 것이라고 생각합니다.\n직접 EC2와 같은 서버에 빌드해보신 분들이라면 아시겠지만, 별다른 세팅 없이 본인의 페이지를 빌드해서 즉시 웹에 게시할 수 있다는 점이 Git Pages의 강력한 점인 것 같습니다.\n이제 블로그 배포까지 완료했으니, 다음 포스팅에서는 다른 사용자와 소통할 수 있는 댓글 기능을 utterances 라이브러리를 사용해 연결해보겠습니다.\nReferences 배포용 레포지토리의 이름을 깃허브 주소와 일치시키지 않으면, https://{깃허브 이름}.github.io/{레포지토리 이름} 형식으로 메인 페이지 URL이 구성됩니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EC%A2%8C%EC%B6%A9%EC%9A%B0%EB%8F%8C_%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EC%83%9D%EC%84%B1%EA%B8%B0/git_%EC%97%B0%EB%8F%99%EA%B3%BC_%EC%A0%95%EC%A0%81_%ED%8E%98%EC%9D%B4%EC%A7%80_%EB%B0%B0%ED%8F%AC/","summary":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여 \u0026gt; HUGO 기본 설치 및 사용법\n지난 시간에 Hugo설치 및 간단한 사용법을 알아보았습니다. 이번에는 깃과 연동하여 버전관리 및 깃허브 페이지에 블로그를 띄워보겠습니다.\n이 포스팅은 Git이 설치되어 있는 것을 전제로 합니다. 혹시 Git이 설치되지 않은 분들은 설치 후 진행해주세요.\n블로그 디렉터리와 Git 연결하기 먼저 지난 시간에 생성한 디렉터리를 Git에 등록해야 합니다. 대부분 Git에 익숙하시겠지만, 아직 어려우신 분들을 위해 자세히 설명드리겠습니다.","title":"Git 연동과 정적 페이지 배포"},{"content":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여\n어떤 개발 블로그를 사용할지도 정했고, SSG 엔진도 정했으니 이제 진짜로 블로그를 만들어보겠습니다.\n이 글을 읽는 분들은 처음 Hugo를 접하실테니 간단한 구조와 기본적인 명령어, 테마 적용법 정도만 알아보고 자세한 환경설정은 차후 별도의 포스팅으로 다룰 예정입니다.\n그 외 환경설정은 Hugo 공식문서1에 친절하게 (영어로) 정리되어 있으니 해당 페이지를 확인하시면 됩니다.\nHugo 관련된 오류들은 한글로 검색해도 잘 안나와서 자동으로 영어공부를 하게 해줍니다 \u0026#x1f622;\n이 포스팅은 Git이 설치되어 있는 것을 전제로 합니다. 혹시 Git이 설치되지 않은 분들은 설치 후 진행해주세요.\nHugo 설치방법 Hugo의 쉘 스크립트2를 사용하기 위해서는 별도의 설치가 필요합니다.\n맥 유저는 brew를 사용하면 정말 간편하게 설치할 수 있습니다. brew를 사용할 수 없는 윈도우는 직접 압축파일을 받아 설치하시거나 별도의 패키지 매니저를 통해 설치가 가능합니다.\n윈도우 패키지 매니저를 활용해 설치\n환경변수나 기본 세팅을 패키지 매니저를 통해 쉽게 할 수 있습니다.\n패키지 매니저를 다운로드합니다. Hugo 공식문서에서 지원하는 윈도우 패키지 매니저는 Chocolatey, Scoop, Winget 3가지 종류가 있습니다. 저는 윈도우 노트북에서 설치 시 Scoop을 사용해 설치를 진행했기에 Scoop을 설치하는 것을 예시로 설명드리겠습니다.\nScoop 설치방법은 공식 홈페이지에 나와있는 것처럼 윈도우에 기본 설치된 PowerShell을 열어서 다음 스크립트를 실행하시면 됩니다.\n$ Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser $ Invoke-RestMethod -Uri https://get.scoop.sh | Invoke-Expression Hugo를 설치합니다.\n$ scoop install hugo-extended 위 명령어를 사용하면 자동으로 환경변수 세팅까지 완료됩니다.\nHugo 패키지 직접 설치\n패키지 매니저 설치가 귀찮으시면 다음과 같이 진행할 수 있습니다. 다만, 환경변수를 직접 설정해야 합니다.\n공식 깃허브에 최신 패키지가 릴리즈되고 있습니다. 해당 패키지를 다운로드 받습니다. Assets \u0026gt; Show all 24 assets \u0026gt; hugo_{최신버전}_windows-amd64.zip\n다운로드 받은 파일을 hugo \u0026gt; bin 폴더에 압축 해제합니다.(나중에 환경변수를 통해 접근하기 때문에 폴더는 어디에 생성하셔도 무관합니다.3) c:₩{설치경로}₩hugo₩bin₩{압축파일 해제}\n환경변수를 세팅합니다. 명령어를 실행하려면 hugo.exe가 포함된 c:₩{설치경로}₩hugo₩bin 폴더를 환경변수에 등록해야 합니다.4 저는 맥에서 작업하고 있어 구체적인 설명은 윈도우 도움말을 확인하시거나, 환경변수 관련된 블로그 글이 많으니 구글신의 도움을 받읍시다.\n맥 \u0026amp; 리눅스 brew만 설치되어 있으면 코드 1줄이면 끝입니다.\n$ brew install hugo 설치 확인 다음 명령어를 쳤을 때 휴고 버전이 0.112.0 이상이면 정상 설치 완료입니다.\n$ hugo version # hugo v0.123.4-21a41003c4633b142ac565c52da22924dc30637a+extended darwin/arm64 BuildDate=2024-02-26T16:33:05Z VendorInfo=brew 참고로 윈도우의 경우 Git Bash와 같은 리눅스 기반 쉘에서 실행하라는 경고문이 있습니다.5\n디렉터리 생성 및 로컬 실행 이제 Hugo 설치를 마쳤으니, 블로그를 위한 디렉터리를 구성하고 로컬에서 직접 실행해보겠습니다.\n사이트 디렉터리 생성 다음 명령어를 통해 디렉터리를 생성할 수 있습니다.\n# 사이트명 내부에 본인이 원하는 사이트 이름을 적습니다.(괄호는 제외) $ hugo new site {사이트명} 로컬서버 실행 이어서 다음 명령어를 실행하면 해당 디렉터리로부터 서버를 생성해서 로컬로 띄워줍니다.\n$ hugo server # Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) 서버주소는 기본적으로 localhost:1313 입니다.\n정상 실행된다면, 브라우저에서 다음과 같은 화면이 나옵니다.\n디렉터리 구조 생성된 디렉터리 구조는 다음과 같습니다.\n├── archetypes # 새 블로그 글을 쓰면 생성되는 글의 기본 형식을 작성할 수 있습니다. │ └── default.md # 별다른 옵션없이 글을 작성하면 생성되는 글의 포맷입니다. ├── assets # 로고 이미지와 같은 이미지나 js, css 등의 파일이 위치합니다. ├── content # 작성한 글이 들어가는 디렉터리입니다. 차후 해당 디렉터리를 참고해 블로그 페이지를 빌드합니다. ├── data # json이나 csv, yaml과 같은 데이터를 저장할 수 있습니다. ├── hugo.toml # 설정파일입니다. 다양한 설정들이 있으며 차후 별도 포스팅으로 다룰 예정입니다. ├── i18n # 국제화 시 웹사이트 번역 내용이 포함됩니다. 글로벌하게 포스팅을 하려면 번역해서 넣으면 됩니다. ├── layouts # header, body 등 http 템플릿의 레이아웃을 설정할 수 있습니다. ├── public # hugo가 빌드한 파일이 들어가는 경로입니다. 차후 서버가 배포되면 해당 위치의 파일들을 제공합니다. │ ├── categories │ │ └── index.xml │ ├── index.xml │ ├── sitemap.xml │ └── tags │ └── index.xml ├── static # 빌드 시에 그대로 들어가야 하는 정적파일들이 들어갑니다. favicon.ico, robots.txt 등이 있습니다. └── themes # 다운로드한 테마가 들어갑니다. 테마 적용 및 블로그 글 작성 테마 적용방법 hugo사이트에서 기본적으로 제공하는 ananke 테마를 적용해보겠습니다.\n새로 생성한 사이트 루트 디렉토리에서 진행합니다.\n깃으로 테마를 다운로드 하기 위해 다음과 같은 명령어를 사용합니다.\n# 해당 경로에서 git을 생성합니다. $ git init # submodule로 테마를 다운로드 받습니다. $ git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke 해당 테마를 적용하기 위해 설정파일(hugo.toml)에 테마를 명시합니다. # hugo.toml파일을 열고 아래 내용을 적으시면 됩니다. theme = \u0026#39;ananke\u0026#39; 아까 접속한 로컬 서버에 테마가 적용되었는지 확인합니다. 블로그 글 작성 블로그 글을 작성하는 명령어는 다음과 같습니다. # 해당 명령어를 사용하면 /content 내부에 /posts/my-first-post.md 파일이 생성됩니다. $ hugo new content posts/my-first-post.md 해당 파일에 다음과 같은 내용을 작성해봅시다. // 아래 주석의 내부를 /posts/my-first-post.md 파일의 생성된 글 아래에 붙여넣으시면 됩니다. +++ title = \u0026#39;My First Post\u0026#39; date = 2024-03-03T16:49:22+09:00 draft = true +++ /* \u0026lt;!-- -----------여기부터-------------- --\u0026gt; ## Hello World! *안녕하세요!* **첫 블로그 글**입니다. [홈페이지](http://localhost:1313)로도 이동이 가능합니다. \u0026lt;!-- -----------여기까지-------------- --\u0026gt; */ 이제 로컬 서버에서 확인하기 위해 서버가 실행중인 쉘에서 서버를 중지한 후, -D 옵션을 붙여 다시 시작해봅시다. /* 로컬서버 중지 */ $ ctrl + c /* 서버 재시작 */ $ hugo server -D 글이 정상적으로 업로드 되었는지 확인해봅니다. 여기까지 따라오셨다면, 블로그 생성 및 게시글 작성까지 완료입니다!\n결론 지금까지 Hugo의 설치방법과 블로그 생성 및 글 작성방법에 대해 알아보았습니다.\n명령어 몇 줄로 쉽게 홈페이지를 생성할 수 있다니 참 좋은 세상에 살고 있는 것 같습니다. \u0026#x1f604;\n다음 시간에는 Git pages를 활용해서 웹에 블로그를 직접 배포해 보겠습니다.\nReferences \u0026ldquo;Hugo 공식 문서\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n쉘에서 사용하는 간단한(?) 명령어를 뜻합니다. 윈도우에서는 cmd나 powershell 등에서 실행이 가능하고, 맥에서는 기본적으로 zsh나 bash로 실행할 수 있습니다. 자세한 설명은 위키백과를 확인하세요.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n다만 다른 설치프로그램들과 함께 관리하기 위해 C:₩Program Files₩ 경로에 hugo 폴더를 생성해서 설치하는 것을 권장합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n이 절차를 거치지 않으면 매번 hugo 명령어를 쓸때마다 c:₩{설치경로}₩hugo₩bin₩hugo를 적어야 하므로 매우 불편합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n윈도우 사용자를 위한 경고문\n제가 직접 PowerShell에서 기본적인 명령어를 쳤을땐 잘 작동했던 것 같은데 어디선가 충돌이 발생하나 봅니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EC%A2%8C%EC%B6%A9%EC%9A%B0%EB%8F%8C_%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EC%83%9D%EC%84%B1%EA%B8%B0/hugo_%EA%B8%B0%EB%B3%B8_%EC%84%A4%EC%B9%98_%EB%B0%8F_%EC%82%AC%EC%9A%A9%EB%B2%95/","summary":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택 \u0026gt; SSG에 대하여\n어떤 개발 블로그를 사용할지도 정했고, SSG 엔진도 정했으니 이제 진짜로 블로그를 만들어보겠습니다.\n이 글을 읽는 분들은 처음 Hugo를 접하실테니 간단한 구조와 기본적인 명령어, 테마 적용법 정도만 알아보고 자세한 환경설정은 차후 별도의 포스팅으로 다룰 예정입니다.\n그 외 환경설정은 Hugo 공식문서1에 친절하게 (영어로) 정리되어 있으니 해당 페이지를 확인하시면 됩니다.\nHugo 관련된 오류들은 한글로 검색해도 잘 안나와서 자동으로 영어공부를 하게 해줍니다 \u0026#x1f622;","title":"HUGO 기본 설치 및 사용법"},{"content":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택\n이제 깃허브 블로그를 쓰기로 마음먹었으니, 어떤 도구를 사용해서 블로그를 만들지에 대한 선택이 남았습니다. 인생도 그렇지만 개발도 항상 선택의 연속인 것 같습니다.\n이번 포스팅에서는 SSG(Static Site Generator)의 개념, 종류와 특징에 대해 알아보고, SSG Framework 중 하나인 HUGO에 대해서 간단히 소개하겠습니다.\nSSG 저는 최초 블로그를 작성하기 위해 어떻게 홈페이지를 만들어야 하는지 고민이 되었고, 여러 옵션들을 확인하던 중, SSG를 사용해 블로그를 만드는 것이 가장 좋아보여 이를 도입하게 되었습니다.\n사실 SSG를 제대로 이해하기 위해서는 SSR, CSR, SPA 등의 개념에 대해 우선 설명해야 하지만, 이는 생각보다 양이 방대하고 개발의 역사와도 관련이 되는 내용이기에 나중에 별도의 포스팅으로 다루도록 하겠습니다. 지금은 블로그를 만들기 위한 필수개념 정도만 간단히 다루고 넘어가겠습니다.\nSSG(Static Site Generator)는 텍스트 입력 파일(ex. Markdown, reStructuredText, AsciiDoc 및 JSON)을 사용하여 정적 웹 페이지를 생성하는 엔진입니다.1\n즉, 간단한 텍스트 파일을 사용해 정적으로 웹 페이지를 빌드하고 배포하는 방식의 개발 방법입니다.\n이러한 SSG는 다양한 장점을 갖고 있으며 SSG 프레임워크를 다루는 잼스택(JAMStack2) 개발자가 별도로 등장할 정도로 최근 많이 주목받는 최신 트렌드 기술 중 하나입니다.\n장점은 다음과 같습니다.\n확장성 : 이미 생성된 파일을 통해 서비스하므로, 기존에 빌드한 파일에 대해 더이상 추가적인 자원을 사용할 필요가 없습니다3. 이는 기존 서비스에 대해 더이상 신경쓰지 않고 새로운 서비스를 확장할 수 있게 해줍니다. 성능 : 이미 빌드가 되어있기에 생성된 파일을 전송하는 과정 자체도 빠른 응답이 가능하며, CDN4과 같은 캐싱 서버에서 직접 해당 파일만 응답하면 되므로 더욱 빠른 성능을 기대할 수 있습니다. 보안 : CDN을 통해 분리된 지역서버는 DB에 접근하지 않고 서비스가 가능하며, 해커에 의한 공격이 발생했을때 중앙 서버에 영향을 미치기 전에 해당 네트워크를 빠르게 분리하는 것이 가능합니다. 또한, 공격 대상인 서버를 다시 구성하여 CDN을 재구축하면 되기에 빠른 대응 또한 가능합니다. 이렇게 훌륭한 SSG이지만, 잼스택 개발자라는 직군이 따로 분리될 정도로 초기 구현 및 세팅이 복잡하고 아직 많은 레퍼런스가 없기에 처음 공부하거나 도입하기가 어렵다는 단점이 있습니다.\n제가 블로깅을 하면서 확장성이나 성능 등을 걱정할 일은 크게 없겠지만, 애초에 깃허브에서 제공하는 배포 도구를 사용하려면 단일 HTML이 필요했습니다. 매번 블로그에 글을 쓸때마다 HTML을 생성할 바에는 차라리 SSG를 공부해서 도입하는게 더 빠르겠다는 생각에 SSG를 사용하기로 마음먹었습니다.\nSSG의 종류 이러한 SSG에도 종류가 많습니다. SSR(Server Side Rendering)5 프레임워크로 알고있던 Next.js도 SSG를 지원했고, 국내 개발 블로그에서 많이 사용하는 jekyll과 제가 사용하는 Hugo 또한 SSG입니다. 이러한 SSG의 특징과 장단점에 대해 알아보겠습니다.\n(어째 저번 포스팅과 흐름이 똑같네요..)\nNext.js 국내 프론트엔드 시장의 대부분을 점유하고 있는 React를 사용해 SSR을 구현한 프레임워크입니다. Vercel에서 개발하고 관리하고 있습니다.(React를 만든 Meta에서 개발한게 아니었네요!)\n제가 생각한 장점 및 특징은 다음과 같습니다.\n많은 레퍼런스와 개발 생태계\n아래 그래프6에서 보시는 것처럼 국내 프레임워크의 높은 순위를 차지하고 있는 React + Next.js인 만큼 수많은 레퍼런스와 학습자료를 쉽게 찾아볼 수 있습니다. 또한, 개발자가 많다는 것은 그만큼 에러가 발생했을 때 여기저기에 질문을 통해 쉽게 해결할 수 있다는 뜻이기도 합니다. 프로그래머스 통계 : 주로 사용하는 웹 프레임워크 또는 라이브러리는 무엇인가요?\n안정성과 다양한 오픈소스 지원\n우선 메타에서 지원 및 유지보수를 하는 React 기반의 프레임워크인 점에서 매우 안정성이 높다고 할 수 있습니다. 또한, 위에서 본 것처럼 많은 사용자들을 보유하다 보니 관련된 오픈소스 라이브러리도 많습니다. 저도 프론트엔드 라이브러리를 도입하기 위해 오픈소스를 찾아보면 체감상 80% 이상은 React기반으로 생성되어 있는 것 같습니다. (부끄럽지만 아직 Vue.js만 조금 다루는 수준이라 React로 되어있는 오픈소스는 그림의 떡처럼 아쉬운 적도 많았습니다.) Vercel과 연동한 손쉬운 배포\n개발사인 vercel은 클라우드 컴퓨팅을 제공하는 회사입니다. 즉, 기본적인 웹사이트 배포를 위한 인프라가 이미 완성되어 있기에 웹페이지만 완성하면 빌드 및 배포하는 것은 정말 쉽다고 합니다. 이러한 호환성을 무기로 하기 위해 Vercel에서 React를 활용한 Next.js 생태계를 구축하지 않았나 싶습니다. 원래도 React는 한번 공부해보고는 싶었고, React만 알면 쉽게 웹페이지를 제작할 수 있다는 부분은 정말 매력적으로 다가왔습니다.\n하지만 React를 단시간에 배울 수 있을지도 조금 걱정되었고, 너무 큰 생태계인지라 블로그를 작성하는 것보다 프레임워크를 배우는데 더 많은 시간을 쓸까 우려가 되었습니다. 자칫 배보다 배꼽이 커질 수도 있겠다는 생각이 들어 다른 옵션을 찾아보게 되었습니다.\nJekyll 지킬은 Ruby7로 개발된 SSG입니다.\n깃허브의 공동 설립자 Tom Preston-Werner에 의해 개발되었으며, 깃허브가 나온 2008년에 함께 출시되었으니 깃허브와 거의 역사를 함께했습니다.\n위 내용만 봐도 깃허브와 아주 친할 것 같은 느낌이네요. 실제로 국내 대부분의 깃허브 블로그는 Jekyll을 활용하고 있고 같은 언어를 사용하기에 호환성이 좋습니다.\n그럼 특장점을 살펴보겠습니다.\n깃허브 연동성\n애초에 깃허브 블로그를 만들기 위해 나온 SSG이기 때문에, 별다른 설치없이 Ruby만 설치하면 RubyGems8를 통해 쉽게 설치가 가능합니다. 아마 깃허브나 지킬 둘중 하나가 망하지 않는 한 깃허브와의 연동은 별다른 이슈가 없을 것 같습니다. 다양한 레퍼런스와 테마\nNext.js만큼은 아니지만 국내의 많은 블로그가 Jekyll로 만들어져 있기 때문에 참고할 만한 사이트가 많습니다. 테마도 많아서 다양한 테마를 직접 설치하고 커스터마이징 하는 것이 가능합니다.9 가벼움\n처음에는 RubyGems의 라이브러리 중 하나가 아닌가 생각할 정도로 가볍고 간편합니다. 저도 개발 경험이 많지는 않지만 지킬과 같이 가볍고 최소한의 필요한 기능만 제공하는 프레임워크가 금방 손에 익고 편했습니다. 저도 Jekyll을 찾아보면서 Ruby라는 언어가 매우 흥미롭게 다가와서 공부해보고 싶다는 생각도 많이 들었습니다. 그리고 Jekyll은 굳이 Ruby의 내부 동작을 몰라도 간단한 쉘스크립트만 실행하면 되기에 배우는데는 큰 무리가 없어 보였습니다.\n하지만 좀더 찾아보니 Ruby만 설치하면 된다는게 말이 쉽지, 사실 쉽지많은 않다는 이야기도 많았고, (Ruby환경세팅이 악명 높기로 유명하다고 합니다) 테마를 적용하는 과정에서도 RubyGem의 번들링하는 과정이 상대적으로 번거롭다는 글도 확인했습니다.10\n마지막으로 깃허브에 많이 의존하고 있다는 것은 반대로 생각하면 깃허브와 생명주기를 함께한다는 것이고, 나중에 다른 사이트나 클라우드를 통해 배포를 하고 싶을때 걸림돌이 되지 않을까 하는 생각도 들었습니다.\nHugo 드디어 오늘의 주인공 Hugo입니다. 이름에서 알 수 있듯이 go언어로 만들어진 SSG입니다. 공식 웹사이트에 들어가면 자세한 설명을 보실 수 있습니다.11\n해외에는 비교적 인기가 많은 것 같은데, 국내에는 레퍼런스가 많이 없습니다. 저도 블로그 환경세팅을 하면서 많은 애를 먹고 있는데, 그래도 세계공용어인 영어가 있으니 대부분의 문제는 어찌저찌 해결이 되긴 합니다..\n그래도 레퍼런스가 없다는 것을 모두 상쇄할 만큼 좋은 장점들이 많아 결국 Hugo를 선택하게 되었습니다.\n성능\n공식 홈페이지에 나와있는 유튜브만 보더라도 성능 면에서 압도적입니다. 영상을 다 보시기 귀찮은 분들을 위해 요약하자면, 하루에 2개씩 5000개의 포스트를 작성하면 대략 6.8년이 걸리는데, 이정도 되는 양도 Hugo로 생성시 6~7초면 빌드가 완료된다는 영상입니다.\n(반면, Jekyll은 1000개 빌드하는데 4~5분 걸린다고 하네요. 공식 페이지에도 빌드관련 이슈가 상당히 많습니다.12)\nGo\n구글에서 사용하는 Go(Golang) 기반이라는 점도 매력적이라고 생각합니다. 컴파일 언어이지만 정말 빨라서 마치 인터프리터 언어처럼 사용이 가능하다고 하는데, 구글에서 지원하고 개발하는만큼 향후에도 많은 발전이 이루어지지 않을까 기대가 됩니다. 문법도 점점 쉽게 개선되고 있고, 특히 html 템플릿은 이중 중괄호 문법으로 마치 Vue.js나 백엔드에서 익숙한 Mustache처럼 간편하게 사용이 가능합니다. Go의 마스코트인 Go gopher. 이름을 좀 대충 지은 티가 나는 것 같기도\u0026hellip;?\n// 위 그림을 불러오기 위한 템플릿 문법입니다. // 원래는 {{와 \u0026lt;를 붙여야 하지만, 예시를 위해 띄어쓰기 했습니다. {{ \u0026lt;figure src=\u0026#34;gogopher.jpeg\u0026#34; caption=\u0026#34;Go의 마스코트인 Go gopher. 이름을 좀 대충 지은 티가 나는 것 같기도...?\u0026#34;\u0026gt; }} 테마 적용과 확장의 용이성\n지킬과 함께 블로그 SSG의 양대산맥인 가장 큰 이유 중 하나는 바로 방대한 양의 테마입니다. 고르는 게 힘들 정도로 다양한 테마가 있고13, 이러한 테마를 적용하거나 커스터마이징 하는게 매우 간편합니다. 저도 시작한지 얼마 되지 않았지만 확실히 테마를 만들거나 불러오는 기능이 간편하고 적용하기도 쉬웠습니다. # 테마를 다운로드받은 후 이 한줄이면 테마가 변경됩니다. hugo -t \u0026#34;테마이름\u0026#34; Go와 테마도 좋지만, 아무래도 성능이 가장 끌리는 부분인 것 같습니다. 애초에 SSG를 사용하는 부분도 빠르고 간편하기 때문인데, 빌드하는 과정에서 너무 많은 시간이 소요되면 원래의 목적과 멀어질 우려가 듭니다. 백엔드는 역시 성능!\n결론 지금까지 SSG의 특징과 종류, 그리고 제가 Hugo를 선택하게 된 이유에 대해 알아보았습니다. 사실 Hugo 말고 다른 SSG도 정말 훌륭하고, 블로깅 정도로 사용하기에는 전혀 무리가 없다고 생각합니다.\n다들 장단점을 잘 찾아보시고 고민해서 본인의 상황에 맞는 최적의 스택을 고르셨으면 좋겠습니다!\n블로그 경험이 없다보니 분량조절이 힘드네요.. 사실 이번 포스팅에서 hugo 설치 및 적용까지 하려고 했는데 내용이 자꾸 길어져서 해당 포스팅은 다음번에 작성하는 것으로 하겠습니다. 그리고 앞으로는 하루 1시간 정도에 작성할 수 있는 분량으로 포스팅을 이어나가려고 합니다.\nReferences \u0026ldquo;What is a Static Site Generator? How do I find the best one to use?\u0026rdquo;. Netlify. 2020.04.14. Phil Hawksworth.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;What is Jamstack?\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCSR은 이와 다르게 매번 기존 파일을 빌드합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n지리적으로 분산된 서버들을 연결한 네트워크를 뜻합니다. 예를 들어 구글 서버는 미국에 있지만, 구글 코리아는 한국에 따로 서버를 구성해서 파일이 변경될 때만 미국의 구글서버와 동기화합니다. 이렇게 한국에 있는 구글서버를 통해 더욱 빠른 통신이 가능합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n서버에서 페이지를 렌더링하는 방식입니다. SSG와 유사하지만, SSR은 요청 시마다 페이지를 렌더링해서 전송하는 방식이고 SSG는 서버 빌드 시점에 이미 해당 페이지를 생성합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nProgrammers Dev Survey 2023.Programmers. 2022.12.05. ~ 2022.12.31.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n마츠모토 유키히로가 1995년 만든 스크립트 언어입니다. Ruby On Rails(ROR)라는 프레임워크를 사용하면 풀스택 개발도 가능하며, 깃허브도 ROR로 만들어져 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRuby에서 사용하는 패키지 관리자입니다. \u0026lsquo;gem\u0026rsquo;으로 시작하는 쉘스크립트는 해당 패키지 관리자를 호출하는 스크립트입니다. (보석 컨셉이 확실하네요!)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJekyll 테마 사이트\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGitHub Pages를 이용한 기술 블로그 제작 후기.Yogiyo. 2019.01.23. Yogiyo Tech Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhat is Hugo\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBuild Time Performance Issues\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHugo 테마 사이트\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/posts/%EC%A2%8C%EC%B6%A9%EC%9A%B0%EB%8F%8C_%EA%B9%83%ED%97%88%EB%B8%8C_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EC%83%9D%EC%84%B1%EA%B8%B0/ssg%EC%97%90_%EB%8C%80%ED%95%98%EC%97%AC/","summary":"도입 이전 포스팅 참조 : 개발 블로그의 종류와 선택\n이제 깃허브 블로그를 쓰기로 마음먹었으니, 어떤 도구를 사용해서 블로그를 만들지에 대한 선택이 남았습니다. 인생도 그렇지만 개발도 항상 선택의 연속인 것 같습니다.\n이번 포스팅에서는 SSG(Static Site Generator)의 개념, 종류와 특징에 대해 알아보고, SSG Framework 중 하나인 HUGO에 대해서 간단히 소개하겠습니다.\nSSG 저는 최초 블로그를 작성하기 위해 어떻게 홈페이지를 만들어야 하는지 고민이 되었고, 여러 옵션들을 확인하던 중, SSG를 사용해 블로그를 만드는 것이 가장 좋아보여 이를 도입하게 되었습니다.","title":"SSG에 대하여"},{"content":"로그레벨 변경하기 단위테스트에서 간단하게 로그 레벨을 변경할 수 있습니다.\n통합테스트는 @SpringBootTest를 사용하면 /src/test/resources/application.properties에 있는 설정정보를 자동으로 불러오지만, 단위테스트에서는 해당 어노테이션이 너무 무겁기 때문에 사용할 수 없습니다.\n바로 코드로 알아보겠습니다.\n// 단위테스트가 필요한 클래스 내부에 해당 코드를 추가하면 완료입니다. import org.slf4j.LoggerFactory; import ch.qos.logback.classic.Level; import ch.qos.logback.classic.Logger; @BeforeAll public void setLogLevel() { final Logger logger = (Logger)LoggerFactory.getLogger(Logger.ROOT_LOGGER_NAME); logger.setLevel(Level.ALL); } 간단히 코드를 설명드리자면, 단위테스트 시작 전 LoggerFactory로 새로운 loogger를 생성하고 레벨을 변경한 후 테스트를 수행하기 위한 코드입니다.\n반드시 logback1 라이브러리에 있는 Logger를 import받으셔야 합니다!\nJunit4에서는 @BeforeaAll 대신 @Before 를 사용하시면 됩니다.\n감사합니다.\nReferences URL 게시일자 방문일자 작성자 https://stackoverflow.com/questions/38778026/how-to-set-the-log-level-to-debug-during-junit-tests 2016.08.04. 2024.03.20 PedroD log4j의 후속 라이브러리입니다. 더 자세한 설명은 해당 페이지를 확인해주세요.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/tips/springboot_junit_%EB%8B%A8%EC%9C%84%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%97%90%EC%84%9C_%EB%A1%9C%EA%B7%B8_%EB%A0%88%EB%B2%A8_%EC%A1%B0%EC%A0%95%ED%95%98%EA%B8%B0/","summary":"로그레벨 변경하기 단위테스트에서 간단하게 로그 레벨을 변경할 수 있습니다.\n통합테스트는 @SpringBootTest를 사용하면 /src/test/resources/application.properties에 있는 설정정보를 자동으로 불러오지만, 단위테스트에서는 해당 어노테이션이 너무 무겁기 때문에 사용할 수 없습니다.\n바로 코드로 알아보겠습니다.\n// 단위테스트가 필요한 클래스 내부에 해당 코드를 추가하면 완료입니다. import org.slf4j.LoggerFactory; import ch.qos.logback.classic.Level; import ch.qos.logback.classic.Logger; @BeforeAll public void setLogLevel() { final Logger logger = (Logger)LoggerFactory.getLogger(Logger.ROOT_LOGGER_NAME); logger.setLevel(Level.ALL); } 간단히 코드를 설명드리자면, 단위테스트 시작 전 LoggerFactory로 새로운 loogger를 생성하고 레벨을 변경한 후 테스트를 수행하기 위한 코드입니다.","title":"Springboot Junit 단위테스트에서 로그 레벨 조정하기"},{"content":"상황 기존 코드를 리팩토링하는 과정에서 엔티티 객체에 있던 @Data를 @Getter로 변경중이었습니다.\n테스트를 위해 임시로 @Data를 붙여놓고 사용중이었습니다.\n@Getter // 기존 : @Data @Builder @AllArgsConstructor public class LaneInfo { private TeamPosition teamPosition; private boolean isBottomLane; private int myTeamId; private int myLaneNumber; private int oppositeLaneNumber; private int myBottomDuoNumber; private int oppositeBottomDuoNumber; //...(생략) } 기존에 잘 동작하던 아래 테스트에서 오류가 발생했습니다.\n//생략 // matchIndicator가 가진 laneInfo와 given에서 주어진 laneInfo 비교 assertThat(matchIndicators.get(0) .getMetadata() .getLaneInfo()) .isEqualTo(laneInfo); 원인 분석 오류 로그는 다음과 같았습니다. Expected :com.ssafy.matchup_statistics.indicator.entity.match.LaneInfo@1150d471 Actual :com.ssafy.matchup_statistics.indicator.entity.match.LaneInfo@6393bf8b 해당 테스트코드는 기존에는 잘 동작했고, 각 필드가 하나라도 달라지면 실패하던 테스트코드였기에 원인이 궁금했습니다.\n@Data 내부를 확인해본 결과, 기존 코드가 성공했던 이유는 @Data 에서 내부적으로 @EqualsAndHashCode를 통해 equals를 구현해주었기 때문이었습니다.\n// 롬복 @Data에 들어가보면 볼 수 있는 Java Doc /** * Generates getters for all fields, a useful toString method, and hashCode and equals implementations that check * all non-transient fields. Will also generate setters for all non-final fields, as well as a constructor. * Equivalent to {@code @Getter @Setter @RequiredArgsConstructor @ToString @EqualsAndHashCode}. * Complete documentation is found at \u0026lt;a href=\u0026#34;https://projectlombok.org/features/Data\u0026#34;\u0026gt;the project lombok features page for \u0026amp;#64;Data\u0026lt;/a\u0026gt;. * * @see Getter * @see Setter * @see RequiredArgsConstructor * @see ToString * @see EqualsAndHashCode * @see lombok.Value */ @Target(ElementType.TYPE) @Retention(RetentionPolicy.SOURCE) 해결 Equals Overriding @Getter @Builder @AllArgsConstructor @EqualsAndHashCode // 추가 public class LaneInfo { private TeamPosition teamPosition; private boolean isBottomLane; private int myTeamId; private int myLaneNumber; private int oppositeLaneNumber; private int myBottomDuoNumber; private int oppositeBottomDuoNumber; 롬복이 제공하는 @EqualsAndHashCode 어노테이션만으로도 간단하게 해결이 가능하지만, Equals를 별도로 구현하지 않고 해결할 수 있는 다른 방법들도 알아보겠습니다.\n각 필드 직접 비교(비추천) assertThat(matchIndicators.get(0) .getMetadata() .getLaneInfo() .getTeamPosition()) .isEqualTo(laneInfo.getTeamPosition()); assertThat(matchIndicators.get(0) .getMetadata() .getLaneInfo() .getIsBottomLane()) .isEqualTo(laneInfo.getIsBottomLane()); //(생략 : 모든 필드 다 비교) 테스트 코드도 길어지고, 필드값 비교 과정에서 human error가 발생할 수 있으므로 비추천합니다.\n재귀적으로 필드값 비교(추천) assertThat(matchIndicators.get(0) .getMetadata() .getLaneInfo()) .usingRecursiveComparison() .isEqualTo(laneInfo); 위 코드보다 훨씬 깔끔하게 테스트가 가능합니다. assertJ 짱! 참고로 아래 메서드로 비교하지 않을 필드를 제외할 수 있습니다.\n// 무시할 필드값 ignoringFields(String… fieldsToIgnore) // 무시할 정규표현식 ignoreFieldsMatchingRegexes(String… regexes) // 무시할 타입(클래스) ignoringFieldsOfTypes(Class… typesToIgnore) References URL 게시일자 방문일자 작성자 https://umanking.github.io/2021/06/11/assertj-field-recursive-comparision/ 2021.06.11. 2024.03.23. CodeNexus https://assertj.github.io/doc/#assertj-core-recursive-comparison-ignoring-fields 2024.02.17. 2024.03.23. assertj-core ","permalink":"https://1eaf.site/tips/jnuit_%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%97%90%EC%84%9C_%EA%B0%9D%EC%B2%B4_%ED%95%84%EB%93%9C%EB%AA%85_%EB%B9%84%EA%B5%90%ED%95%98%EA%B8%B0/","summary":"상황 기존 코드를 리팩토링하는 과정에서 엔티티 객체에 있던 @Data를 @Getter로 변경중이었습니다.\n테스트를 위해 임시로 @Data를 붙여놓고 사용중이었습니다.\n@Getter // 기존 : @Data @Builder @AllArgsConstructor public class LaneInfo { private TeamPosition teamPosition; private boolean isBottomLane; private int myTeamId; private int myLaneNumber; private int oppositeLaneNumber; private int myBottomDuoNumber; private int oppositeBottomDuoNumber; //...(생략) } 기존에 잘 동작하던 아래 테스트에서 오류가 발생했습니다.\n//생략 // matchIndicator가 가진 laneInfo와 given에서 주어진 laneInfo 비교 assertThat(matchIndicators.get(0) .getMetadata() .getLaneInfo()) .","title":"Jnuit 테스트에서 객체 필드명 비교하기"},{"content":"인터페이스 생성자 주입 스프링에서는 의존성을 주입받는 다양한 기능이 있습니다. 그중 가장 많이들 사용하시는 롬복을 활용한 생성자 주입은 다음과 같습니다.\n@RequiredArgsConstructor @Service public class MyService { private final MyRepository myRepository; } // 빌드 시 lombok의 @RequiredArgsConstructor에 의해 추가되는 코드 public MyService(MyRepository myRepository) { this.myRepository = myRepository; } 하지만 주입받아야 하는게 인터페이스1라면 어떻게 의존성을 주입받을 수 있을까요?\n인터페이스의 구현체가 1개라면 문제가 없지만, 여러개 있다면 문제가 됩니다. 스프링이 어떤 Bean을 주입해야 할지 선택하지 못하기 때문입니다.(결정장애)\n직접 생성자 주입하기 정석적인 해결책입니다. lombok이 편하게 해주던 작업을 일일히 쳐주고 @Qualifier를 통해 명시해주면 됩니다.\n/** * interface인 MyRepository의 구현체로 jpaRepository와 mybatisRepository가 Bean으로 등록된 상황입니다. * @Repository(value = \u0026#34;jpaRepository\u0026#34;) * @Repository(value = \u0026#34;mybatisRepository\u0026#34;) */ @Service public class MyService { private final MyRepository myRepository; public MyService(@Qualifier(jpaRepository) MyRepository myRepository) { this.myRepository = myRepository; } } Lombok의 의존성을 제거할 수 있기 때문에 훨씬 좋은 코드2이긴 하지만, 위의 작업이 귀찮고 롬복을 계속 사용하고 싶다면 다음 방법들을 참고하시면 됩니다.\nPrimary 설정 만약 1개의 더 선호하는 Repository가 있다면 이 방법도 유용합니다.\n@Repository(value = \u0026#34;jpaRepository\u0026#34;) @Primary // 해당 설정으로 우선순위 부여 public class JpaRepository implements MyRepository{ // 생략 } 그러나 2가지 Repository를 모두 사용해야 한다면 위 방법으로는 해결이 불가능합니다.\nField Name 변경 스프링에서는 Field Name과 등록된 Bean의 이름이 같으면 자동으로 의존성을 주입해줍니다.\n/** * @Repository(value = \u0026#34;jpaRepository\u0026#34;) * @Repository(value = \u0026#34;mybatisRepository\u0026#34;) */ @RequiredArgsConstructor @Service public class MyService { // myRepository -\u0026gt; jpaRepository private final MyRepository jpaRepository; } 가장 간단하게 해결이 가능합니다.\n롬복 설정 변경 롬복 설정을 다음과 같이 바꾸면 @Qualifier를 사용할 수 있습니다.\n// 경로 : src/main/java/lombok.config(없으면 생성) lombok.copyableAnnotations += org.springframework.beans.factory.annotation.Qualifier // 위 설정 후 다음과 같이 사용 가능합니다. @RequiredArgsConstructor @Service public class MyService { @Qualifier(\u0026#34;jpaRepository\u0026#34;) // Build시 @Qualifier도 함께 생성해줌! private final MyRepository myRepository; } 롬복 설정을 변경하는게 귀찮기도 하지만, 종종 Field Name으로 DI가 안될때가 있습니다\u0026hellip;(아직 원인은 찾지 못했습니다.)\nReferences URL 게시일자 방문일자 작성자 https://www.inflearn.com/questions/71872/requiredargsconstructor%EA%B3%BC-qualifier%EC%A7%88%EB%AC%B8 2020.10.02. 2024.03.28. vkdlxj3562 인터페이스는 구현체가 아니기 때문에 Bean으로 등록할 수 없습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n단위테스트를 하기 좋은 코드이기도 합니다. 참고로 아래와 같이 Spring에 의존하지 않고도 테스트할 수 있습니다.\n@Test @DisplayName(\u0026#34;스프링 컨테이너에 의존하지 않은 테스트\u0026#34;) void dependencyInjectionWithoutSpringTest() { // given MyRepository myRepository = new JpaRepository(); // when MyService myService = new MyService(myRepository); // then assertThat(myService).isNotNull(); assertThat(myService.getMyRepository()).isNotNull(); assertThat(myService.getMyRepository()).isInstanceOf(MyRepository.class); } \u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"https://1eaf.site/tips/lombok_%EC%83%9D%EC%84%B1%EC%9E%90_%EC%A3%BC%EC%9E%85_%EC%8B%9C_%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%A3%BC%EC%9E%85%ED%95%98%EA%B8%B0/","summary":"인터페이스 생성자 주입 스프링에서는 의존성을 주입받는 다양한 기능이 있습니다. 그중 가장 많이들 사용하시는 롬복을 활용한 생성자 주입은 다음과 같습니다.\n@RequiredArgsConstructor @Service public class MyService { private final MyRepository myRepository; } // 빌드 시 lombok의 @RequiredArgsConstructor에 의해 추가되는 코드 public MyService(MyRepository myRepository) { this.myRepository = myRepository; } 하지만 주입받아야 하는게 인터페이스1라면 어떻게 의존성을 주입받을 수 있을까요?\n인터페이스의 구현체가 1개라면 문제가 없지만, 여러개 있다면 문제가 됩니다. 스프링이 어떤 Bean을 주입해야 할지 선택하지 못하기 때문입니다.","title":"Lombok 생성자 주입 시 인터페이스 주입하기"},{"content":"상황 SpringBoot에서 MongoDB에 데이터를 저장하고, 저장한 데이터를 파싱하는 과정에서 다음과 같은 오류가 발생했습니다.\n실행 코드\n// 몽고DB 컬렉션 클래스 @Document(collection = \u0026#34;indicators\u0026#34;) @Getter @NoArgsConstructor @Builder @AllArgsConstructor @Slf4j public class Indicator { @Id private String id; private List\u0026lt;MatchIndicator\u0026gt; matchIndicators; private MatchIndicatorStatistics matchIndicatorStatistics; // 메서드 생략 } // 컬렉션 조회 메서드 @Override public Indicator getIndicatorInDB(String SummonerId) { Query query = Query.query( Criteria.where(\u0026#34;_id\u0026#34;).is(SummonerId)); Indicator indicators = mongoTemplate.findOne(query, Indicator.class, \u0026#34;indicators\u0026#34;); if (indicators == null) throw new RiotDataException(RiotDataError.NOT_IN_STATISTICS_DATABASE); else log.info(\u0026#34;indicator founded : {}\u0026#34;, indicators.getId()); return indicators; } 오류 코드 Parameter org.springframework.data.mapping.Parameter@691d29ad does not have a name 원인 분석 실제로 MongoDB에서 데이터를 정상 꺼내오는 로그는 다음과 같이 잘 찍혀있었습니다.\nCommand \u0026#34;find\u0026#34; succeeded on database \u0026#34;matchup_statistics_db\u0026#34; in 1.627834 ms using a connection with driver-generated ID 3 and server-generated ID 321 to localhost:3311. The request ID is 6 and the operation ID is 5. Command reply: {\u0026#34;cursor\u0026#34;: {\u0026#34;firstBatch\u0026#34;: [{\u0026#34;_id\u0026#34;: // 생략 또한, 이미 MongoDB에 데이터를 저장할 때는 문제없이 저장되었던 값을 꺼내오는 과정에서 오류가 발생했기 때문에, 꺼내온 값을 spring에서 mapping하는 과정에서 특정 파라미터를 인식하지 못해 발생했다고 생각했습니다.\n해결 1. 기본 생성자 추가 Spring에서 사용하는 mapping은 기본적으로 생성자를 통해 객체를 Reflection하기 때문에, 기본 생성자를 추가해야 합니다.(혹은 lombok의 @NoArgsConstructor) 해당 Collection의 Field에 들어가는 모든 클래스에 기본 생성자를 붙여주었지만 동일한 오류가 계속 발생했습니다.\n2. @Field 추가 MongoDB에서 객체를 생성해서 가져오는 과정에서 해당 어노테이션이 없으면 인식을 못해서 org.springframework.data.mapping.PropertyReferenceException 가 발생할 수 있다고 합니다.1 저와 다른 종류의 오류이기도 하고, 저는 해당 어노테이션 없이 해결이 되었지만 혹시 해결되지 않는 분들은 적용해보시기 바랍니다.\n3. Build Option : Intellij -\u0026gt; Gradle로 변경 해당 코드를 디버깅하면 다음 소스코드에서 null이 발생함을 알 수 있습니다. @Nullable private String[] getParameterNames(Parameter[] parameters) { String[] parameterNames = new String[parameters.length]; for (int i = 0; i \u0026lt; parameters.length; i++) { Parameter param = parameters[i]; if (!param.isNamePresent()) { return null; // null 발생 } parameterNames[i] = param.getName(); } return parameterNames; } 즉, 빌드 시점에 파라미터가 설정되지 않아 발생하는 문제이며 이는 Gradle로 실행 시 자동으로 해결됩니다. 자세한 설명은 해당 블로그를 참고하시기 바랍니다.\n저는 인텔리제이에서 빌드 옵션을 변경했더니 정상 실행이 되었습니다. Intellij에서 Gradle로 변경합니다.\n오류의 원인이 단순히 코드에만 있는 게 아니라, 프레임워크나 IDE등에 의해서도 충분히 발생할 수 있음을 항상 견지해야겠습니다. 그리고 프레임워크의 의존성을 줄여나가는 것도 좋은 방향이라고 생각합니다.\nReferences URL 게시일자 방문일자 작성자 https://ricma.co/posts/tech/dev/migrating-to-spring-61-javac-parameters 2023.09.22. 2024.04.02. Riccardo Macoratti https://stackoverflow.com/questions/36160919/caused-by-org-springframework-data-mapping-model-mappingexception-no-property 2016.03.22. 2024.04.02. user4821194 https://stackoverflow.com/questions/53207049/spring-data-mongo-no-property-b-found-on-entity-class-when-retrieving-entity-by/53210768#53210768 2018.11.08. 2024.04.02. J.Pip 쏘니의 개발블로그:티스토리\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/tips/org.springframework.data.mapping.mappingexception_%EC%98%A4%EB%A5%98_%ED%95%B4%EA%B2%B0/","summary":"상황 SpringBoot에서 MongoDB에 데이터를 저장하고, 저장한 데이터를 파싱하는 과정에서 다음과 같은 오류가 발생했습니다.\n실행 코드\n// 몽고DB 컬렉션 클래스 @Document(collection = \u0026#34;indicators\u0026#34;) @Getter @NoArgsConstructor @Builder @AllArgsConstructor @Slf4j public class Indicator { @Id private String id; private List\u0026lt;MatchIndicator\u0026gt; matchIndicators; private MatchIndicatorStatistics matchIndicatorStatistics; // 메서드 생략 } // 컬렉션 조회 메서드 @Override public Indicator getIndicatorInDB(String SummonerId) { Query query = Query.query( Criteria.where(\u0026#34;_id\u0026#34;).is(SummonerId)); Indicator indicators = mongoTemplate.findOne(query, Indicator.class, \u0026#34;indicators\u0026#34;); if (indicators == null) throw new RiotDataException(RiotDataError.","title":"Org.springframework.data.mapping.MappingException 오류 해결"},{"content":"상황 Controller 테스트 작성 시 mockMvc의 결과가 원하는 값과 일치하는지 확인하는 상황입니다. @Test @DisplayName(\u0026#34;[인수] 읽지 않은 알림 요청 시 전체응답(200)\u0026#34;) void testAllNotifications200() throws Exception { // given Cookie[] followingUserLoginCookie = mockMvc.perform(get(\u0026#34;/api/users/login\u0026#34;).header(HttpHeaders.AUTHORIZATION, \u0026#34;Bearer valid_token_2\u0026#34;)).andReturn().getResponse().getCookies(); Cookie[] myLoginCookie = mockMvc.perform(get(\u0026#34;/api/users/login\u0026#34;).header(HttpHeaders.AUTHORIZATION, \u0026#34;Bearer valid_token\u0026#34;)).andReturn().getResponse().getCookies(); // when // following -\u0026gt; user 팔로우 mockMvc.perform(post(\u0026#34;/api/users/\u0026#34; + me.getId() + \u0026#34;/follows\u0026#34;).cookie(followingUserLoginCookie)); // notifications 전체 조회 String responseBody = mockMvc.perform(get(\u0026#34;/api/users/notifications\u0026#34;).cookie(myLoginCookie)) .andExpect(status().is(200)).andReturn().getResponse().getContentAsString(); ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt; notificationDtos = objectMapper.readValue(responseBody, new TypeReference\u0026lt;ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt;\u0026gt;() {}); // then assertThat(notificationDtos.getList()).hasSize(1); assertThat(notificationDtos.getList().get(0).getDescription()).isEqualTo(\u0026#34;leaf2님이 당신을 팔로우합니다.\u0026#34;); } 테스트 결과 junit 테스트 결과(실패)\n원인 테스트 결과를 보면, 한글 인코딩이 깨져 있습니다. 기존에 MockMvc를 사용하면서 한글을 잘 검증하지 않았는데 이번 테스트에서는 한글을 검증하면서 이런 오류가 발생한 것 같습니다. 기본적으로 MockMVC는 *ISO-8859-1(Latin-1)*로 인코딩된다고 합니다. objectMapper는 UTF-8로만 디코딩하기 때문에 ISO-8859-1로 인코딩 된 값을 읽을 수 없습니다. 해결 다음 세가지 방법 중 하나를 사용하면 해결이 가능합니다. 1) UTF-8로 인코딩 결과값(content)을 UTF-8로 인코딩합니다. String responseBody = mockMvc.perform(get(\u0026#34;/api/users/notifications\u0026#34;).cookie(myLoginCookie)) .andExpect(status().is(200)).andReturn().getResponse().getContentAsString(StandardCharsets.UTF_8); // StandardCharset.UTF_8 추가 2) 결과값 byte 배열로 변환(인코딩 안하기) 다음과 같이 readValue 대상을 String 이 아닌 byte[]로 변경합니다. // notifications 전체 조회 byte[] responseBody = mockMvc.perform(get(\u0026#34;/api/users/notifications\u0026#34;).cookie(myLoginCookie)) // 기존 Return type : String .andExpect(status().is(200)).andReturn().getResponse().getContentAsByteArray(); // 기존 method : getContentAsString() ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt; notificationDtos = objectMapper.readValue(responseBody, new TypeReference\u0026lt;ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt;\u0026gt;() {}); 3) Server Default Encoding 추가 SpringBoot 서버의 기본 인코딩 설정을 변경합니다.\n# application.yml server: servlet: encoding: charset: UTF-8 force: true 테스트 결과 junit 테스트 결과(성공)\nReferences URL 게시일자 방문일자 작성자 https://github.com/spring-projects/spring-framework/issues/23219 2019.07.01. 2024.05.07. momega https://stackoverflow.com/questions/10004241/jackson-objectmapper-with-utf-8-encoding 2012.04.04. 2024.05.07. Patricio ","permalink":"https://1eaf.site/tips/object_mapper_nested_class_utf_8_%EC%9D%B8%EC%BD%94%EB%94%A9_%EC%98%A4%EB%A5%98_%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0/","summary":"상황 Controller 테스트 작성 시 mockMvc의 결과가 원하는 값과 일치하는지 확인하는 상황입니다. @Test @DisplayName(\u0026#34;[인수] 읽지 않은 알림 요청 시 전체응답(200)\u0026#34;) void testAllNotifications200() throws Exception { // given Cookie[] followingUserLoginCookie = mockMvc.perform(get(\u0026#34;/api/users/login\u0026#34;).header(HttpHeaders.AUTHORIZATION, \u0026#34;Bearer valid_token_2\u0026#34;)).andReturn().getResponse().getCookies(); Cookie[] myLoginCookie = mockMvc.perform(get(\u0026#34;/api/users/login\u0026#34;).header(HttpHeaders.AUTHORIZATION, \u0026#34;Bearer valid_token\u0026#34;)).andReturn().getResponse().getCookies(); // when // following -\u0026gt; user 팔로우 mockMvc.perform(post(\u0026#34;/api/users/\u0026#34; + me.getId() + \u0026#34;/follows\u0026#34;).cookie(followingUserLoginCookie)); // notifications 전체 조회 String responseBody = mockMvc.perform(get(\u0026#34;/api/users/notifications\u0026#34;).cookie(myLoginCookie)) .andExpect(status().is(200)).andReturn().getResponse().getContentAsString(); ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt; notificationDtos = objectMapper.readValue(responseBody, new TypeReference\u0026lt;ListDto\u0026lt;List\u0026lt;NotificationDto\u0026gt;\u0026gt;\u0026gt;() {}); // then assertThat(notificationDtos.getList()).hasSize(1); assertThat(notificationDtos.","title":"MockMvc Object mapper nested class utf-8 인코딩 오류 해결하기"},{"content":"환경 FrontEnd : Next.js { // package.json \u0026#34;node.js\u0026#34; : \u0026#34;20.11\u0026#34; \u0026#34;react\u0026#34; : \u0026#34;^18\u0026#34;, \u0026#34;next\u0026#34; : \u0026#34;14.2.1\u0026#34;, \u0026#34;cookie\u0026#34; : \u0026#34;^0.6.0\u0026#34;, \u0026#34;js-cookie\u0026#34; : \u0026#34;^3.0.5\u0026#34; } BackEnd : SpringBoot // build.gradle java { sourceCompatibility = \u0026#39;17\u0026#39; } plugins { id \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;3.2.4\u0026#39; id \u0026#39;io.spring.dependency-management\u0026#39; version \u0026#39;1.1.4\u0026#39; } dependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-redis\u0026#39; implementation \u0026#39;org.springframework.session:spring-session-data-redis\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-oauth2-client\u0026#39; implementation \u0026#39;org.springdoc:springdoc-openapi-starter-webmvc-ui:2.4.0\u0026#39; } 상황 프로젝트 중 로그인을 구현하기 위해 로컬에서 E2E 테스트를 진행하고 있었습니다. 프론트엔드 : http://localhost:3000 백엔드 : http://localhost:8080 대략적인 시퀀스는 다음과 같습니다. 로그인 시퀀스 다이어그램\n등록되지 않은 회원이 회원가입 시 다시 구글에 회원정보를 조회하지 않으려면, 로그인 시에 받아온 회원정보를 저장해야 했습니다. 이를 위해 회원가입 시 302 응답에 쿠키로 회원정보1를 저장해서 전송했고, 보안을 위해 Http-only, secure 옵션을 적용했습니다. 문제상황 localhost에서 테스트하는 과정에서 프론트엔드의 로그인 요청 후 Redirect 시 정상적으로 쿠키가 브라우저에 저장되지 않았습니다.\n더 이상한 점은 분명 개발자 도구에서 캡쳐한 네트워크 패킷에 쿠키가 있었는데도 이를 저장하지 못했다는 것입니다.\n[패킷 캡쳐 사진 추가]\n시도 쿠키관련 설정 변경 세션쿠키 영속쿠키로 변경 Cookie secure 해제 Cookie path 명시 Cookie domain 127.0.0.1 로 변경 // 기존 쿠키 생성 코드 public ResponseCookie getTimeoutCookie(String key, String value) { return ResponseCookie.from(key, URLEncoder.encode(value, StandardCharsets.UTF_8)) .path(\u0026#34;/register\u0026#34;) // 기존 : path(\u0026#34;/\u0026#34;) .domain(\u0026#34;127.0.0.1\u0026#34;) // 기존 : localhost .secure(false) // 기존 : True * sameSite 옵션과 함께 사용시 True 로 변경 .maxAge(sessionTimeout) // 기존 : 미작성(세션 쿠키) .build(); } Cors 관련 설정 확인 및 변경 Allow Origin 설정 Allow Method 설정 Credentials 설정 HttpHeader 노출 public CorsConfigurationSource getSource() { CorsConfiguration configuration = new CorsConfiguration(); // allow local configuration.addAllowedOrigin(\u0026#34;http://localhost:3000\u0026#34;); configuration.addAllowedHeader(\u0026#34;*\u0026#34;); configuration.setAllowedMethods(asList(\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;)); configuration.setAllowCredentials(true); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfuration(\u0026#34;/**\u0026#34;, configuration); return source; } 프론트엔드 쿠키 전달 fetch(apiUrl + \u0026#34;/users/login\u0026#34;, { headers: { Authorization: `Bearer ${accessToken}`, }, }) .then((response) =\u0026gt; { switch (response.status) { case 200: { window.history.go(-1); break; } case 302: { let setCookie = response.headers.get(\u0026#39;Set-Cookie\u0026#39;); console.log(setCookie) // 애초에 여기에 안찍힘 if (setCookie) { const parsed = cookie.parse(setCookie); cookies().set(\u0026#39;needRegist\u0026#39;, parsed[\u0026#39;isRegist\u0026#39;], parsed); cookies().set(\u0026#39;snsId\u0026#39;, parsed[\u0026#39;snsId\u0026#39;], parsed); cookies().set(\u0026#39;snsType\u0026#39;, parsed[\u0026#39;snsType\u0026#39;], parsed); cookies().set(\u0026#39;email\u0026#39;, parsed[\u0026#39;email\u0026#39;], parsed); } location.href = `/${locale}/register`; break; } } }).catch((error) =\u0026gt; console.log(error)); 현재 진행경과는 여기까지입니다. 추후 사건이 해결되면 최신화하도록 하겠습니다.\nReferences URL 게시일자 방문일자 작성자 https://github.com/ZeroCho/next-app-router-z/blob/master/ch4/src/auth.ts#L56 2024.02.20. 2024.05.02 ZeroCho 물론 민감한 회원정보가 아닌 이메일 주소, snsId, OAuth 에이전트 정보 정도만 쿠키로 전달했습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/coldcase/localhost_%EC%BF%A0%ED%82%A4_%EB%8F%84%EB%82%9C%EC%82%AC%EA%B1%B4/","summary":"환경 FrontEnd : Next.js { // package.json \u0026#34;node.js\u0026#34; : \u0026#34;20.11\u0026#34; \u0026#34;react\u0026#34; : \u0026#34;^18\u0026#34;, \u0026#34;next\u0026#34; : \u0026#34;14.2.1\u0026#34;, \u0026#34;cookie\u0026#34; : \u0026#34;^0.6.0\u0026#34;, \u0026#34;js-cookie\u0026#34; : \u0026#34;^3.0.5\u0026#34; } BackEnd : SpringBoot // build.gradle java { sourceCompatibility = \u0026#39;17\u0026#39; } plugins { id \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;3.2.4\u0026#39; id \u0026#39;io.spring.dependency-management\u0026#39; version \u0026#39;1.1.4\u0026#39; } dependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-redis\u0026#39; implementation \u0026#39;org.springframework.session:spring-session-data-redis\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-oauth2-client\u0026#39; implementation \u0026#39;org.springdoc:springdoc-openapi-starter-webmvc-ui:2.4.0\u0026#39; } 상황 프로젝트 중 로그인을 구현하기 위해 로컬에서 E2E 테스트를 진행하고 있었습니다.","title":"localhost_쿠키_도난사건"},{"content":"개요 프로젝트를 하던 중, 엔티티 연관관계에서 cascade를 잘못 사용하여 잘못된 엔티티가 삭제되었고, 테스트가 실패하는 상황이 발생했습니다.\n동일한 실수를 반복하지 않도록, 이번 기회에 JPA Cascade 개념과 Orphan Removal과는 어떠한 차이가 있는지 확인해보겠습니다.\nJPA(Hibernate) Cascade 먼저 Java EE 6의 가이드에는 다음과 같이 명시되어 있습니다.\nJava EE6 가이드의 CASCADE 설명\n설명을 읽어보면 Cascade는 영속성 컨텍스트(Persistence Context)에 부모(Cascade옵션을 작성하는 엔티티)가 특정 작업을 수행할 때, 연관된 엔티티(이후 자식이라고 하겠습니다)도 같은 작업을 수행해야 함을 명시하고 있습니다.\n자세한 내용은 Hibernate의 공식문서1 를 살펴보면 더욱 이해하기 좋은 것 같습니다.\n위 문서의 본문 예시를 참조하면 각 옵션의 주요 기능을 알 수 있습니다.2\n1. ALL 아래 모든 기능들을 포함하는 속성입니다. @Entity public class Person { @Id private Long id; private String name; // Cascade가 All로 설정되어 모든 옵션이 적용되어 있습니다. @OneToMany(mappedBy = \u0026#34;owner\u0026#34;, cascade = CascadeType.ALL) private List\u0026lt;Phone\u0026gt; phones = new ArrayList\u0026lt;\u0026gt;(); // Getter, Setter 생략 public void addPhone(Phone phone) { this.phones.add(phone); phone.setOwner(this); } } @Entity public class Phone { @Id private Long id; @Column(name = \u0026#34;`number`\u0026#34;) private String number; @ManyToOne(fetch = FetchType.LAZY) private Person owner; // Getter, Setter 생략 } 2. PERSIST3 DB에 저장될 때 자식을 함께 저장합니다. // given : Person과 phone 엔티티 생성 및 등록 Person person = new Person(); person.setId(1L); person.setName(\u0026#34;John Doe\u0026#34;); Phone phone = new Phone(); phone.setId(1L); phone.setNumber(\u0026#34;123-456-7890\u0026#34;); person.addPhone(phone); // when : person 저장 entityManager.persist(person); // then : 다음과 같이 2개의 Insert 쿼리가 나가면서 연관된 자식을 함께 저장합니다. INSERT INTO Person(name, id) VALUES( \u0026#39;John Doe\u0026#39;,1) INSERT INTO Phone( `number`, person_id, id) VALUES( \u0026#39;123-456-7890\u0026#39;,1,1) 3. MERGE4 부모의 상태를 병합할 때, 자동으로 자식의 상태를 함께 확인해서 병합합니다. // given : DB에서 엔티티 조회, 변경사항 생성 후 영속성 컨텍스트를 clear() -\u0026gt; 엔티티 분리 Phone phone = entityManager.find(Phone.class, 1L); Person person = phone.getOwner(); person.setName(\u0026#34;John Doe Jr.\u0026#34;); phone.setNumber(\u0026#34;987-654-3210\u0026#34;); entityManager.clear(); // when : person 병합(merge) entityManager.merge(person); // then : 객체를 채우기 위해 다음과 같이 자동으로 Fetch Join이 나가서 자식 엔티티의 값을 채웁니다. SELECT p.id as id1_0_1_, p.name as name2_0_1_, ph.owner_id as owner_id3_1_3_, ph.id as id1_1_3_, ph.id as id1_1_0_, ph.\u0026#34;number\u0026#34; as number2_1_0_, ph.owner_id as owner_id3_1_0_ FROM Person p LEFT OUTER JOIN Phone ph on p.id=ph.owner_id WHERE p.id = 1 4. REMOVE 부모가 삭제될 떄 자식을 함께 삭제합니다. 참고로 Hibernate에는 DELETE라는 속성도 있는데 같은 동작이라고 합니다. // given : person을 불러오기 Person person = entityManager.find(Person.class, 1L); // when : person 삭제 entityManager.remove(person); // then : 부모가 삭제되기 전 자식을 먼저 삭제합니다. DELETE FROM Phone WHERE id = 1 DELETE FROM Person WHERE id = 1 5. DETACH5 부모가 분리될 때, 자식도 함께 분리합니다. // given : person을 불러오기 Person person = entityManager.find(Person.class, 1L); Phone phone = person.getPhones().get(0); assertTrue(entityManager.contains(person)); assertTrue(entityManager.contains(phone)); // when : 영속성 컨텍스트에서 Person을 분리할 경우, entityManager.detach(person); // then : 부모가 컨텍스트에서 분리될 떄, 자식도 함께 분리합니다. assertFalse(entityManager.contains(person)); assertFalse(entityManager.contains(phone)); 6. Hibernate 추가 명세 Hibernate에서는 추가로 LOCK, REFRESH, REPLICATE 세가지 옵션을 더 지원합니다. Session에서 사용하는 위 세가지 메서드의 편의를 제공하기 위함입니다. CascadeType.LOCK6\n부모 조회 시 Lock이 될때 자식도 lock에 걸릴 것 같지만, 그렇게 동작하지는 않는다고 합니다.7 Lock 옵션을 적용하여 부모를 영속성 컨텍스트에 다시 불러오면(reattach), 자식도 함께 불러오는 옵션입니다. 아래 예시에서 session8의 Lock() 메서드를 통해 부모를 조회하면 자식 또한 함께 조회되는 것을 볼 수 있습니다. // given : person을 불러오기 Person person = entityManager.find(Person.class, 1L); assertEquals(1, person.getPhones().size()); Phone phone = person.getPhones().get(0); assertTrue(entityManager.contains(person)); assertTrue(entityManager.contains(phone)); // when : 부모 분리 후 lock메서드를 통해 session을 다시 불러올 경우 entityManager.detach(person); assertFalse(entityManager.contains(person)); assertFalse(entityManager.contains(phone)); entityManager.unwrap(Session.class) .lock(person, new LockOptions(LockMode.NONE)); // then : 부모, 자식 한번에 조회 assertTrue(entityManager.contains(person)); assertTrue(entityManager.contains(phone)); CascadeType.REFRESH9\n부모가 새로고침(Refresh) 될 때, 자식도 함께 새로고침하는 옵션입니다. 정합성 보장을 위해 DB와 영속성 컨텍스트를 일치화 후 작업해야 할 때 유용할 것 같습니다. // given : person을 불러오기 Person person = entityManager.find(Person.class, 1L); Phone phone = person.getPhones().get(0); // when : 엔티티 값 변경 후 새로고침하기 person.setName(\u0026#34;John Doe Jr.\u0026#34;); phone.setNumber(\u0026#34;987-654-3210\u0026#34;); entityManager.refresh(person); // then : 변경사항이 반영되지 않고, DB에 있는 값이 그대로 적용됨 assertEquals(\u0026#34;John Doe\u0026#34;, person.getName()); assertEquals(\u0026#34;123-456-7890\u0026#34;, phone.getNumber()); CascadeType.REPLICATE10\n부모가 다른 데이터소스를 수정할 때, 자식도 함께 수정하는 옵션입니다. CQRS 분리나 Scale Out등을 위해 여러 데이터소스를 함께 사용한다면 유용할 것 같습니다. // given : person과 phone 생성(저장하지 않은 상태) Person person = new Person(); person.setId(1L); person.setName(\u0026#34;John Doe Sr.\u0026#34;); Phone phone = new Phone(); phone.setId(1L); phone.setNumber(\u0026#34;(01) 123-456-7890\u0026#34;); person.addPhone(phone); // when : 다른 데이터소스에 있는 값 덮어쓰기 entityManager.unwrap(Session.class).replicate(person, ReplicationMode.OVERWRITE); // then : 다음과 같이 자동으로 다른 데이터소스를 수정하는 쿼리가 나갑니다. SELECT id FROM Person WHERE id = 1 SELECT id FROM Phone WHERE id = 1 UPDATE Person SET name = \u0026#39;John Doe Sr.\u0026#39; WHERE id = 1 UPDATE Phone SET \u0026#34;number\u0026#34; = \u0026#39;(01) 123-456-7890\u0026#39;, owner_id = 1 WHERE id = 1 지금까지 JPA와 Hibernate의 Cascade 옵션에 대해 알아보았습니다. 결국 영속성 컨텍스트에 부모-자식 엔티티를 한번에 불러오거나 생성, 변경, 삭제하는 옵션이라고 할 수 있겠습니다.\nOrphan Removal 다음은 Orphan Removal 옵션입니다.\n해당 옵션에 대한 설명은 JPA 기본 명세 45p에 잘 나와있습니다.(GPT 3.5 번역)\n일대일(OneToOne) 또는 일대다(OneToMany)로 지정된 연관 관계는 orphanRemoval 옵션을 사용할 수 있습니다. orphanRemoval이 적용될 때 다음과 같은 동작이 발생합니다:\n연관 관계의 대상이 되는 엔터티가 연관 관계에서 제거되면(예: 연관 관계를 null로 설정하거나 연관 관계 컬렉션에서 엔터티를 제거함으로써), 고아가 된 엔터티에 대해 삭제 작업이 적용됩니다. 삭제 작업은 플러시(flush) 작업 시점에 적용됩니다. orphanRemoval 기능은 부모 엔터티에 의해 개인적으로 \u0026ldquo;소유\u0026quot;되는 엔터티를 위해 의도된 것입니다. 이 기능을 사용할 경우, 응용 프로그램은 특정한 제거 순서에 의존해서는 안 되며, 고아가 된 엔터티를 다른 연관 관계에 재할당하거나 해당 엔터티를 지속(persist)하려고 시도해서는 안 됩니다. 고아가 된 엔터티가 분리(detached) 상태이거나, 새로 생성된 상태이거나, 삭제된 상태인 경우, orphanRemoval의 의미는 적용되지 않습니다.\n관리되는 소스 엔터티에 대해 삭제 작업이 적용되면, 삭제 작업은 섹션 3.2.311의 규칙에 따라 연관 관계의 대상 엔터티에 전파됩니다(따라서 연관 관계에 대해 cascade=REMOVE를 명시할 필요는 없습니다).\n즉, 일대일 또는 일대다 연관관계에서 부모 엔티티의 참조가 사라지면, 영속성 컨텍스트를 flush하는 시점에 자식 엔티티를 삭제합니다.\n또한, 부모 엔티티를 삭제하면 자동으로 cascade=REMOVE를 적용한 것과 같이 자식을 삭제하는 효과도 줍니다.\n// given : person을 불러오기 Person person = entityManager.find(Person.class, 1L); Phone phone = person.getPhones().get(0); assertEquals(phone.getId(), 1); // when : person에서 phone 참조값 제거 후 flush person.getPhones().set(0, null); entityManager.flush(); // then : 참조가 사라진 자식(고아) 엔티티를 삭제합니다. DELETE FROM Phone WHERE id = 1 결론 제가 잘못 이해하고 있던 부분은 CascadeType.REMOVE는 삭제되는게 아니라 영속성 컨텍스트에서 분리될 때 함께 분리된다고 생각한 점이었습니다(이 기능은 CascadeType.DETACH와 헷갈렸던 것 같습니다.). 사실 Orphan Removal과 CascadeType.REMOVE는 기능적으로는 동일하지만, REMOVE는 삭제(EntityManager.remove())를 명시할때만 발동되는 반면 Orphan Removal은 삭제 뿐 아니라 null이나 참조값 변경 등으로 참조가 없어질 때에도 삭제하는 것이 가장 큰 차이인 것 같습니다. 두루뭉실하게 알고 있던 지식들이 공식문서를 통해 접하니 좀더 확실하게 알게 된 느낌입니다. 앞으로도 잘 모르겠다 싶으면 공식문서를 참고하는 습관을 들여야겠습니다.\nReferences URL 게시일자 방문일자 작성자 https://docs.oracle.com/javaee/6/tutorial/doc/bnbqa.html#gjjnj 2013. 2024.05.13. Oracle https://docs.jboss.org/hibernate/orm/7.0/userguide/html_single/Hibernate_User_Guide.html 2024.05.03. 2024.05.13. Hibernate https://download.oracle.com/otndocs/jcp/persistence-2_2-mrel-eval-spec/index.html 2017.07.17. 2024.05.13. Oracle Hibernate는 JPA 명세의 구현체입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n쉬운 이해를 위해 별도의 예시를 만들기보다 본문 링크에 있는 예시를 최대한 그대로 시용하겠습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpring Data JPA의 Repository에서 save() 메서드에 해당합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJPA 공식문서에서는 Merge에 대해 다음과 같이 설명하고 있습니다.\nThe merge operation allows for the propagation of state from detached entities onto persistent entities managed by the entity manager. 병합(merge) 작업은 분리(detached)된 엔티티에서의 상태를 엔티티 매니저(entity manager)가 관리하는 영속 엔티티로 전파할 수 있도록 합니다.\n즉, 위 예시에서는 영속 상태의 엔티티를 영속성 컨텍스트에 불러오는 과정에서 Merge 옵션이 있으면 부모와 자식을 한번에 가져오는 것으로 이해할 수 있습니다. \u0026#160;\u0026#x21a9;\u0026#xfe0e; JPA 공식문서에서는 다음과 같은 상황에서 분리가 발생한다고 설명하고 있습니다.\n트랜잭션 스코프(persistence context)의 영속성 컨텍스트를 사용하는 경우, 트랜잭션 커밋 시 트랜잭션 롤백 시 엔티티를 영속성 컨텍스트에서 분리(detach)하는 경우 영속성 컨텍스트를 비우는 경우 엔티티 매니저를 닫는 경우 엔티티를 직렬화하거나 엔티티를 값으로 전달할 때(예: 다른 애플리케이션 계층으로, 원격 인터페이스를 통해 등) \u0026#160;\u0026#x21a9;\u0026#xfe0e; Lock은 트랜잭션 발생 시 데이터 경합(충돌)이 발생할 것을 예방하기 위해, 조회 시 다른 트랜잭션을 통해 DB가 변경되지 않도록 접근을 통제하는 것을 말합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n이렇게 동작시키기 위해서는 jakarta.persistence.lock.scope = PessimisticLockScope.EXTENDED 값을 사용해야 합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHibernate의 Session은 JPA의 영속성 컨텍스트를 구현한 개념입니다. 위 예제에서는 EntityManager의 unwrap() 메서드를 사용하여 Session을 획득한 후, lock() 메서드를 통해 잠금을 설정하고 있습니다. 이 때, CascadeType.LOCK 옵션을 통해 영속성 컨택스트에서 분리(detach)된 부모와 자식 엔티티를 한번에 가져오게 됩니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSession에서 영속성 컨텍스트와 실제 Database를 동일하게 맞추는 메서드입니다. 작업 과정에서 DB가 변경되거나 트리거가 실행되어 엔티티와 DB가 다를 때 새로고침을 하여 일치화하는 메서드입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSession에 있는 엔티티를 다른 데이터소스의 데이터와 일치화하는 메서드입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n섹션 3.2.3은 cascade=REMOVE에 대한 설명입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/concept/jpa_cascade_vs_mysql_cascade_vs_orphan_removal/","summary":"개요 프로젝트를 하던 중, 엔티티 연관관계에서 cascade를 잘못 사용하여 잘못된 엔티티가 삭제되었고, 테스트가 실패하는 상황이 발생했습니다.\n동일한 실수를 반복하지 않도록, 이번 기회에 JPA Cascade 개념과 Orphan Removal과는 어떠한 차이가 있는지 확인해보겠습니다.\nJPA(Hibernate) Cascade 먼저 Java EE 6의 가이드에는 다음과 같이 명시되어 있습니다.\nJava EE6 가이드의 CASCADE 설명\n설명을 읽어보면 Cascade는 영속성 컨텍스트(Persistence Context)에 부모(Cascade옵션을 작성하는 엔티티)가 특정 작업을 수행할 때, 연관된 엔티티(이후 자식이라고 하겠습니다)도 같은 작업을 수행해야 함을 명시하고 있습니다.","title":"JPA Cascade vs Orphan Removal"},{"content":"출처 https://school.programmers.co.kr/learn/courses/30/lessons/86052 접근 문제의 예시를 잘 살펴보면, 모든 위치에서 네 방향을 적어도 한번씩 방문하는 것을 볼 수 있습니다. 즉, 빛이 갈 수 있는 모든 경로를 탐색하면서 한번 탐색을 돌면서 방문한 경로는 같은 사이클이라고 할 수 있습니다. 이러한 사이클의 개수를 세서 정렬 후 출력하면 됩니다. 모든 경로를 탐색하는 점에서 DFS나 BFS 모두 구현이 가능합니다. 저는 DFS를 통해 빛의 경로를 따라서 탐색하는 것이 문제를 이해하는데 더 직관적이라고 생각하여 DFS로 구현하였습니다.\ngrid의 길이가 500 이하이므로 O(N^2) 알고리즘에서 4방향 탐색 시 최대 500 X 500 X 4 = 100,000의 시간복잡도가 필요해서 재귀적으로는 풀이할 수 없습니다.1 구현 구현에 도움이 되는 두 가지 스킬을 설명드리겠습니다.\n방향 전환 \u0026lsquo;S\u0026rsquo;인 칸은 방향전환을 할 필요가 없으니 기존 진행방향으로 통과시키면 됩니다. \u0026lsquo;R\u0026rsquo;인 칸은 시계방향으로 방향전환을 해야 하니, L -\u0026gt; U -\u0026gt; R -\u0026gt; D 순으로 방향을 전환해야 합니다. \u0026lsquo;L\u0026rsquo;인 칸은 반시계방향으로 전환을 해야 하니, L -\u0026gt; D -\u0026gt; R -\u0026gt; U 순으로 방향을 전환해야 합니다. 이를 다음과 같이 구현할 수 있습니다.\n// d : 0 -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; 3 (진입방향 int로 변경) // D : L -\u0026gt; U -\u0026gt; R -\u0026gt; D (진입방향 좌 -\u0026gt; 상 -\u0026gt; 우 -\u0026gt; 하) // R : 0 -\u0026gt; -1 -\u0026gt; 0 -\u0026gt; 1 (상하방향 움직임) // C : -1 -\u0026gt; 0 -\u0026gt; 1 -\u0026gt; 0 (좌우방향 움직임) int[] dr = {0, -1, 0, 1}; int[] dc = {-1, 0, 1, 0}; int d; // 초기 진입하는 방향 switch(g) { // g : 현재 격자 칸에 적힌 알파벳 // \u0026#39;S\u0026#39; : 그대로 진행 case \u0026#39;S\u0026#39;: break; // \u0026#39;R\u0026#39; : 현재 방향에서 1 증가시킴 case \u0026#39;R\u0026#39;: d++; d %= 4; break; // \u0026#39;L\u0026#39; : 현재 방향에서 1 감소시킴, 0보다 작아질 수 있으니 Modular로 회전 case \u0026#39;L\u0026#39;: d--; d += 4; d %= 4; break; } 격자 끝으로 이동 시 반대쪽으로 복귀 다음 위치로 이동했을 때 격자 끝이면, 반대쪽으로 나와야 합니다. 이를 다음과 같이 구현할 수 있습니다.\nint nr = r + dr[d]; // 다음 위치로 이동 nr += R; nr %= R; // 벽 크기만큼 더해준 뒤, 모듈러 연산을 통해 반대쪽 위치로 이동 int nc = c + dc[d]; // 다음 위치로 이동 nc += C; nc %= C; // 벽 크기만큼 더해준 뒤, 모듈러 연산을 통해 반대쪽 위치로 이동 Modular 연산을 통해 반대방향으로 이동하는 동작 원리는 연속 부분 수열 합의 개수 풀이에 자세히 설명되어 있습니다.\n풀이 import java.util.*; class Solution { // 격자 크기 int R, C; // 정답을 담을 동적 배열 List\u0026lt;Integer\u0026gt; answer = new ArrayList\u0026lt;\u0026gt;(); public int[] solution(String[] grid) { // 격자 크기 초기화 R = grid.length; C = grid[0].length(); // String[] 배열로부터 char[][] 배열 생성 char[][] grid_ = new char[R][C]; for (int i = 0; i \u0026lt; R; i++) grid_[i] = grid[i].toCharArray(); // 방문처리를 위한 배열 생성 boolean[][][] visited = new boolean[R][C][4]; // 각 격자 4방향 탐색 for (int r = 0; r \u0026lt; R; r++) { for (int c = 0; c \u0026lt; C; c++) { for (int d = 0; d \u0026lt; 4; d++) { // 방문한 방향의 빛은 재탐색하지 않음 if (visited[r][c][d]) continue; // DFS 수행(현재 위치 및 방향에서 1번 이동한 후 다음위치부터 DFS) dfs(new int[] {r, c, d}, move(grid_[r][c], r, c, d), grid_, visited); } } } // 동적배열 정렬 후 정적배열로 변환 answer.sort(Comparator.naturalOrder()); int[] ret = new int[answer.size()]; for (int i = 0; i \u0026lt; answer.size(); i++) ret[i] = answer.get(i); return ret; } // 깊이우선 탐색 void dfs(int[] start, int[] current, char[][] grid_, boolean[][][] visited) { // 스택을 활용한 깊이우선 탐색 Stack\u0026lt;int[]\u0026gt; s = new Stack\u0026lt;\u0026gt;(); // 처음 위치 방문처리 후 스택에 삽입 visited[current[0]][current[1]][current[2]] = true; s.push(new int[] {current[0], current[1], current[2], 1}); // 스택이 빌때까지 완전탐색 수행 while (!s.isEmpty()) { current = s.pop(); // 시작지점으로 돌아오면 DFS 종료 if (start[0] == current[0] \u0026amp;\u0026amp; start[1] == current[1] \u0026amp;\u0026amp; start[2] == current[2]) { answer.add(current[3]); return; } // 다음위치로 이동 int[] next = move(grid_[current[0]][current[1]], current[0], current[1], current[2]); // 방문처리 후 스택에 삽입 visited[next[0]][next[1]][next[2]] = true; s.push(new int[] {next[0], next[1], next[2], current[3] + 1}); } } // 빛의 이동 구현(현재위치, 방향, 알파벳을 토대로 다음 빛의 위치와 이동방향 반환) int[] dr = {0, -1, 0, 1}; int[] dc = {-1, 0, 1, 0}; int[] move(char g, int r, int c, int d) { // 방향 전환 switch(g) { case \u0026#39;S\u0026#39;: break; case \u0026#39;R\u0026#39;: d++; d %= 4; break; case \u0026#39;L\u0026#39;: d--; d += 4; d %= 4; break; } // 벽에 닿을 때 처리 int nr = r + dr[d]; nr += R; nr %= R; int nc = c + dc[d]; nc += C; nc %= C; return new int[] {nr, nc, d}; } } 결과 리뷰 완전탐색이라는 아이디어는 문제를 보자마자 바로 알 수 있어, 풀이방법을 생각하는건 어렵지 않은 문제인 것 같습니다. 구현이 까다로운 편인데, 배열을 탐색하면서 방향전환을 하는 부분이 처음 접하면 조금 힘들게 다가왔을 것 같습니다. 처음에 조건을 생각하지 않고 재귀적으로 DFS를 구현해서 StackOverflow가 발생했는데, 기본 조건을 잘 살펴보는 습관을 가져야겠습니다. References Link 게시일자 방문일자 작성자 OpenJDK 14 공식문서 - 2024.11.10. OpenJDK Oracle Java 8 공식문서 - 2024.11.10. Oracle 프로그래머스 컴파일 옵션을 확인해보면 다음과 같이 스택 크기는 별도 설정되어 있지 않아 기본값을 사용하는 것을 알 수 있습니다. 프로그래머스 컴파일 옵션\nJVM의 -Xss 옵션을 지정하여 스택 크기를 증가시킬 수 있는데, 64비트에서 기본값은 1(MB)로 되어있습니다. Java 8의 기본 쓰레드 스택 사이즈\nOpenJDK 14의 공식문서를 찾아보았지만, 기본 쓰레드 스택 사이즈 값을 찾을 수 없어 Oracle Java 8 공식문서를 확인했습니다. OpenJDK 14에서도 동일한 기본값을 사용할 것으로 보입니다.\n1MB(100,000Byte)의 스택 사이즈를 사용해 주어진 100,000번의 메서드를 호출하기 위해서는 메서드의 크기를 1Byte 이내로 사용해야 하지만 이는 불가능하므로 재귀 호출 시 StackOverflow가 발생합니다.\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"https://1eaf.site/cote/programmers_%EB%B9%9B%EC%9D%98_%EA%B2%BD%EB%A1%9C_%EC%82%AC%EC%9D%B4%ED%81%B4/","summary":"출처 https://school.programmers.co.kr/learn/courses/30/lessons/86052 접근 문제의 예시를 잘 살펴보면, 모든 위치에서 네 방향을 적어도 한번씩 방문하는 것을 볼 수 있습니다. 즉, 빛이 갈 수 있는 모든 경로를 탐색하면서 한번 탐색을 돌면서 방문한 경로는 같은 사이클이라고 할 수 있습니다. 이러한 사이클의 개수를 세서 정렬 후 출력하면 됩니다. 모든 경로를 탐색하는 점에서 DFS나 BFS 모두 구현이 가능합니다. 저는 DFS를 통해 빛의 경로를 따라서 탐색하는 것이 문제를 이해하는데 더 직관적이라고 생각하여 DFS로 구현하였습니다.\ngrid의 길이가 500 이하이므로 O(N^2) 알고리즘에서 4방향 탐색 시 최대 500 X 500 X 4 = 100,000의 시간복잡도가 필요해서 재귀적으로는 풀이할 수 없습니다.","title":"[Java]Programmers 빛의 경로 사이클"},{"content":"출처 https://school.programmers.co.kr/learn/courses/30/lessons/131701 접근 원소의 길이가 1,000 이하이기 때문에 N^2 알고리즘을 사용해도 풀이가 가능합니다. 각 수열의 시작점에서 인덱스를 1칸씩 증가시키면서 합의 가지수를 찾는 문제입니다. 인덱스는 원형으로 연결되어 있기 때문에, 전체 수열의 길이보다 큰 인덱스는 다시 0부터 시작해야 합니다. 원형 배열을 구현하기 위해 다음과 같이 modular연산을 사용하면 쉽게 구현이 가능합니다. 예시에서 주어진 수열 [7, 9, 1, 1, 4]에서 원형 배열을 더하는 방법을 알아보겠습니다. 현재 값이 9(idx == 1)일때 이후의 값들은 다음과 같습니다. 현재 값이 9일 때, 이후의 값 위치\nnow + 1 ~ 3 까지는 쉽게 구할 수 있지만, now + 4는 인덱스를 초과해버립니다. 이 때, 다음과 같이 배열의 길이만큼 modular 연산을 하면 해당 인덱스를 다시 0부터 시작하도록 만들 수 있습니다. modular를 사용해서 원형 배열처럼 만들기\n현재 값이 1(idx == 2)일때도 modular 연산을 통해 다음과 같이 원형 배열로 만들 수 있습니다. modular를 사용해서 원형 배열처럼 만들기2\n이후에는 현재 값부터 원형으로 현재 값 이전까지 모든 값들을 더하면서 합의 가짓수를 찾아나가면 됩니다. 저는 set를 활용해서 중복되는 값을 제거하였습니다.\n풀이 import java.util.*; class Solution { public int solution(int[] elements) { // 합 저장 Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; elements.length; i++) { set.add(elements[i]); int sum = elements[i]; // 현재 인덱스 + 1 ~ 현재 인덱스 -1까지 확인 for (int j = i + 1; j \u0026lt; i + elements.length; j++) { // modular 연산을 통해 원형 수열 구현 int k = j % elements.length; sum += elements[k]; set.add(sum); } } // 전체 합 개수 반환 return set.size(); } } 결과 리뷰 배열의 인덱스를 원형처럼 사용하는 방법만 알면 쉽게 풀 수 있는 문제입니다. 이러한 접근방법은 알고리즘 문제에서 자주 등장하기도 하고, 자료구조 중 배열로 Dequeue를 구현할 때에도 자주 사용되는 방법이니 알아두시면 좋을 것 같습니다.\nReferences URL 게시일자 방문일자 작성자 ","permalink":"https://1eaf.site/cote/programmers_%EC%97%B0%EC%86%8D_%EB%B6%80%EB%B6%84_%EC%88%98%EC%97%B4_%ED%95%A9%EC%9D%98_%EA%B0%9C%EC%88%98/","summary":"출처 https://school.programmers.co.kr/learn/courses/30/lessons/131701 접근 원소의 길이가 1,000 이하이기 때문에 N^2 알고리즘을 사용해도 풀이가 가능합니다. 각 수열의 시작점에서 인덱스를 1칸씩 증가시키면서 합의 가지수를 찾는 문제입니다. 인덱스는 원형으로 연결되어 있기 때문에, 전체 수열의 길이보다 큰 인덱스는 다시 0부터 시작해야 합니다. 원형 배열을 구현하기 위해 다음과 같이 modular연산을 사용하면 쉽게 구현이 가능합니다. 예시에서 주어진 수열 [7, 9, 1, 1, 4]에서 원형 배열을 더하는 방법을 알아보겠습니다. 현재 값이 9(idx == 1)일때 이후의 값들은 다음과 같습니다. 현재 값이 9일 때, 이후의 값 위치","title":"[Java]Programmers 연속 부분 수열 합의 개수"},{"content":"출처 해커 랭크 : Lego Blocks 문제 설명 영문 사이트이므로 문제를 간단히 설명하겠습니다. 다음과 같은 총 네 가지 종류의 레고 블럭이 무한히 있습니다. d\th\tw 1\t1\t1 [] : 길이가 1이고, 높이가 1인 레고 블럭 1\t1\t2 [ ] : 길이가 2이고, 높이가 1인 레고 블럭 1\t1\t3 [ ] : 길이가 3이고, 높이가 1인 레고 블럭 1\t1\t4 [ ] : 길이가 4이고, 높이가 1인 레고 블럭 문제에서 주어지는 높이와 길이만큼 레고 블럭을 쌓으려고 합니다.\n이 때, 다음과 같이 수직으로 동일한 블럭이 쌓여있는 형태의 블럭은 단단하지 않아서1 만들 수 없습니다. Good layouts는 단단하게 연결되어 있지만, Bad layouts는 연결되어 있지 않아 분리될 수 있습니다.\n주어진 높이 n, 길이 m의 블럭을 만들 수 있는 모든 경우의 수를 구해야 합니다.\n접근 레고의 높이(n), 길이(m)가 최대 1000이므로 완전탐색으로 모든 경우의 수를 구하는 것은 불가능하며, 길이 2, 높이 1000의 블럭을 쌓는 모든 경우의 수만 해도 벌써 2^1000입니다.2 그래서 문제에서도 소수 모듈러 연산으로 크기를 줄이고 있습니다.\n이 문제에서는 전체 경우의 수를 귀납적으로 구하고, 전체에서 단단하지 않은 레고의 경우를 빼는 방식으로 단단한 레고의 경우를 구해야 합니다. 흐름 큰 문제해결의 흐름은 다음과 같습니다.\n해당 길이만큼 레고를 만들 수 있는 모든 경우의 수 찾기 row[m]\n해당 높이만큼 레고를 쌓기 row[m] ^ n = col[m]\n모든 경우의 수에서 단단하지 않은 레고의 경우의 수 빼기 col[m] - notSolidCol[m] = solidCol[m]\n풀이 위 흐름에서처럼 총 3단계로 걸쳐 단계별 설명과 코드를 함께 확인해보겠습니다.\n귀납적으로 레고 블럭 개수 구하기 레고 블럭의 길이가 4 이하인 경우와, 이상인 경우를 분리해서 개수를 구해보겠습니다.\n레고 블럭의 길이가 1 증가할 때마다 발생하는 경우의 수\n[N = 1일 때]\n그냥 1인 블럭 1개만 사용 가능합니다.\nrow[1] = 1\n[N = 2일 때]\n맨 앞을 크기가 1인 블럭으로 고정시키면, 뒤에는 1인 블럭 1개(row[1])만 올 수 있습니다. 크기가 2인 블럭 1개를 사용할 수 있습니다. row[2] = row[1] + 1 = 2\n[N = 3일 때]\n맨 앞을 N = 1인 블럭으로 고정시켰을 때, 뒤의 2칸은 row[2]인 경우의 수와 같습니다. 맨 앞을 N = 2인 블럭으로 고정시켰을 때, 뒤의 1칸은 row[1]인 경우의 수와 같습니다. 크기가 3인 블럭 1개를 사용할 수 있습니다. row[3] = (row[2] + row[1]) + 1 = 4\n[N \u0026lt;= 4일 때]\n레고 블럭의 길이가 1 증가할 때마다, 전체 경우의 수는 다음과 같이 구할 수 있습니다.\n(맨 앞 블럭을 (N = 1 ~ N-1)까지 고정시킨 경우의 수의 합) + 현재 블럭(1)\nrow[N] = (row[N - 1] + row[N - 2] + \u0026hellip; + row[1]) + 1\n[N \u0026gt; 4일 때]\n레고 블럭의 길이는 최대 4까지만 증가하므로3, 맨 앞 블럭을 1 ~ 4까지만 고정시킬 수 있으므로 다음과 같습니다.\n맨 앞 블럭을 (N = 1 ~ 4)까지 고정시킨 경우의 수의 합\nrow[N] = row[N - 1] + row[N - 2] + row[N - 3] + row[N - 4]\n위의 귀납식을 다음과 같이 DP를 사용한 코드로 나타낼 수 있습니다.\npublic static int legoBlocks(int n, int m) { // Row 개수 구하기 long[] row = new long[m + 1]; for (int i = 1; i \u0026lt;= m; i++) { if (i \u0026lt;= 4) { row[i] = 1; for (int j = 1; j \u0026lt; i; j++) row[i] += row[j]; } else { // Overflow 방지를 위한 MOD 연산 // MOD = (int)Math.pow(10, 9) + 7; row[i] = (row[i - 1] + row[i - 2] + row[i - 3] + row[i - 4]) % MOD; } } // ... } 레고 블럭을 쌓는 모든 경우의 수 구하기 단단한 블럭인지를 확인하지 않고, 모든 경우를 구하면 되므로 다음과 같이 구할 수 있습니다.\n해당 길이의 블럭의 수 ^ 블럭의 높이 col[m] = row[m] ^ n\n이를 코드로 다음과 같이 나타낼 수 있습니다\nMath.pow(x, y) 연산을 하게 되면 Overflow가 발생하므로 다음과 같이 곱셈 후 모듈러 연산을 해야합니다.\npublic static int legoBlocks(int n, int m) { // ...(생략) // 레고 블럭을 쌓는 모든 경우의 수 저장하기 long[] col = new long[m + 1]; for (int i = 0; i \u0026lt;= m; i++) { col[i] = 1; for (int j = 1; j \u0026lt;= n; j++) { col[i] *= row[i]; // Overflow 방지를 위한 MOD 연산 col[i] %= MOD; } } // ...(생략) } 단단하지 않은 블럭인 경우 빼기 단단하지 않은 블럭의 수 구하기는 앞에서 구했던 귀납적으로 블럭의 수 구하기와 유사합니다.\n레고 블럭의 길이가 1 증가할 때마다 발생하는 경우의 수\n위와 같이 j를 고정시켜두면, 나머지 길이(m - j)에서 어떻게 블럭을 쌓더라도 단단하지 않은 경우가 됩니다. 이 때, (m - j)에서 블럭을 쌓는 모든 경우의 수는 위에서 구한 값을 활용할 수 있습니다.\n길이가 (m - j)인 단단하지 않은 블럭 : col[m - j]\n이를 코드로 표현하면 다음과 같습니다.\npublic static int legoBlocks(int n, int m) { // ...(생략) // Solid하지 않은 경우 빼서 Solid한 경우만 구하기 long[] solidCol = new long[m + 1]; solidCol[1] = 1; // 길이가 1일 때는 크기가 1인 블럭을 쌓는 1가지 경우밖에 없음 for (int i = 2; i \u0026lt;= m; i++) { long temp = col[i]; // 전체 경우의 수로 초기화 for (int j = 1; j \u0026lt; i; j++) { // 길이를 1씩 증가시키면서 단단하지 않은 경우 빼기 temp -= solidCol[j] * col[i - j]; // Overflow 방지를 위한 MOD 연산 temp %= MOD; } // Overflow 방지를 위한 MOD 연산2 solidCol[i] = (temp + MOD) % MOD; // 연산 전 MOD를 더해서 계산 결과가 -인 경우 처리 } // m번째 단단한 레고블럭 개수 출력 return (int)solidCol[m]; } 결과 전체 코드\npublic static int legoBlocks(int n, int m) { // Row 개수 구하기 long[] row = new long[m + 1]; for (int i = 1; i \u0026lt;= m; i++) { if (i \u0026lt;= 4) { row[i] = 1; for (int j = 1; j \u0026lt; i; j++) row[i] += row[j]; } else { row[i] = (row[i - 1] + row[i - 2] + row[i - 3] + row[i - 4]) % MOD; } } // Row X Col 총 개수 구하기 long[] col = new long[m + 1]; for (int i = 0; i \u0026lt;= m; i++) { col[i] = 1; for (int j = 1; j \u0026lt;= n; j++) { col[i] *= row[i]; col[i] %= MOD; } } // Solid하지 않은 경우 빼서 Solid한 경우만 구하기 long[] solidCol = new long[m + 1]; solidCol[1] = 1; for (int i = 2; i \u0026lt;= m; i++) { long temp = col[i]; for (int j = 1; j \u0026lt; i; j++) { temp -= solidCol[j] * col[i - j]; temp %= MOD; } solidCol[i] = (temp + MOD) % MOD; } return (int)solidCol[m]; } 결과 리뷰 넥슨 코딩테스트를 준비하면서 HackerRank의 문제들을 처음 풀어봤습니다.\n문제별로 난이도 차이가 있는 것 같은데, 이 문제만 유난히 어려워서 많이 고민했고 결국 Discussion에 있는 풀이들을 보고 나서야 이해할 수 있었습니다.\nDP의 개념을 익힐 수 있는 좋은 문제인 것 같습니다.\nReferences URL 게시일자 방문일자 작성자 https://www.hackerrank.com/challenges/one-week-preparation-kit-lego-blocks/forum?isFullScreen=true\u0026amp;h_l=interview\u0026amp;playlist_slugs%5B%5D=preparation-kits\u0026amp;playlist_slugs%5B%5D=one-week-preparation-kit\u0026amp;playlist_slugs%5B%5D=one-week-day-six - 2024.10.26. - 영문으로는 one solid structure를 만들어야 한다고 하는데, 레고 블럭이 두개로 분리되지 않는 형태를 말합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n길이가 2인 블럭은 2가지 경우가 있고([][], [ ]), 이를 높이 1000으로 쌓는 경우이므로 2^1000입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n문제 설명에서 보듯이 레고 블럭은 길이 1 ~ 4까지 총 4가지 종류만 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/hackerrank_lego_blocks/","summary":"출처 해커 랭크 : Lego Blocks 문제 설명 영문 사이트이므로 문제를 간단히 설명하겠습니다. 다음과 같은 총 네 가지 종류의 레고 블럭이 무한히 있습니다. d\th\tw 1\t1\t1 [] : 길이가 1이고, 높이가 1인 레고 블럭 1\t1\t2 [ ] : 길이가 2이고, 높이가 1인 레고 블럭 1\t1\t3 [ ] : 길이가 3이고, 높이가 1인 레고 블럭 1\t1\t4 [ ] : 길이가 4이고, 높이가 1인 레고 블럭 문제에서 주어지는 높이와 길이만큼 레고 블럭을 쌓으려고 합니다.","title":"[Java]HackerRank Lego Blocks"},{"content":"한줄평 추상적인 객체지향의 개념을 구현하기 위한 책\n책을 읽게 된 계기 지인 추천으로 읽게 되었습니다.\n작가 소개 조영호\n객체지향 설계와 도메인-주도 설계에 관심이 많으며 행복한 팀과 깔끔한 코드가 훌륭한 소프트웨어를 낳는다는 믿음을 증명하기 위해 노력하고 있다. LG-CNS, 네이버, 쿠팡을 거치며 개발이라는 창조적인 작업의 즐거움을 만끽했으며, NHN NEXT에서 후배들을 양성하며 지식을 공유하는 즐거움을 누리기도 했다. 현재는 다음카카오에서 사용자에게 가치를 제공할 수 있는 다양한 서비스 개발에 참여하고 있다. 소프트웨어 개발과 관련된 경험과 정보를 공유하기 위해 ‘이터너티(Eternity)’라는 필명으로 블로그(http://aeternum.egloos.com/)를 운영하고 있다.\n핵심요약 저자는 객체지향의 특성을 다양한 측면에서 바라보면서 본질이 무엇인지 계속 고민해나갑니다. 그리고 이러한 과정에서 잘못 알려진 개념과 지식들을 바로잡습니다.\n객체와 타입은 다르며, 객체를 심볼, 외연, 내연으로 분류한 것이 타입이다. 타입은 개념과 동의어이다. 또한, 클래스와 타입은 다르며, 클래스는 타입을 구현하기 위한 수단일 뿐이다. 또한, 클래스는 코드를 재사용할 때에도 사용되기 때문에 타입이라고 할 수 없다. 역할, 책임, 협력을 통해 여러 객체가 상호작용하여 시스템을 구성한다. 이러한 객체의 상호작용은 \u0026lsquo;메시지\u0026rsquo;를 통해서만 전달되며, 이러한 메시지는 공용 인터페이스로 표현된다. 책임은 \u0026lsquo;자율적\u0026rsquo;으로 구성되어야 하며, 이는 다른 객체에게 너무 많은 메시지를 통해 행동을 제약하지 않아야 한다는 것이다. 프로그램을 설계하는 과정에서 객체를 먼저 고민하지 말고, 어떤 메시지를 주고받을지를 먼저 고민하면 훨씬 안정된 구조를 만들 수 있다. 지도 하나를 통해 다양한 길을 찾을 수 있는 것처럼, 도메인 모델을 만들면 다양한 문제를 해결할 수 있다. 인상깊은 구절 재귀적으로 컴퓨터를 객체라고 불리는 더 작은 컴퓨터로 분할1 위 구절이 객체지향 프로그래밍에서의 객체를 가장 본질적으로 나타냈다는 생각이 들어 인상깊었습니다. 서버2와 시스템, 심지어 JVM도 컴퓨터 내에서 동작하는 객체이면서 작은 컴퓨터라는 생각이 들었습니다. 결국 이러한 객체들은 작은 컴퓨터처럼 저장공간(객체 - 속성 / 컴퓨터 - 메모리)에 있는 데이터를 통해 특정 연산(객체 - 메서드 / 컴퓨터 - CPU)을 수행합니다.\n평가 추상적인 개념을 다양한 방향에서 접근할 수 있어 좋았습니다. 장님이 코끼리를 보려면 다양한 각도에서 직접 만져봐야 하는 것처럼, 추상적인 개념을 알기 위해서는 다양한 방향에서 확인하는 것이 효과적인 것 같습니다. 중간에 \u0026lsquo;이상한 나라의 앨리스\u0026rsquo;의 상황이나, 실제 커피 주문 시스템의 설계 과정을 통해 더욱 쉽게 이해할 수 있었습니다. 다만, 객체지향을 처음 접하는 분이라면 추상적인 이야기가 많아 조금 이해하기 어려울 수 있을 것 같습니다. 느낀점 어렴풋이 언어적 느낌으로만 알던 추상적인 지식이 책의 설명으로 구체화된 것 같습니다. 나중에 좀더 객체지향에 대해 깊이 이해하고 다시 읽으면 또 다른 느낌일 것 같아 주기적으로 읽어보려고 합니다. 객체지향을 잘하는 개발자들은 비유를 참 잘 드는 것 같습니다. 추천 객체지향의 개념이 헷갈리거나, 어느 정도의 경험은 있지만 이론적인 지식이 필요한 분들이 읽으면 좋을 것 같습니다. 저처럼 초보 개발자들이 어떻게 공부해가야 할지 감을 잡을 수 있도록 쉬운 예시와 다양한 레퍼런스 서적들이 제시되고 있어, 초보 개발자들에게 더욱 추천합니다. References URL 게시일자 방문일자 작성자 https://www.kyobobook.co.kr/service/profile/information?chrcCode=1001590703 미확인 240710 교보문고 203p 그림 6.12\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n실제로 SpringBoot에서는 Tomcat이라는 서버 객체가 Application Context 내 객체로 존재합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/review/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98_%EC%82%AC%EC%8B%A4%EA%B3%BC_%EC%98%A4%ED%95%B4/","summary":"한줄평 추상적인 객체지향의 개념을 구현하기 위한 책\n책을 읽게 된 계기 지인 추천으로 읽게 되었습니다.\n작가 소개 조영호\n객체지향 설계와 도메인-주도 설계에 관심이 많으며 행복한 팀과 깔끔한 코드가 훌륭한 소프트웨어를 낳는다는 믿음을 증명하기 위해 노력하고 있다. LG-CNS, 네이버, 쿠팡을 거치며 개발이라는 창조적인 작업의 즐거움을 만끽했으며, NHN NEXT에서 후배들을 양성하며 지식을 공유하는 즐거움을 누리기도 했다. 현재는 다음카카오에서 사용자에게 가치를 제공할 수 있는 다양한 서비스 개발에 참여하고 있다. 소프트웨어 개발과 관련된 경험과 정보를 공유하기 위해 ‘이터너티(Eternity)’라는 필명으로 블로그(http://aeternum.","title":"객체지향의 사실과 오해"},{"content":"출처 https://www.acmicpc.net/problem/16236 접근 알고리즘 시작지점부터 가장 가까운 물고기부터 탐색합니다. 문제 조건에서 주어진 물고기를 선택하는 기준을 만족하기 위해, Heap1에 다음 물고기를 넣어 정렬하였습니다. 다음 물고기가 먹을 수 있는 물고기라면, 해당 위치를 시작점으로 다시 BFS를 수행합니다. 시간복잡도 고민 BFS로 물고기를 먹으러 이동하면서 걸리는 시간 : O(N^2) 이동하면서 물고기를 정렬하는 시간(Priority Queue 사용 시) : O(NlogN) N = 20 이므로 시간복잡도 내 충분히 가능하다고 판단했습니다.\n유의사항 PriorityQueue를 정렬할 때, Integer의 유틸리티 메서드인 compare()를 활용하면 좋다고 합니다.2 물고기를 먹은 뒤 해당 위치에서 BFS를 다시 수행하기 위해 방문 배열을 초기화하는 로직이 필요합니다. 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; /* * [조건] * 시간 제한 : 2초 / 메모리 제한 512MB * [풀이] * 오른쪽 아래부터 역으로 공간을 돌면서 가장 가까운 물고기의 위치를 확인한다.(N^2) * 해당 물고기를 먹으러 이동하면서 걸리는 시간을 측정한다.(N^2) * 더이상 이동할 수 없거나, 모든 칸이 빌때까지 이를 반복한다(N^2) * =\u0026gt; N^6 = 20^6 = 32 x 10^6 이므로 시간복잡도 내 가능 * 시작지점부터 가장 가까운 물고기를 탐색한다. * 해당 지점까지 bfs로 이동하여 해당 지점이 나오면 걸린 시간을 현재시간에 더한다. * 더이상 이동이 불가능하다면 현재 시간을 출력한다. * 이동이 가능하다면 먹은 횟수를 더하고, 먹은 횟수가 상어의 크기만큼 쌓이면 상어 크기를 1 늘린다. */ public class bj_16236_아기_상어 { static int N, eatCount, size = 2; static int[] start; static int[][] space; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); N = Integer.parseInt(br.readLine()); space = new int[N][N]; start = new int[2]; for (int i = 0; i \u0026lt; N; i++) { StringTokenizer st = new StringTokenizer(br.readLine()); for (int j = 0; j \u0026lt; N; j++) { int now = Integer.parseInt(st.nextToken()); if (now == 9) start = new int[]{i, j}; space[i][j] = now; } } System.out.println(bfs()); } // 먹을 수 있는 물고기가 더 없을떄까지 bfs 이동 static int[] dr = {-1, 0, 0, 1}; static int[] dc = {0, -1, 1, 0}; private static int bfs() { boolean[][] visited = new boolean[N][N]; // 우선순위 큐 : 거리 \u0026gt; 위 \u0026gt; 왼쪽 순으로 내부 정렬 PriorityQueue\u0026lt;int[]\u0026gt; q = new PriorityQueue\u0026lt;\u0026gt;((o1, o2) -\u0026gt; { if (o1[2] != o2[2]) return Integer.compare(o1[2], o2[2]); // Integer.compare() 메서드 활용 if (o1[0] != o2[0]) return Integer.compare(o1[0], o2[0]); return Integer.compare(o1[1], o2[1]); }); int ret = 0; q.offer(new int[] {start[0], start[1], 0}); visited[start[0]][start[1]] = true; while (!q.isEmpty()) { int[] now = q.poll(); // 자신보다 작은 물고기를 만났을 때 : 해당 물고기를 먹은 후 큐를 비우고 다시 bfs 시작 int fish = space[now[0]][now[1]]; if (fish != 0 \u0026amp;\u0026amp; fish \u0026lt; size) { if (++eatCount \u0026gt;= size) { size++; eatCount = 0; } // 이동시간 갱신 ret += now[2]; // bfs 초기화 + 방문배열 초기화 q.clear(); q.offer(new int[]{now[0], now[1], 0}); for (int j = 0; j \u0026lt; N; j++) Arrays.fill(visited[j], false); visited[now[0]][now[1]] = true; // 공간 변화 : 아기상어 위치 이동 + 최초위치 아기상어 칸 비우기 space[now[0]][now[1]] = 9; space[start[0]][start[1]] = 0; start = new int[]{now[0], now[1]}; continue; } for (int i = 0; i \u0026lt; 4; i++) { int nr = now[0] + dr[i]; int nc = now[1] + dc[i]; if (nr \u0026lt; 0 || nr \u0026gt;= N || nc \u0026lt; 0 || nc \u0026gt;= N) continue; if (visited[nr][nc] || space[nr][nc] \u0026gt; size) continue; visited[nr][nc] = true; q.offer(new int[] {nr, nc, now[2] + 1}); } } return ret; } } 결과 리뷰 먹을 수 있는 가장 가까운 물고기의 위치를 구하기 위해 BFS를 문제의 조건에 맞게 구현하는 문제였습니다. 최단거리를 구할 때 기본적으로 BFS를 고려하는 습관을 들여야겠습니다.\nCompareTo를 구현하기 위해 Integer의 유틸리티 메서드를 활용하는 것이 좋다는 것을 이펙티브 자바를 읽으며 알게 되었고, 실제로 활용해볼 수 있었습니다. 접근방법을 알면 생각보다 간단히 구현할 수 있는 문제이지만, 구현 과정에서 디버깅하면서 1시간 정도 소요되었습니다. 이럴 때 IDE의 디버깅 모드를 활용할지 고민이지만, 프로그래머스 같은 웹 환경에서 코딩테스트에 익숙해지기 위해 최대한 console만으로 디버깅하는 연습을 하려고 노력중입니다. 구현 문제는 꾸준히 연습해야 시간을 단축할 수 있는 것 같습니다.\nReferences URL 게시일자 방문일자 작성자 Heap을 구현한 PriorityQueue를 사용했습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n이펙티브 자바(Effective Java 3/E) \u0026ldquo;Item 14 : Comparable을 구현할지 고려하라\u0026rdquo; 참조\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_16236_%EC%95%84%EA%B8%B0_%EC%83%81%EC%96%B4/","summary":"출처 https://www.acmicpc.net/problem/16236 접근 알고리즘 시작지점부터 가장 가까운 물고기부터 탐색합니다. 문제 조건에서 주어진 물고기를 선택하는 기준을 만족하기 위해, Heap1에 다음 물고기를 넣어 정렬하였습니다. 다음 물고기가 먹을 수 있는 물고기라면, 해당 위치를 시작점으로 다시 BFS를 수행합니다. 시간복잡도 고민 BFS로 물고기를 먹으러 이동하면서 걸리는 시간 : O(N^2) 이동하면서 물고기를 정렬하는 시간(Priority Queue 사용 시) : O(NlogN) N = 20 이므로 시간복잡도 내 충분히 가능하다고 판단했습니다.\n유의사항 PriorityQueue를 정렬할 때, Integer의 유틸리티 메서드인 compare()를 활용하면 좋다고 합니다.","title":"[Java]백준 16236 아기 상어"},{"content":"출처 https://www.acmicpc.net/problem/2573 접근 각 칸이 10이하이고 전체 칸은 10,000이므로 빙산을 모두 녹이려면 10 _ 10,000 _ 10,000이지만, 네 변이 노출되면 금방 사라지므로 완전탐색이 가능하다고 판단했습니다. 매 회마다 빙산을 녹이고, 빙산을 bfs(dfs)로 탐색해서 두 덩어리가 있는지 확인한다. 모든 빙산이 다 녹았지만 2개로 분리되지 않는 경우를 주의한다.1 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; /* * [조건] * 시간제한 : 1초, 메모리 제한 : 256MV * 이차원 배열의 크기가 300^2 이하이며 전체 칸의 개수는 10,000개 이하, 각 칸의 크기는 10 이하 * [풀이] * 각 칸이 10이하이고 전체 칸은 10,000이므로 빙산을 모두 녹이려면 10 * 10,000 * 10,000이지만, 네 변이 노출되면 금방 사라지므로 완전탐색 * 매 회마다 빙산을 녹이고, 빙산을 bfs로 탐색해서 두 덩어리가 있는지 확인한다. */ public class bj_2573_빙산 { static int N, M, count; static int[] dr = {0, 0, 1, -1}; static int[] dc = {1, -1, 0, 0}; static int[][] pole; public static void main(String[] args) throws IOException { // 초기화 BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); pole = new int[N][M]; for (int i = 0; i \u0026lt; N; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u0026lt; M; j++) pole[i][j] = Integer.parseInt(st.nextToken()); } count = 0; // 빙산을 녹이면서 두 개로 분리되는지 확인 while (!isFinished()) { melt(); count++; } System.out.println(count); } // 빙산 녹이기(녹은 값을 별도의 리스트에 저장 후 마지막에 반영) private static void melt() { List\u0026lt;int[]\u0026gt; melted = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; M; j++) { if (pole[i][j] == 0) continue; int now = pole[i][j]; for (int k = 0; k \u0026lt; 4; k++) { int nr = i + dr[k]; int nc = j + dc[k]; if (nr \u0026lt; 0 || nr \u0026gt;= N || nc \u0026lt; 0 || nc \u0026gt;= M || pole[nr][nc] != 0) continue; now --; } if (now \u0026lt; 0) now = 0; melted.add(new int[] {i, j, now}); } } for (int[] now : melted) pole[now[0]][now[1]] = now[2]; } // 2개로 분리되었는지 확인(BFS) private static boolean isFinished() { // 두 덩이로 분리되지 않고 모든 빙산이 녹았을때 예외처리(중요) int sum = 0; for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; M; j++) { sum += pole[i][j]; } } if (sum == 0) { count = 0; return true; } // BFS 초기화 Queue\u0026lt;int[]\u0026gt; q = new ArrayDeque\u0026lt;\u0026gt;(); boolean[][] isVisited = new boolean[N][M]; boolean isOneBlock = false; // 한 얼음을 만날때까지 확인 for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; M; j++) { if (!isVisited[i][j] \u0026amp;\u0026amp; pole[i][j] != 0) { // 이미 얼음을 만났음에도 다시 만난 경우 true(빙산이 2개로 나눠짐) if (isOneBlock) return true; isOneBlock = true; // BFS를 돌면서 방문처리 q.offer(new int[] {i, j}); isVisited[i][j] = true; while (!q.isEmpty()) { int[] now = q.poll(); for (int k = 0; k \u0026lt; 4; k++) { int nr = now[0] + dr[k]; int nc = now[1] + dc[k]; if (nr \u0026lt; 0 || nr \u0026gt;= N || nc \u0026lt; 0 || nc \u0026gt;= M || pole[nr][nc] == 0 || isVisited[nr][nc]) continue; isVisited[nr][nc] = true; q.offer(new int[] {nr, nc}); } } } } } return false; } } 결과 리뷰 BFS를 사용한 간단한 구현문제였습니다. 2등분 되기 전에 얼음이 모두 녹아버리는 경우를 예외처리하지 않아 시간초과가 발생2해서 헤맸습니다. 실제 구현하는데는 오래 걸리지 않았지만 시간초과가 발생해서 최적화 문제로 생각했고, 예외상황을 생각하는데 많은 시간이 걸렸습니다. 문제 풀이가 막히거나 시간 초과가 발생한다면 최적화보다는 예외상황을 우선 점검하는게 좋을 것 같습니다.\nReferences URL 게시일자 방문일자 작성자 문제에도 위 경우에는 0으로 처리하라는 주의사항이 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n제 풀이에서 얼음이 모두 녹아버리면 while문을 빠져나오지 못해 시간초과가 발생합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_2573_%EB%B9%99%EC%82%B0/","summary":"출처 https://www.acmicpc.net/problem/2573 접근 각 칸이 10이하이고 전체 칸은 10,000이므로 빙산을 모두 녹이려면 10 _ 10,000 _ 10,000이지만, 네 변이 노출되면 금방 사라지므로 완전탐색이 가능하다고 판단했습니다. 매 회마다 빙산을 녹이고, 빙산을 bfs(dfs)로 탐색해서 두 덩어리가 있는지 확인한다. 모든 빙산이 다 녹았지만 2개로 분리되지 않는 경우를 주의한다.1 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; /* * [조건] * 시간제한 : 1초, 메모리 제한 : 256MV * 이차원 배열의 크기가 300^2 이하이며 전체 칸의 개수는 10,000개 이하, 각 칸의 크기는 10 이하 * [풀이] * 각 칸이 10이하이고 전체 칸은 10,000이므로 빙산을 모두 녹이려면 10 * 10,000 * 10,000이지만, 네 변이 노출되면 금방 사라지므로 완전탐색 * 매 회마다 빙산을 녹이고, 빙산을 bfs로 탐색해서 두 덩어리가 있는지 확인한다.","title":"[Java]백준 2573 빙산"},{"content":"출처 https://www.acmicpc.net/problem/1753 접근 각 정점에서 다른 정점으로의 최솟값을 다익스트라1를 통해 구합니다. 정점으로부터 최단거리의 간선으로만 이동하기 때문에 O(ElogV) ≈ 1,200,0002으로 모든 간선을 확인하는 것이 가능합니다. 탐색하는 간선 개수를 최적화하기 위해 LinkedList로 저장합니다.3 문제에서 주어진 예제를 그래프로 표현했습니다.\n그래프 1 2 3 4 5 초기화 0 INF INF INF INF 1 -\u0026gt; 2, 3 0 2 3 INF INF 2 -\u0026gt; 3, 4 0 2 3 7 INF 3 -\u0026gt; 4 0 2 3 7 INF 5 -\u0026gt; 1 0 2 3 7 INF 위와 같이 거리 배열을 초기화한 후, 각 정점의 간선들을 탐색하며 배열을 채워나갑니다. 이 때, Greedy 알고리즘인 다익스트라가 도입되는데, 각 지점에서 가중치의 최솟값인 경로만 선택하면서 목표지점까지 이동하면 최소 경로를 구할 수 있다는 것입니다.\n풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.PriorityQueue; import java.util.StringTokenizer; /* * [조건] * 시간 제한 : 1초 / 메모리 제한 : 256MB * V \u0026lt;= 20,000 / E \u0026lt;= 300,000 * [풀이] * 각 정점에서 다른 정점으로의 최솟값을 다익스트라를 통해 구한다. * 정점으로부터 최단거리의 간선으로만 이동하기 때문에 O(E * logV) ≈ 1,500,000으로, 모든 간선을 확인하는 것이 가능하다. * 탐색하는 간선 개수를 최적화하기 위해 linkedList로 저장한다.(V^2 \u0026gt;\u0026gt; E) */ public class bj_1753_다익스트라 { static int INF = Integer.MAX_VALUE; static int V, E, K; static Node[] adj; static class Node { int v; int w; Node next; public Node(int v, int w, Node next) { this.v = v; this.w = w; this.next = next; } } public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); V = Integer.parseInt(st.nextToken()); E = Integer.parseInt(st.nextToken()); K = Integer.parseInt(br.readLine()); // 간선 리스트 초기화 adj = new Node[V + 1]; for (int i = 0; i \u0026lt; E; i++) { st = new StringTokenizer(br.readLine()); int from = Integer.parseInt(st.nextToken()); int to = Integer.parseInt(st.nextToken()); int w = Integer.parseInt(st.nextToken()); adj[from] = new Node(to, w, adj[from]); } // 다익스트라 int[] dijkstra = dijkstra(); for (int i = 1; i \u0026lt;= V; i++) System.out.println(dijkstra[i] == INF? \u0026#34;INF\u0026#34; : dijkstra[i]); } // 각 목표지점까지의 다익스트라 private static int[] dijkstra() { PriorityQueue\u0026lt;int[]\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;((o1, o2) -\u0026gt; o1[1] - o2[1]); // 가중치의 최솟값 저장 pq.offer(new int[] {K, 0}); // int[0] : 정점, int[1] : 현재까지의 최단경로 int[] distance = new int[V + 1]; // 거리 배열 초기화 Arrays.fill(distance, INF); distance[K] = 0; while (!pq.isEmpty()) { int[] now = pq.poll(); if (distance[now[0]] \u0026lt; now[1]) continue; // 현재 거리배열보다 작은값은 사용하지 않음(최적화) for (Node n = adj[now[0]]; n != null; n = n.next) { int total = now[1] + n.w; // 이전 최단경로에서 가중치를 더하여 현재 최단경로를 구함 if (total \u0026lt; distance[n.v]) { distance[n.v] = total; // 거리배열에 현재까지의 최솟값 저장 pq.offer(new int[] {n.v, total}); // 우선순위 큐에 현재 최단경로 추가 } } } return distance; } } 결과 리뷰 처음 문제를 보고 모든 지점까지의 경로를 계산하는 부분에서 플로이드-워샬 문제라고 생각했지만, 시간복잡도를 계산해보니 불가능함을 알았습니다. 보통은 다익스트라를 통해 특정 지점까지의 최솟값을 구하지만, 다익스트라의 특성상 한 정점에서 모든 탐색을 완료하면 나머지 지점까지의 최솟값을 얻을 수 있는 것을 활용한 문제였습니다. 다익스트라 문제를 오랜만에 풀다가 구현이 막혀서 다른 블로그의 개념을 참고했습니다. 항상 개념이 부족하면 구현이 안되는 것 같습니다. 각 노드의 최솟값을 저장하고, 방문배열처럼 사용하는 것과 이를 통해 최적화하는 부분의 로직을 잘 기억해야겠습니다. References URL 게시일자 방문일자 작성자 https://velog.io/@panghyuk/%EC%B5%9C%EB%8B%A8-%EA%B2%BD%EB%A1%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98 2022.02.07. 2024.06.21. PANGHYUK 가중치가 있는 그래프에서 최단 경로를 Greedy로 탐색하는 알고리즘입니다. 다음 블로그에 잘 정리가 되어있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n우선순위큐에 모든 간선을 집어넣어서 정렬을 해야하므로 O(E x logE)이지만, 중복 간선은 존재하지 않기 때문에 근사적으로 O(ElogE) = O(ElogV^2) = O(2ElogV)로 표현이 가능합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n간선을 매트릭스 형태로 저장하게 되면 V^2 = 20,000 x 20,000 이지만, 간선 리스트로 저장하면 E = 300,000으로 시간복잡도를 훨씬 절약할 수 있습니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_1753_%EB%8B%A4%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%9D%BC/","summary":"출처 https://www.acmicpc.net/problem/1753 접근 각 정점에서 다른 정점으로의 최솟값을 다익스트라1를 통해 구합니다. 정점으로부터 최단거리의 간선으로만 이동하기 때문에 O(ElogV) ≈ 1,200,0002으로 모든 간선을 확인하는 것이 가능합니다. 탐색하는 간선 개수를 최적화하기 위해 LinkedList로 저장합니다.3 문제에서 주어진 예제를 그래프로 표현했습니다.\n그래프 1 2 3 4 5 초기화 0 INF INF INF INF 1 -\u0026gt; 2, 3 0 2 3 INF INF 2 -\u0026gt; 3, 4 0 2 3 7 INF 3 -\u0026gt; 4 0 2 3 7 INF 5 -\u0026gt; 1 0 2 3 7 INF 위와 같이 거리 배열을 초기화한 후, 각 정점의 간선들을 탐색하며 배열을 채워나갑니다.","title":"[Java]백준 1753 다익스트라"},{"content":"출처 https://www.acmicpc.net/problem/1976 접근 일반적인 DFS로 구현하면 각 여행경로를 확인하는데 O(N^3)1가 소요됩니다. 도시가 1000개이므로 200 x 200 x 200 x 1000 = 8,000,000,000(80억)으로 시간초과가 발생합니다.\n해당 문제에서는 다른 도시를 몇번이든 방문할 수 있기 때문에, 일일히 경로를 방문하는 것은 시간초과를 유발합니다. 이를 최적화하기 위해 모든 여행계획이 같은 네트워크(루트를 공유)에 포함되는지 확인하기만 하면 됩니다. 이는 유니온 파인드(Union-find)로 구현할 수 있습니다. 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; /* * [조건] * 시간 제한 : 2초, 메모리 제한 : 128MB * N \u0026lt;= 200, M \u0026lt;= 1000 * [구현] * 유니온 파인드를 통해 연결그래프를 구하고, 주어지는 여행계획이 같은 루트에 속하는지 확인한다. */ public class bj_1976_여행_가자 { static int N, M; static int[] root; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; N = Integer.parseInt(br.readLine()); M = Integer.parseInt(br.readLine()); root = new int[N + 1]; // 유니온 초기화 for (int i = 1; i \u0026lt;= N; i++) root[i] = i; for (int i = 1; i \u0026lt;= N; i++) { st = new StringTokenizer(br.readLine()); for (int j = 1; j \u0026lt;= N; j++) { // 두 도시를 같은 집합(루트)에 소속 if (st.nextToken().equals(\u0026#34;1\u0026#34;)) union(i, j); } } int[] plan = new int[M + 1]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u0026lt;= M; i++) plan[i] = Integer.parseInt(st.nextToken()); System.out.println(solve(plan)); } private static void union(int i, int j) { int ri = find(i); int rj = find(j); if (ri != rj) root[rj] = ri; } private static int find(int i) { if (i != root[i]) root[i] = find(root[i]); return root[i]; } private static String solve(int[] plan) { int r = find(plan[1]); for (int i = 2; i \u0026lt;= M; i++) { if (find(plan[i]) != r) return \u0026#34;NO\u0026#34;; } return \u0026#34;YES\u0026#34;; } } 결과 리뷰 시행착오 마지막에 각 도시의 root를 비교할때 find로 안찾고 root를 그대로 사용하는 시행착오가 있었습니다. /* ...생략 */ private static String solve(int[] plan) { int r = root[plan[1]]; for (int i = 2; i \u0026lt;= M; i++) { if (root[plan[i]] != r) return \u0026#34;NO\u0026#34;; } return \u0026#34;YES\u0026#34;; } 경로압축2을 통해 모든 도시가 같은 루트를 바라보게 될 것이라고 생각했는데, 다시 생각해보니 경로압축이 되지 않은 도시가 충분히 존재할 수 있어 보입니다.\n주어진 조건에서 DFS로는 구현이 안될 것 같다고 예상했는데, 이렇게 실제 구현 전에 시간복잡도 및 메모리를 잘 고려하여 많은 시간을 절약할 수 있었습니다. 유니온 파인드 알고리즘은 이제 어느정도 이해하는 것 같은데, 매번 다시 구현하는데 시간이 걸리는 것 같습니다. 다음에 유사한 문제를 만나면 좀더 빨리 풀 수 있기를 기대합니다. References URL 게시일자 방문일자 작성자 가장 멀리 떨어진 도시까지 모든 도시를 돌면서(N) 연결여부를 확인(N^2)하므로 총 O(N x N^2) = O(N^3) 입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n아래 코드를 통해 find() 메서드를 실행하며 만나는 모든 도시들의 root를 최종 root로 변경합니다.\nprivate static int find(int i) { // 현재 메서드의 root[i]를 재귀적으로 다음에서 찾은 root로 변경 if (i != root[i]) root[i] = find(root[i]); return root[i]; } \u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_1976_%EC%97%AC%ED%96%89_%EA%B0%80%EC%9E%90/","summary":"출처 https://www.acmicpc.net/problem/1976 접근 일반적인 DFS로 구현하면 각 여행경로를 확인하는데 O(N^3)1가 소요됩니다. 도시가 1000개이므로 200 x 200 x 200 x 1000 = 8,000,000,000(80억)으로 시간초과가 발생합니다.\n해당 문제에서는 다른 도시를 몇번이든 방문할 수 있기 때문에, 일일히 경로를 방문하는 것은 시간초과를 유발합니다. 이를 최적화하기 위해 모든 여행계획이 같은 네트워크(루트를 공유)에 포함되는지 확인하기만 하면 됩니다. 이는 유니온 파인드(Union-find)로 구현할 수 있습니다. 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; /* * [조건] * 시간 제한 : 2초, 메모리 제한 : 128MB * N \u0026lt;= 200, M \u0026lt;= 1000 * [구현] * 유니온 파인드를 통해 연결그래프를 구하고, 주어지는 여행계획이 같은 루트에 속하는지 확인한다.","title":"[Java]백준 1976 여행 가자"},{"content":"출처 https://www.acmicpc.net/problem/14503 접근 N, M \u0026lt;= 50, O(N^5) = 312,500,000 이므로 시간복잡도는 여유롭게 구현 가능합니다. 로봇 청소기의 이동 방식을 BFS로 구현했습니다. 다시 생각해보니 BFS형태가 아니더라도 구현 가능한데 습관적으로 BFS를 사용한 것 같습니다.\n문제에서 주어진 방향설정이 중요합니다. 북(-1, 0), 동(0, 1), 남(1, 0), 서(0, -1)\n친절하게 방의 둘레는 모두 벽(1)로 채워져 있기 때문에 ArrayIndexOutOfBoundsException1은 처리하지 않아도 됩니다. 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayDeque; import java.util.Queue; import java.util.StringTokenizer; /* * N, M이 50 이하이므로, 시간복잡도와 메모리제한은 고려하지 않음 * [풀이] * 로봇 청소기의 이동 방식을 bfs로 구현한다. * 방향 : 북(-1, 0), 동(0, 1), 남(1, 0), 서(0, -1) * 청소를 마치면 0 -\u0026gt; -1로 변경 * 로봇의 동작은 각각 별도의 메서드로 분리 */ public class bj_14503_로봇_청소기 { static int N; static int M; static int[][] room; static int[] dr = {-1, 0, 1, 0}; static int[] dc = {0, 1, 0, -1}; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); room = new int[N + 1][M + 1]; st = new StringTokenizer(br.readLine()); int[] start = {Integer.parseInt(st.nextToken()), Integer.parseInt(st.nextToken())}; int direction = Integer.parseInt(st.nextToken()); for (int i = 0; i \u0026lt; N; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u0026lt; M; j++) room[i][j] = Integer.parseInt(st.nextToken()); } solve(start, direction); } private static void solve(int[] start, int direction) { Queue\u0026lt;int[]\u0026gt; q = new ArrayDeque\u0026lt;\u0026gt;(); q.offer(new int[]{start[0], start[1], direction}); int count = 0; while (!q.isEmpty()) { int[] cur = q.poll(); int r = cur[0], c = cur[1], d = cur[2]; // 현재 칸이 청소되지 않은 경우 if (room[r][c] == 0) { count++; room[r][c] = -1; } // 주변 4칸 중 빈칸이 없을 경우 if (!findDirty(r, c)) { int[] back = moveBack(r, c, d); if (back == null) break; q.offer(back); } // 주변 4칸 중 빈칸이 있을 경우 else { for (int i = 0; i \u0026lt; 4; i++) { d = d == 0 ? 3 : d == 3 ? 2 : d == 2 ? 1 : 0; int[] forward = moveForward(r, c, d); if (forward != null) { q.offer(forward); break; } } } } System.out.println(count); } private static int[] moveForward(int r, int c, int nd) { int nr = r + dr[nd]; int nc = c + dc[nd]; // 더이상 이동할 수 없을 때 if (room[nr][nc] != 0) return null; else return new int[]{nr, nc, nd}; } private static int[] moveBack(int r, int c, int d) { int nd = d == 0 ? 2 : d == 1 ? 3 : d == 2 ? 0 : 1; int nr = r + dr[nd]; int nc = c + dc[nd]; // 더이상 물러날 곳이 없을때 if (room[nr][nc] == 1) return null; else return new int[]{nr, nc, d}; } private static boolean findDirty(int r, int c) { for (int i = 0; i \u0026lt; 4; i++) { int nr = r + dr[i]; int nc = c + dc[i]; if (room[nr][nc] == 0) return true; } return false; } } 결과 리뷰 문제에 주어진 로직을 그대로 구현하는 문제여서 난이도는 높지 않았습니다. 로직을 메서드 단위로 분리해서 구현하니 좀더 직관적으로 구현이 가능했습니다. BFS를 구현하기 위해 불필요한 Queue 객체를 추가로 생성한 것 같아 아쉽습니다. BFS나 DFS를 사용하기에 앞서 탐색 시 기존 경로를 저장할 필요가 있는지를 따져보고 도입하는게 좋을 것 같습니다. References URL 게시일자 방문일자 작성자 유효하지 않은 배열 인덱스에 접근할때 발생하는 오류입니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_14503_%EB%A1%9C%EB%B4%87_%EC%B2%AD%EC%86%8C%EA%B8%B0/","summary":"출처 https://www.acmicpc.net/problem/14503 접근 N, M \u0026lt;= 50, O(N^5) = 312,500,000 이므로 시간복잡도는 여유롭게 구현 가능합니다. 로봇 청소기의 이동 방식을 BFS로 구현했습니다. 다시 생각해보니 BFS형태가 아니더라도 구현 가능한데 습관적으로 BFS를 사용한 것 같습니다.\n문제에서 주어진 방향설정이 중요합니다. 북(-1, 0), 동(0, 1), 남(1, 0), 서(0, -1)\n친절하게 방의 둘레는 모두 벽(1)로 채워져 있기 때문에 ArrayIndexOutOfBoundsException1은 처리하지 않아도 됩니다. 풀이 package solving; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayDeque; import java.util.Queue; import java.","title":"[Java]백준 14503 로봇 청소기"},{"content":"출처 https://www.acmicpc.net/problem/1806 접근 문제는 굉장히 심플하나, 시간제한이 0.5초이며 메모리 제한이 128MB인 것으로 보아 최적화 문제임을 알 수 있습니다. 주어지는 수열의 부분합을 구해야 하는데, 수열의 길이가 100,000이므로 O(N^2)으로는 시간 초과가 발생합니다. 부분합의 최대 크기를 100,000,000 ≒ 2^30 정도로 제한해주었기 때문에 int로 총합을 구해도 Overflow가 발생하지 않습니다. 풀이 포인터를 2개 두고 합이 S보다 커질때까지 부분수열의 크기를 늘리다가, S보다 커지는 시점부터 부분수열의 크기를 줄여나가면 됩니다. ①에서 점점 부분수열을 늘리다가 ②처럼 다시 15보다 작을때까지 사이즈를 줄여나갑니다.\n위와 같은 로직을 반복하면 각 숫자를 최대 2번씩 확인하기 때문에 O(2N) = O(N)의 시간복잡도로 해결이 가능합니다. import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; /* * [조건] * 시간 제한 : 1s / 메모리 제한 : 128MB * N \u0026lt; 100,000 / s \u0026lt;= 100,000,000 / 최대 O(Nlog(N)) / Int로 총합 구해도 Overflow 발생하지 않음 * [풀이] * 합이 S보다 커질떄까지 앞에서부터 부분수열 더하기, S보다 클때의 길이 저장 * 합이 S보다 커지면 S보다 작아질때까지 앞에서부터 부분수열 빼기, S보다 클때의 길이 저장 * 길이의 최솟값 출력 */ public class bj_1806_부분합 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); int N = Integer.parseInt(st.nextToken()); int S = Integer.parseInt(st.nextToken()); int[] arr = new int[N]; st = new StringTokenizer(br.readLine()); for (int i = 0; i \u0026lt; N; i++) arr[i] = Integer.parseInt(st.nextToken()); System.out.print(solve(N, S, arr)); } private static int solve(int N, int S, int[] arr) { int min = N + 1, sum = arr[0], p0 = 0, p1 = 0; while (p1 \u0026lt; N) { if (sum \u0026gt;= S) { min = Math.min(p1 - p0 + 1, min); sum -= arr[p0++]; } else { if (p1 == N - 1) break; sum += arr[++p1]; } } return min != N + 1? min : 0; } } 결과 리뷰 예전에 파이썬으로 풀었던 적이 있는 문제였습니다. 풀이는 금방 떠올렸는데 이를 구현하려고 하니 조금 복잡하게 느껴졌습니다. 설계한 로직을 빠르고 직관적으로 코드로 옮기는 과정을 좀더 연습해야겠다고 느꼈습니다. 동일한 로직을 파이썬으로 풀었을 때1 전체 시간이 160ms정도로 더 작게 나왔는데, 자바에서는 최초 배열을 생성하고 loop를 한번 도는 로직이 추가되어 그런 듯 합니다. References URL 게시일자 방문일자 작성자 아래는 파이썬 코드입니다.\nimport sys input = sys.stdin.readline N, S = map(int, input().split()) arr = list(map(int, input().split())) min_sum_length = 100000000 left, right = 0, 0 judge = arr[0] while right \u0026lt; len(arr): if judge \u0026gt;= S: min_sum_length = min(min_sum_length, right - left + 1) judge -= arr[left] left += 1 elif judge \u0026lt; S: if right == len(arr) - 1: break right += 1 judge += arr[right] print(0 if min_sum_length == 100000000 else min_sum_length) \u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_1806_%EB%B6%80%EB%B6%84%ED%95%A9/","summary":"출처 https://www.acmicpc.net/problem/1806 접근 문제는 굉장히 심플하나, 시간제한이 0.5초이며 메모리 제한이 128MB인 것으로 보아 최적화 문제임을 알 수 있습니다. 주어지는 수열의 부분합을 구해야 하는데, 수열의 길이가 100,000이므로 O(N^2)으로는 시간 초과가 발생합니다. 부분합의 최대 크기를 100,000,000 ≒ 2^30 정도로 제한해주었기 때문에 int로 총합을 구해도 Overflow가 발생하지 않습니다. 풀이 포인터를 2개 두고 합이 S보다 커질때까지 부분수열의 크기를 늘리다가, S보다 커지는 시점부터 부분수열의 크기를 줄여나가면 됩니다. ①에서 점점 부분수열을 늘리다가 ②처럼 다시 15보다 작을때까지 사이즈를 줄여나갑니다.","title":"[Java]백준 1806 부분합"},{"content":"출처 https://www.acmicpc.net/problem/4195 접근 처음에는 문제가 잘 이해되지 않았습니다.1 몇 번 읽어보니, 두 정점이 주어지면 두 정점을 연결하고 같은 그래프 내에 있는 모든 친구 개수를 출력하는 문제임을 알았습니다. ①, ②을 통해 연결된 네트워크는 각각 친구가 2명이며, ③을 통해 두 네트워크가 연결되면 총 친구는 4명입니다.\n친구관계가 연결되어 같은 그래프에 포함되는 과정이 Union-Find 알고리즘과 동일하기 때문에, 이를 활용하여 해결할 수 있습니다. 유니온 파인드(Union Find) Union과 Find 메서드를 통해 서로소 집합2을 연결하는 알고리즘입니다. 각 집합의 단위는 Root로부터 하위 원소들로 구성되며, 모든 원소들은 동일한 Root를 바라보는 특징이 있습니다. Union과 Find를 간략히 그림으로 나타내면 다음과 같습니다. 노란색 : 부모 / 빨간색 : 유니온(Union) 메서드 / 파란색 : 파인드(find) 메서드\nRoot는 본인을 바라보는 노드이며, 최초 네트워크가 구성될 때 본인을 바라보도록 만듭니다. Union union 연산을 수행하면, 서로 교집합이 없는 두 네트워크의 Root를 한쪽을 바라보도록 연결합니다. 이 때, 한쪽 네트워크의 부모를 다른 네트워크의 부모를 바라보도록 변경해주면 되므로 연결 과정은 O(1)로 연산이 가능합니다. Find find 연산을 수행하면, 부모가 본인인 노드(Root)가 나올때까지 탐색을 수행합니다. 만약 네트워크 끝에서부터 탐색한다면(위 그림에서 3, 5번 노드), 최대 O(N)의 시간복잡도가 필요합니다. 이를 줄이기 위해 Find과정에서 만나는 부모들을 모두 부모를 바라보도록 변경하는 작업을 수행하면, 처음 탐색속도는 동일하게 O(N)이지만 이후 탐색속도는 O(1)이 되도록 개선할 수 있습니다.3 풀이 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashMap; import java.util.LinkedList; import java.util.List; import java.util.StringTokenizer; /* * [조건] * 시간제한 : 3초 / 메모리제한 : 256MB * F \u0026lt;= 100,000 / name.length() \u0026lt;= 20 * [풀이] * Union find 알고리즘을 통해 공통 친구 네트워크의 개수를 구한다. * 친구 집합의 root를 find를 통해 찾는다. * root가 아직 정해지지 않았다면, 공통 집합에 가입시킨다. * 두 친구관계가 만나면 Union을 통해 공통 집합에 가입시키고, 공통 집합의 크기를 더한다. */ public class bj_4195_친구_네트워크 { static int groupId = 0; static HashMap\u0026lt;String, String\u0026gt; friendship; // 친구관계(부모)를 가리키는 해시맵 static HashMap\u0026lt;String, Integer\u0026gt; rootCount; // 네트워크 크기를 루트와 매핑하는 해시맵 public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int T = Integer.parseInt(br.readLine()); for (int i = 0; i \u0026lt; T; i++) { int F = Integer.parseInt(br.readLine()); friendship = new HashMap\u0026lt;\u0026gt;(); rootCount = new HashMap\u0026lt;\u0026gt;(); for (int j = 0; j \u0026lt; F; j++) { StringTokenizer st = new StringTokenizer(br.readLine()); String f1 = st.nextToken(); String f2 = st.nextToken(); System.out.println(getFriends(f1, f2)); } } } /* * 집합(친구관계)을 생성하는 메서드 */ static void makeSet(String s) { friendship.put(s, s); // 최초 친구 : 1명 rootCount.put(s, 1); } /* * 각 네트워크의 루트를 찾아(Find) 두 관계를 합치는 메서드 * 왼쪽값의 root에 오른쪽을 편입시킴 */ static int union(String s1, String s2) { String root1 = find(s1); String root2 = find(s2); // 이미 친구일 경우 예외처리 if (root1.equals(root2)) return rootCount.get(root1); // 네트워크 편입 friendship.put(root2, root1); // 편입 시 두 네트워크의 합으로 루트 해시맵의 값을 변경, 네트워크의 합 return int value = rootCount.get(root1) + rootCount.get(root2); rootCount.put(root1, value); return value; } /* * 부모를 찾는 메서드 * HashMap의 값이 본인이 아니면 본인이 나올때까지 재귀호출하여 path compression * HashMap의 값 == 본인 이면 root */ static String find(String me) { // Recursive Path Compression(재귀적으로 부모값을 루트로 변경시켜 이후 탐색속도 높임) if (!me.equals(friendship.get(me))) friendship.put(me, find(friendship.get(me))); return friendship.get(me); } /* * 두 네트워크를 합치고 공통의 친구 개수를 찾는 메서드 */ static int getFriends(String f1, String f2) { if (!friendship.containsKey(f1)) makeSet(f1); if (!friendship.containsKey(f2)) makeSet(f2); return union(f1, f2); } } 결과 리뷰 오랜만에 유니온 파인드 알고리즘을 만나서 복습해볼 수 있었습니다. 중간에 같은 네트워크에 이미 소속된 두 친구가 만났을 경우를 예외처리하지 않아서 조금 헤맸습니다. 확실히 구현문제는 예외 상황들을 미리 그려놓고 문제 풀이에 들어가야 빠르게 처리할 수 있는 것 같습니다. References URL 게시일자 방문일자 작성자 개인적으로 영어 원문으로 변경하니 더 이해가 쉬웠던 것 같습니다. \u0026#160;\u0026#x21a9;\u0026#xfe0e;\n서로 중복(교집합)이 없는 집합을 말합니다. 애초에 교집합이 있다면 같은 네트워크 안에 포함되어 있기 때문에 유니온 연산이 불가능합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n위 과정을 경로 압축(Path Compression)이라고 부릅니다. 이번 문제에서 경로압축을 하지않으면 O(N)의 탐색을 N(100,000)회 수행하므로 O(N^2) ≒ 2^40 으로 시간초과가 발생합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_4195_%EC%B9%9C%EA%B5%AC_%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/","summary":"출처 https://www.acmicpc.net/problem/4195 접근 처음에는 문제가 잘 이해되지 않았습니다.1 몇 번 읽어보니, 두 정점이 주어지면 두 정점을 연결하고 같은 그래프 내에 있는 모든 친구 개수를 출력하는 문제임을 알았습니다. ①, ②을 통해 연결된 네트워크는 각각 친구가 2명이며, ③을 통해 두 네트워크가 연결되면 총 친구는 4명입니다.\n친구관계가 연결되어 같은 그래프에 포함되는 과정이 Union-Find 알고리즘과 동일하기 때문에, 이를 활용하여 해결할 수 있습니다. 유니온 파인드(Union Find) Union과 Find 메서드를 통해 서로소 집합2을 연결하는 알고리즘입니다. 각 집합의 단위는 Root로부터 하위 원소들로 구성되며, 모든 원소들은 동일한 Root를 바라보는 특징이 있습니다.","title":"[Java]백준 4195 친구 네트워크"},{"content":"출처 https://www.acmicpc.net/problem/12904 접근 처음에는 DP문제인줄 알고 접근했으나, 시간 초과로 실패했습니다.1 S로부터 T로 갈때는 여러 경로가 존재해서 DP와 같은 최적화가 필요해보입니다. S에서 시작할 경우 2^(T의 길이 - S의 길이) 만큼의 탐색이 필요합니다.\n그러나 반대로 T에서 S로 갈때는 경로가 1개만 존재하므로, (T의 길이 - S의 길이)만큼만 탐색하면 S를 구할 수 있습니다. T에서 S로 갈때는 T의 맨뒤 값으로 이전 노드를 예측하는 것이 가능합니다.\n이를 활용하면 다음과 같은 접근을 통해 O(N)으로 해결이 가능합니다. T의 맨뒤값을 확인하여 A일 경우, 맨끝을 제거합니다. B일 경우, 맨끝을 제거하고 문자열을 뒤집습니다. S의 길이가 될때까지 반복 후, 두 문자열이 같은지 비교합니다. 풀이 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.List; public class bj_12904_A와_B_2트 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String S = br.readLine(); String T = br.readLine(); if (solve(S, T)) System.out.print(1); else System.out.print(0); } /* * [조건] * 시간제한 : 2초 / 메모리제한 : 512MB * S.length() \u0026lt;= 999, T.length() \u0026lt;= 1000, S.length() \u0026lt; T.length() * [풀이] * T의 맨뒤를 보면 이전값을 유추할 수 있다. * T를 맨뒤에서부터 이전으로 돌려간다. */ static boolean solve(String s, String t) { int l = s.length(); String nt = t; while (nt.length() \u0026gt; l) { // nt의 길이가 s가 될때까지 반복 char[] tc = nt.toCharArray(); char end = tc[nt.length() - 1]; // 맨뒤값 가져오기 nt = nt.substring(0, nt.length() - 1); // 맨뒤값 제거하기 if (end == \u0026#39;B\u0026#39;) nt = new StringBuilder(nt).reverse().toString(); // B일 경우 뒤집기 } if (nt.equals(s)) return true; // nt와 s가 같으면 true else return false; // nt와 s가 다르면 false } } 결과 리뷰 한쪽 방향으로 생각했을때는 탐색 과정에서 자식이 2개씩 있는 이진 트리 형태라고 생각했는데, 반대로 생각하니 부모는 1개만 존재했습니다. 처음에 DP로 풀려고 하다가 시간을 1시간정도 써서 아쉬웠습니다. DP로 풀수있을지 약간 망설여졌는데, 지금 생각해보면 1000개나 되는 자식을 이진트리로 검색하는건 아무리 최적화해도 힘들 듯합니다. 앞으로는 코드 작성 전 더 많은 경우의 수를 고민하고, 충분히 해결 가능하다 싶을때 풀이에 들어가는 습관을 길러야 하겠습니다. References URL 게시일자 방문일자 작성자 잘못된 풀이는 다음과 같습니다.\nimport java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.List; public class bj_12904_A와_B { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String S = br.readLine(); String T = br.readLine(); if (solve(S, T)) System.out.print(1); else System.out.print(0); } /* * [조건] * 시간제한 : 2초 / 메모리제한 : 512MB * S.length() \u0026lt;= 999, T.length() \u0026lt;= 1000, S.length() \u0026lt; T.length() * [풀이] * DP를 통해 해당 길이에서 나올 수 있는 모든 경우의 수를 저장한다. * 해당 길이의 경우의 수는 이전 길이의 2배이므로 처음 주어진 S의 2배씩 저장공간이 필요하다. * 그대로 저장하려면 2^(T - S)개가 필요하므로 최대 2^999의 저장공간이 필요하므로 최적화해야 한다. * 최적화를 위해 T가 될 수 없는 경우의 수를 가지치기한다. / 될수없는 경우 : T의 일부가 아니면서 뒤집은 T의 일부가 아닐때 */ static boolean solve(String s, String t) { List\u0026lt;String\u0026gt; dp = new ArrayList\u0026lt;\u0026gt;(); // 이전값들 중 가능한 값들만 저장하는 dp 리스트 dp.add(s); int l = s.length(); while(l \u0026lt; t.length()) { getNs1(dp, t); // 뒤에 A 추가하기 getNs2(dp, t); // 뒤집은 후 B 추가하기 l++; } for (String ns : dp) if (ns.equals(t)) return true; return false; } static void getNs1(List\u0026lt;String\u0026gt; dp, String t) { List\u0026lt;String\u0026gt; addList = new ArrayList\u0026lt;\u0026gt;(); for (String ns : dp) { StringBuilder sb = new StringBuilder(ns); ns = sb.append(\u0026#34;A\u0026#34;).toString(); if (isPossible(dp, ns, t)) addList.add(ns); } dp.addAll(addList); } static void getNs2(List\u0026lt;String\u0026gt; dp, String t) { List\u0026lt;String\u0026gt; addList = new ArrayList\u0026lt;\u0026gt;(); for (String ns : dp) { StringBuilder sb = new StringBuilder(ns); sb.reverse(); ns = sb.append(\u0026#34;B\u0026#34;).toString(); if (isPossible(dp, ns, t)) addList.add(ns); } dp.addAll(addList); } static boolean isPossible(List\u0026lt;String\u0026gt; dp, String ns, String t) { // dp에 이미 포함되어있는지 확인 for (String d : dp) if (d.equals(ns)) return false; // Ns가 t의 부분문자열인지 확인 int l = ns.length(); String rt = new StringBuilder(t).reverse().toString(); for (int i = 0; i \u0026lt;= t.length() - l; i++) { String nt = t.substring(i, i + l); String nrt = rt.substring(i, i + l); if (nt.equals(ns)) return true; if (nrt.equals(ns)) return true; } return false; } } \u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_12904_a%EC%99%80_b/","summary":"출처 https://www.acmicpc.net/problem/12904 접근 처음에는 DP문제인줄 알고 접근했으나, 시간 초과로 실패했습니다.1 S로부터 T로 갈때는 여러 경로가 존재해서 DP와 같은 최적화가 필요해보입니다. S에서 시작할 경우 2^(T의 길이 - S의 길이) 만큼의 탐색이 필요합니다.\n그러나 반대로 T에서 S로 갈때는 경로가 1개만 존재하므로, (T의 길이 - S의 길이)만큼만 탐색하면 S를 구할 수 있습니다. T에서 S로 갈때는 T의 맨뒤 값으로 이전 노드를 예측하는 것이 가능합니다.\n이를 활용하면 다음과 같은 접근을 통해 O(N)으로 해결이 가능합니다. T의 맨뒤값을 확인하여 A일 경우, 맨끝을 제거합니다.","title":"[Java]백준 12904 A와 B"},{"content":"출처 https://www.acmicpc.net/problem/16927 접근 돌려야 하는 배열을 1차원 배열로 만들어서 R만큼 이동하면 다음 배열 값을 얻을 수 있습니다. 1차원 배열과 2차원 배열을 변환하는게 조금 귀찮은데, 저는 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌(반시계) 순으로 이동하도록 설계했습니다. 2차원 배열을 위 순서로 탐색해서 1차원 배열로 만듭니다.\n이 때, 1차원 배열의 크기는 2차원 배열의 (가로 + 세로) * 2 에서 네 귀퉁이(위 사진에서 (1) ~ (4))가 중복되므로 4를 빼주어야 합니다.\n이렇게 구한 배열값을 R만큼 이동시키는데, 이때 R \u0026lt; 10^91 이므로 최적화를 위해 해당 배열의 크기로 나머지를 구합니다. 빨간색 화살표(포인터)만큼 배열을 이동시켜야 합니다.\n다시 그래프를 탐색하면서 이번에는 역순으로 1차원 배열의 원소로 2차원 배열을 채워넣습니다.\n1 ~ 3 과정을 행 / 열 중 하나가 1보다 작아질 때까지 depth를 1씩 이동하며 수행합니다. 행 / 열 중 하나가 1보다 작아지면 행렬을 돌릴 수 없으므로 종료합니다.\n풀이 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class Main { static int N; static int M; static int R; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); R = Integer.parseInt(st.nextToken()); int[][] NM = new int[N][M]; for (int i = 0; i \u0026lt; N; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u0026lt; M; j++) { NM[i][j] = Integer.parseInt(st.nextToken()); } } for (int d = 0; d \u0026lt; Math.min(M, N) / 2; d++) { // M, N 중 최솟값의 절반만큼 수행 rotate(d, N - d, d, M - d, NM); } System.out.print(toStringInt2(NM)); // 정답 출력 } /* * [조건] * 시간제한 : 1초 / 메모리 제한 : 512MB * N, M \u0026lt; 300, R \u0026lt; 10^9, 1 \u0026lt; 원소 \u0026lt; 10^8 * min(N, M) % 2 = 0(M + N은 짝수) * [풀이] * 2(m + n) 크기의 배열에 원소들을 담고, R % 2(m + n)의 값만큼 반시계 방향으로 이동하면 해당위치 값을 구할 수 있다. * 모든 깊이에서 해당 로직을 수행하기 위해 (n / 2 \u0026lt;= 1)가 될때까지 위 로직을 수행한다. */ static void rotate(int n0, int n1, int m0, int m1, int[][] NM) { // 배열 크기는 전체 길이에서 네 귀퉁이를 한번씩 빼주기 int[] arr = new int[(n1 - n0 + m1 - m0) * 2 - 4]; // 배열에 반시계방향으로 원소 담기 getArrElement(n0, n1, m0, m1, arr, NM); // 배열 값 이동시키기 int l = arr.length; int[] newArr = new int[l]; int p = R % l; // 최적화를 위해 R을 행렬의 길이로 나눈 나머지를 구해서 이동시키기 for (int i = 0; i \u0026lt; l; i++) { // int np = i - p \u0026gt;= 0? i - p : i - p + l; newArr[i] = arr[np]; } // 이동한 값 배열에 넣기 setArrElement(n0, n1, m0, m1, newArr, NM); } static int[] dr = {1, 0, -1, 0}; // d = 0 : 하 -\u0026gt; d = 1 : 상 -\u0026gt; d = 2 : 좌 -\u0026gt; d = 3 : 우 static int[] dc = {0, 1, 0, -1}; /* * 1차원 배열로 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌 순으로 2차원 배열 채우기 */ static void setArrElement(int n0, int n1, int m0, int m1, int[] arr, int[][] NM) { // 시작점에서부터 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌 순으로 탐색 int[] p = {n0, m0}; NM[n0][m0] = arr[0]; // 1차원 배열로 2차원 배열 채우기 int l = 1; int d = 0; while (l \u0026lt; arr.length) { // 1차원 배열의 길이가 다 채워질때까지 수행 int[] np = {p[0] + dr[d], p[1] + dc[d]}; if (n0 \u0026gt; np[0] || np[0] \u0026gt;= n1 || m0 \u0026gt; np[1] || np[1] \u0026gt;= m1) { // 해당 꼭지점을 벗어날 경우 방향 전환 d++; // 방향 전환 np = new int[] {p[0] + dr[d], p[1] + dc[d]}; // 방향 전환 후 np 덮어쓰기 } NM[np[0]][np[1]] = arr[l]; // 1차원 배열로 2차원 배열 채우기 l++; // while문 탈출조건 p = np; // 위치 다음으로 변경 } } /* * 2차원 배열로 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌 순으로 1차원 배열 채우기 */ static void getArrElement(int n0, int n1, int m0, int m1, int[] arr, int[][] NM) { // 시작점에서부터 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌 순으로 탐색 int[] p = {n0, m0}; arr[0] = NM[n0][m0]; // 2차원 배열로 1차원 배열 채우기 int l = 1; int d = 0; while (l \u0026lt; arr.length) { int[] np = {p[0] + dr[d], p[1] + dc[d]}; if (n0 \u0026gt; np[0] || np[0] \u0026gt;= n1 || m0 \u0026gt; np[1] || np[1] \u0026gt;= m1) { d++; np = new int[] {p[0] + dr[d], p[1] + dc[d]}; } arr[l] = NM[np[0]][np[1]]; // 2차원 배열로 1차원 배열 채우기 l++; p = np; } } /* * 2차원 배열 출력하기 */ static String toStringInt2(int[][] int2) { StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; int2.length; i++) { for (int j : int2[i]) sb.append(j + \u0026#34; \u0026#34;); if (i != int2.length - 1) sb.append(\u0026#34;\\n\u0026#34;); } return sb.toString(); } } 결과 리뷰 문제 접근은 바로 떠올렸는데, 오랜만에 구현하려고 하니 생각보다 시간이 많이걸렸습니다.\n그리고 2차원 행렬 탐색을 할 때 어줍짢게 for문으로 상하좌우 돌려보려고 했는데 1시간 정도 해보다가 포기했습니다.\n구현방법이 직관적으로 떠오르지 않으면 바로 다른 대안을 찾아 시간을 줄여야겠습니다.\n지금 생각해보니 2차원 \u0026lt;-\u0026gt; 1차원 변환하는 메서드가 중복이 많은데, 플래그를 하나 넣으면 짧게 줄일수도 있을 것 같습니다.\n그리고 매개변수에 각 지점을 하나씩 넣지말고 행과 열을 묶어서 배열로 넣는게 더욱 코드를 이해하기 좋아보입니다.\n개선 코드 /* * 1차원 배열 \u0026lt;-\u0026gt; 2차원 배열 변환 */ static void changeArrElement(int[] n, int[] m, int[] arr, int[][] NM, boolean isTwoToOne) { // 시작점에서부터 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌 순으로 탐색 int[] p = {n[0], m[0]}; if (isTwoToOne) arr[0] = NM[n[0]][m[0]]; // 2차원 배열로 1차원 배열 채우기 else NM[n[0]][m[0]] = arr[0]; // 1차원 배열로 2차원 배열 채우기 int l = 1; int d = 0; while (l \u0026lt; arr.length) { // 1차원 배열의 길이가 다 채워질때까지 수행 int[] np = {p[0] + dr[d], p[1] + dc[d]}; if (n[0] \u0026gt; np[0] || np[0] \u0026gt;= n[1] || m[0] \u0026gt; np[1] || np[1] \u0026gt;= m[1]) { // 해당 꼭지점을 벗어날 경우 방향 전환 d++; // 방향 전환 np = new int[] {p[0] + dr[d], p[1] + dc[d]}; // 방향 전환 후 np 덮어쓰기 } if (isTwoToOne) arr[l] = NM[np[0]][np[1]]; // 2차원 배열로 1차원 배열 채우기 else NM[np[0]][np[1]] = arr[l]; // 1차원 배열로 2차원 배열 채우기 l++; // while문 탈출조건 p = np; // 위치 다음으로 변경 } } References URL 게시일자 방문일자 작성자 R = 10^9이면 원소를 순차적으로 하나씩 이동시켰을때 원소 1개의 시간복잡도가 10^9 이므로 문제에 주어진 10^8개의 원소를 이동시키는데 O(N) = 10^9 * 10^8 = 10^17 이 걸리게 됩니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/cote/%EB%B0%B1%EC%A4%80_16927_%EB%B0%B0%EC%97%B4_%EB%8F%8C%EB%A6%AC%EA%B8%B0_2/","summary":"출처 https://www.acmicpc.net/problem/16927 접근 돌려야 하는 배열을 1차원 배열로 만들어서 R만큼 이동하면 다음 배열 값을 얻을 수 있습니다. 1차원 배열과 2차원 배열을 변환하는게 조금 귀찮은데, 저는 하 -\u0026gt; 우 -\u0026gt; 상 -\u0026gt; 좌(반시계) 순으로 이동하도록 설계했습니다. 2차원 배열을 위 순서로 탐색해서 1차원 배열로 만듭니다.\n이 때, 1차원 배열의 크기는 2차원 배열의 (가로 + 세로) * 2 에서 네 귀퉁이(위 사진에서 (1) ~ (4))가 중복되므로 4를 빼주어야 합니다.\n이렇게 구한 배열값을 R만큼 이동시키는데, 이때 R \u0026lt; 10^91 이므로 최적화를 위해 해당 배열의 크기로 나머지를 구합니다.","title":"[Java]백준 16927 배열 돌리기 2"},{"content":"한줄평 테스트를 하라. 성공시켜라. 리팩토링하라.\n책을 읽게 된 계기 단위테스트를 작성하다가 자연스럽게 TDD라는 개발 방법론을 접하게 되었습니다. 실제로 가능한건지 몸소 체험해보고 싶었고, 이 책을 통해 기본적인 개념을 느끼고 프로젝트에 직접 적용해보고자 했습니다.\n작가 소개 켄트 벡(Kent Beck)\n켄트 벡(Kent Beck, 1961년~ )은 미국의 소프트웨어 엔지니어이자, 협업적이고 반복적인 디자인 프로세스의 엄격한 사양을 삼가는 소프트웨어 개발 방법론인 익스트림 프로그래밍의 개발자이다. 애자일 소프트웨어 개발의 창설 문서인 애자일 선언문의 17명의 오리지널 서명인 가운데 한 명이었다. 현재 캘리포니아주 샌프란시스코에 거주하고 있으며 소셜 미디어 기업 페이스북에서 종사하였다.1\n핵심요약 테스트 성공 전략 가짜로 구현하기 : 상수를 반환하다가, 점점 변수로 변환해간다. 명백한 구현 사용하기 : 실제 구현을 입력한다. 삼각측량 : 두 테스트를 만들고, 이를 모두 해결하기 위한 코드를 작성한다. TDD Process 작은 테스트를 추가한다. 모든 테스트를 실행하고, 실패하는 것을 확인한다. 코드에 변화를 준다. 모든 테스트를 실행하고, 성공하는 것을 확인한다. 중복을 제거하기 위해 리팩토링한다. TDD에 도움이 되는 디자인 패턴 커맨드 : 계산 작업에 대한 호출을 메시지가 아닌 객체로 표현 값 객체 : 객체가 생성된 후 값이 절대로 변하지 않게 한다. 널 객체 : 계산 작업의 기본 사례를 객체로 표현한다. 템플릿 매서드 : 계산 작업의 변하지 않는 순서를 추상 메서드로 표현한다. 플러거블 객체 : 둘 이상의 구현을 객체를 호출하여 다양성을 표현한다. 플러거블 셀렉터 : 객체별로 서로 다른 메서드가 동적으로 호출되게 하여 필요없는 하위 클래스의 생성을 피한다. 팩토리 메서드 : 생성자 대신 메서드를 통해 객체를 생성한다. 임포스터 : 현존 프로토콜의 다른 구현을 추가하여 시스템에 변이를 도입한다. 컴포지트 : 하나의 객체로 여러 객체의 행위 조합을 표현한다. 수집 매개변수 : 여러 다른 객체에서 계산한 결과를 모으기 위해 매개변수를 여러곳으로 전달한다. 평가 제목에 충실하게 이 책은 예제를 통해 저자가 직접 TDD를 어떻게 적용하는지 보여줍니다.\n구체적인 예시와 실제 테스트 커버리지 분석 등의 결과를 통해 TDD가 얼마나 효율적인지 확인할 수 있습니다.\n또한, 후반부에 제시하는 디자인 패턴들도 TDD와 객체지향을 좀더 깊게 이해하고 적용할 수 있도록 도와줍니다.\n느낀점 예제 코드의 흐름이 지나치게 구체적인 것 같다가도, 어느새 완성되어 가는 코드를 보며 직접 TDD로 코딩을 하는듯한 느낌을 받았습니다.\n이 책을 읽고 TDD를 직접 사용하면서 테스트 주도 개발의 안정성과 녹색 막대를 보는 즐거움을 느꼈고, 앞으로도 TDD를 코딩 습관이자 패러다임으로서 계발해 나갈 생각입니다.\n추천 테스트를 어느정도 짜면서 막연하게 TDD에 대해 알고 있었던 분들의 추상적인 개념을 구체화하는데 많은 도움이 될 것 같습니다.\nReferences URL 게시일자 방문일자 작성자 위키백과 : 켄트 백\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/review/test-driven_development_by_example/","summary":"한줄평 테스트를 하라. 성공시켜라. 리팩토링하라.\n책을 읽게 된 계기 단위테스트를 작성하다가 자연스럽게 TDD라는 개발 방법론을 접하게 되었습니다. 실제로 가능한건지 몸소 체험해보고 싶었고, 이 책을 통해 기본적인 개념을 느끼고 프로젝트에 직접 적용해보고자 했습니다.\n작가 소개 켄트 벡(Kent Beck)\n켄트 벡(Kent Beck, 1961년~ )은 미국의 소프트웨어 엔지니어이자, 협업적이고 반복적인 디자인 프로세스의 엄격한 사양을 삼가는 소프트웨어 개발 방법론인 익스트림 프로그래밍의 개발자이다. 애자일 소프트웨어 개발의 창설 문서인 애자일 선언문의 17명의 오리지널 서명인 가운데 한 명이었다.","title":"Test Driven Development: By Example"},{"content":"한줄평 테스트에서 오는 결정장애를 해소해주는 처방전\n책을 읽게 된 계기 프로젝트에서 인터페이스를 단위테스트하려고 여기저기 찾아보다가 인터페이스를 테스트하는 것이 안티패턴이라는 여러 블로그 글을 보았습니다. 그 출처가 대부분 이 책이었고, 호기심이 생겨 책까지 읽어보게 되었습니다.\n작가 소개 Vladimir Khorikov(블라디미르 코리코프)\n블라디미르 코리코프(Vladimir Khorikov)는 \u0026lsquo;Unit Testing Principles, Practices, and Patterns\u0026rsquo;라는 책의 저자로, 이 책은 소프트웨어 개발에서 단위 테스팅에 대한 원칙, 실천 방법, 패턴을 다룹니다. 그는 15년 이상의 경력을 가진 소프트웨어 개발자로, 특히 팀을 지도하여 단위 테스팅의 모든 면을 가르치는 데 전문화되어 있습니다. 또한 그는 \u0026lsquo;Enterprise Craftsmanship\u0026rsquo; 블로그의 창시자로 매년 50만 명의 소프트웨어 개발자에게 접근합니다. 처음에는 일반 프로그래밍 주제에 대한 자문가로 시작했지만 최근에는 단위 테스팅에 중점을 두고 있으며, 주요 메시지는 소프트웨어 개발자들에게 단위 테스팅을 쉽게 만드는 방법을 가르치는 것입니다.1\n핵심요약 좋은 테스트의 속성 회귀 방지 : 의도한 대로 기능이 동작하지 않는 것을 방지 리팩터링 내성 : 리팩터링 시 쉽게 테스트가 깨지지 않는 것(거짓 양성 방지) 빠른 피드백 : 빠른 실행과 결과 확인이 가능해야 함 유지 보수성 : 테스트를 이해하기 쉽고, 실행하기 쉬워야 함(외부 종속 방지) 테스트의 속성과 테스트 종류 사이의 관계\n코드의 유형 간단한 코드 : 테스트 작성할 필요 없음 도메인 모델 및 알고리즘 : 단위 테스트 작성 컨트롤러 : 통합 테스트 작성 지나치게 복잡한 코드 : 도메인 모델과 컨트롤러로 리팩터링 코드의 유형 분류\n평가 테스트 코드를 작성하면서 애매했던 부분들을 명료하게 분류해주어서 좋았습니다. 특히 그래프 위주 설명과 용어에 대한 명확한 정의 이후 논리가 전개되어 생각의 흐름대로 이해하기 쉬웠습니다.\n다만, C#과 .NET 프레임워크를 사용하여 일부 코드는 이해하기 어렵거나 해당 환경에 종속적인 부분이 있어 아쉬웠습니다.\n느낀점 테스트를 작성하는 과정에서 막연하게 느꼈던 불편함과 무의미한 작업의 반복을 이론적으로 이해하게 되었습니다.\n특히 코드의 유형에서 지금까지 컨트롤러나 너무 복잡한 코드를 단위테스트하려고 노력하다 보니, 위와 같은 불편함을 느꼈다는 것을 알게 되었습니다.\n테스트를 짜면서 무언가 계속 잘못된 방향으로 가게 된다면, 우선 원본 코드나 설계가 잘못되었는지부터 의심하는 습관을 들여야겠습니다.\n추천 조금 이해하기 어려운 추상적인 개념이나 예제가 있어 처음 테스트를 접하거나 배워보고 싶은 분들에게는 어려울 수 있을 것 같습니다. 반면 실제로 테스트를 짜면서 답답한 기분을 느꼈던 분들에게는 좋은 나침반이 되어 줄 수 있을 것 같아 강력 추천드립니다.\nReferences URL 게시일자 방문일자 작성자 https://www.pluralsight.com/authors/vladimir-khorikov?clickid=SNLXAPSJBxyPTuVxHH1vL11qUkHWyE09awR9R80\u0026amp;irgwc=1\u0026amp;mpid=1970485\u0026amp;aid=7010a000001xAKZAA2\u0026amp;utm_medium=digital_affiliate\u0026amp;utm_campaign=1970485\u0026amp;utm_source=impactradius 미확인 2024.04.14. Vladimir Khorikov Vladimir Khorikov is the author of the book Unit Testing Principles, Practices, and Patterns: https://amzn.to/2QXS2ch He has been professionally involved in software development for over 15 years, including mentoring teams on the ins and outs of unit testing. He\u0026rsquo;s also the founder of the Enterprise Craftsmanship blog, where he reaches 500 thousand software developers yearly. He started as an adviser on general programming topics, but lately has shifted his focus to unit testing with a central message of teaching software developers how to make unit testing painless.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://1eaf.site/review/unit_testing/","summary":"한줄평 테스트에서 오는 결정장애를 해소해주는 처방전\n책을 읽게 된 계기 프로젝트에서 인터페이스를 단위테스트하려고 여기저기 찾아보다가 인터페이스를 테스트하는 것이 안티패턴이라는 여러 블로그 글을 보았습니다. 그 출처가 대부분 이 책이었고, 호기심이 생겨 책까지 읽어보게 되었습니다.\n작가 소개 Vladimir Khorikov(블라디미르 코리코프)\n블라디미르 코리코프(Vladimir Khorikov)는 \u0026lsquo;Unit Testing Principles, Practices, and Patterns\u0026rsquo;라는 책의 저자로, 이 책은 소프트웨어 개발에서 단위 테스팅에 대한 원칙, 실천 방법, 패턴을 다룹니다. 그는 15년 이상의 경력을 가진 소프트웨어 개발자로, 특히 팀을 지도하여 단위 테스팅의 모든 면을 가르치는 데 전문화되어 있습니다.","title":"Unit Testing"}]